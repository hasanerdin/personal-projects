{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\n",
    "  \"margin-top: 0px;\n",
    "  margin-bottom: 10px;\n",
    "  font-family: sans-serif;\n",
    "  font-size: 8rem;\">\n",
    "<span style=\"color:#808080\">D</span><span style=\"color:#808080\">Q</span><span style=\"color:#808080\">N</span>\n",
    "</h1>\n",
    "\n",
    "In this project, Jupyter Notebook is mainly used for visualizations and reporting the results. We will start implementing a vanilla DQN agent and continue with implementing a RAINBOW agent. In general, there are 3 scripts to run a training experiment with the DQN agent on an environment. First one is the model where we implement the policy and the loss function. Second one is the Trainer class, where all of the training and evaluation is handled. This class is responsible for parameter updates, running the environment, and keeping track of necessary statistics as well as saving the model (agent and optimizer). Lastly, the third script initiates the agent, trainer, environment, and starts the training with the given arguments.\n",
    "\n",
    "- DQN\n",
    "    - model\n",
    "    - trainer\n",
    "    - box2d (experiment script)\n",
    "\n",
    "We will follow a very similar structure for the Rainbow agent.\n",
    "\n",
    "#### Running\n",
    "\n",
    "We will train each experiment with 5 different seeds to have a good understanding of the stochasticity involved in the training process. You can run your experiments with command-line interface within the notebook.\n",
    "\n",
    "Run the cell below to see CL arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T23:48:33.777923Z",
     "start_time": "2022-04-07T23:48:26.673040Z"
    },
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python dqn/dqn/box2d.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example dqn run is given below. (You need to fill the missing parts before running the command below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T23:56:03.715009Z",
     "start_time": "2022-04-07T23:55:26.888181Z"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python dqn/dqn/box2d.py --log_dir logs/vanilla-dqn --gamma 0.9 --n-iterations 10000 --seed 5555 --render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you run the training script (box2d.py), the log file named \"progress.csv\" will be saved to the directory given by the ```log_dir``` argument. You can use the csv file to obtain a Pandas dataframe object and visualize the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Plotting\n",
    "\n",
    "When you are done with experiments, you can plot the statistics. We are interested to see how much variation exists in the training. So, run and plot for at least 5 different seeds. Plotter will handle the multi seed plotting and comparisons.\n",
    "\n",
    "Below is an example plot of two experiments each contains 3 different ```progress.csv``` files to demonstrate Plotter.\n",
    "\n",
    "You can switch axes using the dropdowns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d53ff9e4ab484b9ae286040f198b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='X axis', options=('Epsiode', 'Iteration'), value=None), Dropdown(descriptâ€¦"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict, List\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from dqn.visualize import Plotter\n",
    "\n",
    "\n",
    "def collect_training_logs(log_dir: str) -> Dict[str, List[pd.DataFrame]]:\n",
    "    \"\"\" Obtain pandas frames from progress.csv files in the given directory \"\"\"\n",
    "    return [pd.read_csv(os.path.join(log_dir, folder, \"progress.csv\"))\n",
    "                        for folder in os.listdir(log_dir)\n",
    "                        if os.path.exists(os.path.join(log_dir, folder, \"progress.csv\"))]\n",
    "    \n",
    "\n",
    "df_dict = {\"gamma-0.90\": collect_training_logs(os.path.join(\"logs\", \"vanilla-dqn-gamma-0.90\")),\n",
    "           \"gamma-0.99\": collect_training_logs(os.path.join(\"logs\", \"vanilla-dqn-gamma-0.99\"))}\n",
    "plotter = Plotter(df_dict)\n",
    "plotter()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments\n",
    "\n",
    "We run our experiments in the \"Lunar Lander\" environment. You can open render mode by adding \"--render\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    !python dqn/dqn/box2d.py --log_dir logs/vanilla-dqn-exp1 --target-update-period 100 --buffer-capacity 1000 --render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"logs\", \"vanilla-dqn-exp1\")\n",
    "exp_1_dataframes = collect_training_logs(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Experiment DQN in Lunar Lander with large Replay Buffer and target update period.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :      0, Train reward:    nan, Eval reward: -715.7560008432025, TD loss   :    nan, Episode   :      0\n",
      "Iteration :    100, Train reward: -143.47077702413588, Eval reward: -715.7560008432025, TD loss   : 159.97476196289062, Episode   :      2\n",
      "Iteration :    200, Train reward: -170.2694337163854, Eval reward: -715.7560008432025, TD loss   : 144.7177905893326, Episode   :      3\n",
      "Iteration :    300, Train reward: -148.6800636131734, Eval reward: -715.7560008432025, TD loss   : 135.64990907907486, Episode   :      4\n",
      "Iteration :    400, Train reward: -209.32682404287524, Eval reward: -715.7560008432025, TD loss   : 114.8499541091919, Episode   :      5\n",
      "Iteration :    500, Train reward: -198.38225488793918, Eval reward: -328.65405126106816, TD loss   : 77.4826997590065, Episode   :      6\n",
      "Iteration :    600, Train reward: -190.2070995722755, Eval reward: -328.65405126106816, TD loss   : 84.2433928155899, Episode   :      7\n",
      "Iteration :    700, Train reward: -207.88869847269947, Eval reward: -328.65405126106816, TD loss   : 91.15444592237472, Episode   :      8\n",
      "Iteration :    800, Train reward: -197.02584452069766, Eval reward: -328.65405126106816, TD loss   : 69.39192097187042, Episode   :      9\n",
      "Iteration :    900, Train reward: -205.6029909034628, Eval reward: -328.65405126106816, TD loss   : 62.00920535802841, Episode   :     10\n",
      "Iteration :   1000, Train reward: -205.6029909034628, Eval reward: -179.60498399899876, TD loss   : 75.87277319669724, Episode   :     10\n",
      "Iteration :   1100, Train reward: -186.54684541326105, Eval reward: -179.60498399899876, TD loss   : 64.41202010154724, Episode   :     12\n",
      "Iteration :   1200, Train reward: -188.30281878291407, Eval reward: -179.60498399899876, TD loss   : 56.780057063102724, Episode   :     13\n",
      "Iteration :   1300, Train reward: -188.30281878291407, Eval reward: -179.60498399899876, TD loss   : 46.54723847866058, Episode   :     13\n",
      "Iteration :   1400, Train reward: -199.00386372898757, Eval reward: -179.60498399899876, TD loss   : 70.38673615932464, Episode   :     14\n",
      "Iteration :   1500, Train reward: -193.5812246058075, Eval reward: -269.38985863278384, TD loss   : 63.47234470367432, Episode   :     15\n",
      "Iteration :   1600, Train reward: -178.219610684792, Eval reward: -269.38985863278384, TD loss   : 72.25632907390595, Episode   :     17\n",
      "Iteration :   1700, Train reward: -180.30649079262275, Eval reward: -269.38985863278384, TD loss   : 65.65571487665176, Episode   :     18\n",
      "Iteration :   1800, Train reward: -175.0570571750217, Eval reward: -269.38985863278384, TD loss   : 63.228672971725466, Episode   :     19\n",
      "Iteration :   1900, Train reward: -175.02653631811685, Eval reward: -269.38985863278384, TD loss   : 65.38564504861831, Episode   :     20\n",
      "Iteration :   2000, Train reward: -185.4646446690511, Eval reward: -133.4164144938762, TD loss   : 65.84152690172195, Episode   :     21\n",
      "Iteration :   2100, Train reward: -173.2735576789991, Eval reward: -133.4164144938762, TD loss   : 62.88774522304535, Episode   :     23\n",
      "Iteration :   2200, Train reward: -173.2735576789991, Eval reward: -133.4164144938762, TD loss   : 57.49703641414642, Episode   :     23\n",
      "Iteration :   2300, Train reward: -163.3466938091031, Eval reward: -133.4164144938762, TD loss   : 64.40214108109474, Episode   :     25\n",
      "Iteration :   2400, Train reward: -163.3466938091031, Eval reward: -133.4164144938762, TD loss   : 64.73087950468063, Episode   :     25\n",
      "Iteration :   2500, Train reward: -161.56917350800182, Eval reward: -395.7007510601006, TD loss   : 65.61257925629616, Episode   :     26\n",
      "Iteration :   2600, Train reward: -159.3401038115357, Eval reward: -395.7007510601006, TD loss   : 49.84913606405258, Episode   :     27\n",
      "Iteration :   2700, Train reward: -146.33389013299572, Eval reward: -395.7007510601006, TD loss   : 59.118131457567216, Episode   :     28\n",
      "Iteration :   2800, Train reward: -143.20881980251824, Eval reward: -395.7007510601006, TD loss   : 36.05931610703468, Episode   :     29\n",
      "Iteration :   2900, Train reward: -142.18163871527193, Eval reward: -395.7007510601006, TD loss   : 58.338715575933456, Episode   :     30\n",
      "Iteration :   3000, Train reward: -146.1210277561162, Eval reward: -218.85555865794154, TD loss   : 75.12607773542405, Episode   :     31\n",
      "Iteration :   3100, Train reward: -141.816045684818, Eval reward: -218.85555865794154, TD loss   : 60.21412818431854, Episode   :     33\n",
      "Iteration :   3200, Train reward: -141.816045684818, Eval reward: -218.85555865794154, TD loss   : 53.91155772209167, Episode   :     33\n",
      "Iteration :   3300, Train reward: -130.77085792698534, Eval reward: -218.85555865794154, TD loss   : 44.00947271585464, Episode   :     35\n",
      "Iteration :   3400, Train reward: -130.77085792698534, Eval reward: -218.85555865794154, TD loss   : 51.51148273706436, Episode   :     35\n",
      "Iteration :   3500, Train reward: -151.59963005792508, Eval reward: -49.97579440226132, TD loss   : 42.765872440338136, Episode   :     37\n",
      "Iteration :   3600, Train reward: -141.20593921670982, Eval reward: -49.97579440226132, TD loss   : 44.56188613057137, Episode   :     38\n",
      "Iteration :   3700, Train reward: -141.6757519708891, Eval reward: -49.97579440226132, TD loss   : 44.79533367276192, Episode   :     39\n",
      "Iteration :   3800, Train reward: -136.04642559654033, Eval reward: -49.97579440226132, TD loss   : 44.407163140773775, Episode   :     40\n",
      "Iteration :   3900, Train reward: -127.63732966179646, Eval reward: -49.97579440226132, TD loss   : 53.63588678240776, Episode   :     41\n",
      "Iteration :   4000, Train reward: -125.96763611937183, Eval reward: -106.2654556132755, TD loss   : 43.139306725263594, Episode   :     42\n",
      "Iteration :   4100, Train reward: -120.18864587218954, Eval reward: -106.2654556132755, TD loss   : 40.39351321220398, Episode   :     44\n",
      "Iteration :   4200, Train reward: -117.37441328805676, Eval reward: -106.2654556132755, TD loss   : 45.008190853595735, Episode   :     45\n",
      "Iteration :   4300, Train reward: -117.37441328805676, Eval reward: -106.2654556132755, TD loss   : 38.53883956193924, Episode   :     45\n",
      "Iteration :   4400, Train reward: -119.06937917604951, Eval reward: -106.2654556132755, TD loss   : 40.332703074216845, Episode   :     47\n",
      "Iteration :   4500, Train reward: -127.2879416772455, Eval reward: -98.37448569477189, TD loss   : 40.952629463672636, Episode   :     48\n",
      "Iteration :   4600, Train reward: -127.70995283809134, Eval reward: -98.37448569477189, TD loss   : 47.38432822227478, Episode   :     50\n",
      "Iteration :   4700, Train reward: -127.70995283809134, Eval reward: -98.37448569477189, TD loss   : 29.153638465404512, Episode   :     50\n",
      "Iteration :   4800, Train reward: -124.76288794896422, Eval reward: -98.37448569477189, TD loss   : 39.55120079755783, Episode   :     52\n",
      "Iteration :   4900, Train reward: -124.9961040166269, Eval reward: -98.37448569477189, TD loss   : 37.98060509800911, Episode   :     53\n",
      "Iteration :   5000, Train reward: -124.9961040166269, Eval reward: -40.267544337431886, TD loss   : 38.657587156295776, Episode   :     53\n",
      "Iteration :   5100, Train reward: -119.61229860392227, Eval reward: -40.267544337431886, TD loss   : 41.63408237934112, Episode   :     54\n",
      "Iteration :   5200, Train reward: -107.50006202074628, Eval reward: -40.267544337431886, TD loss   : 28.66524369239807, Episode   :     56\n",
      "Iteration :   5300, Train reward: -107.50006202074628, Eval reward: -40.267544337431886, TD loss   : 38.74759400367737, Episode   :     56\n",
      "Iteration :   5400, Train reward: -96.84258892005954, Eval reward: -40.267544337431886, TD loss   : 33.15372153043747, Episode   :     57\n",
      "Iteration :   5500, Train reward: -98.14595747651454, Eval reward: -70.43550799948113, TD loss   : 35.52801062107086, Episode   :     58\n",
      "Iteration :   5600, Train reward: -94.82241508040607, Eval reward: -70.43550799948113, TD loss   : 38.389066075086596, Episode   :     59\n",
      "Iteration :   5700, Train reward: -103.67890040849443, Eval reward: -70.43550799948113, TD loss   : 36.53454945921898, Episode   :     60\n",
      "Iteration :   5800, Train reward: -100.80547552809021, Eval reward: -70.43550799948113, TD loss   : 36.399186030626296, Episode   :     61\n",
      "Iteration :   5900, Train reward: -102.78285443191673, Eval reward: -70.43550799948113, TD loss   : 40.19155094742775, Episode   :     62\n",
      "Iteration :   6000, Train reward: -108.81242730305742, Eval reward: -17.307756855077194, TD loss   : 39.03865874648094, Episode   :     63\n",
      "Iteration :   6100, Train reward: -106.35888686546446, Eval reward: -17.307756855077194, TD loss   : 45.59572998285294, Episode   :     65\n",
      "Iteration :   6200, Train reward: -106.35888686546446, Eval reward: -17.307756855077194, TD loss   : 41.52857202529907, Episode   :     65\n",
      "Iteration :   6300, Train reward: -100.19478529632138, Eval reward: -17.307756855077194, TD loss   : 43.04228750944137, Episode   :     66\n",
      "Iteration :   6400, Train reward: -101.87832338082471, Eval reward: -17.307756855077194, TD loss   : 35.34025255560875, Episode   :     67\n",
      "Iteration :   6500, Train reward: -104.41458956026284, Eval reward: -31.057365049541982, TD loss   : 32.09156025052071, Episode   :     68\n",
      "Iteration :   6600, Train reward: -94.31224592847273, Eval reward: -31.057365049541982, TD loss   : 34.066653801202776, Episode   :     70\n",
      "Iteration :   6700, Train reward: -94.31224592847273, Eval reward: -31.057365049541982, TD loss   : 30.808335487246513, Episode   :     70\n",
      "Iteration :   6800, Train reward: -111.55448142114922, Eval reward: -31.057365049541982, TD loss   : 29.56643592476845, Episode   :     71\n",
      "Iteration :   6900, Train reward: -105.8124781741192, Eval reward: -31.057365049541982, TD loss   : 39.051922317743305, Episode   :     72\n",
      "Iteration :   7000, Train reward: -106.00040444083989, Eval reward: -31.50298120740454, TD loss   : 28.990037471055984, Episode   :     73\n",
      "Iteration :   7100, Train reward: -106.13656421606069, Eval reward: -31.50298120740454, TD loss   : 38.12868705391884, Episode   :     74\n",
      "Iteration :   7200, Train reward: -106.38235021198832, Eval reward: -31.50298120740454, TD loss   : 40.2098764359951, Episode   :     75\n",
      "Iteration :   7300, Train reward: -107.44222223879726, Eval reward: -31.50298120740454, TD loss   : 34.646058963537214, Episode   :     76\n",
      "Iteration :   7400, Train reward: -111.183995292752, Eval reward: -31.50298120740454, TD loss   : 34.5076725423336, Episode   :     78\n",
      "Iteration :   7500, Train reward: -118.09843450242779, Eval reward: 17.12880249911424, TD loss   : 33.948599017858506, Episode   :     79\n",
      "Iteration :   7600, Train reward: -107.05620581233936, Eval reward: 17.12880249911424, TD loss   : 33.85114867210388, Episode   :     80\n",
      "Iteration :   7700, Train reward: -109.99247570132238, Eval reward: 17.12880249911424, TD loss   : 34.16869583725929, Episode   :     81\n",
      "Iteration :   7800, Train reward: -113.26966547527925, Eval reward: 17.12880249911424, TD loss   : 32.872534234523776, Episode   :     82\n",
      "Iteration :   7900, Train reward: -116.35686041421573, Eval reward: 17.12880249911424, TD loss   : 26.137692861557007, Episode   :     83\n",
      "Iteration :   8000, Train reward: -116.40024244580142, Eval reward: 11.772727784876452, TD loss   : 45.53483531236648, Episode   :     84\n",
      "Iteration :   8100, Train reward: -112.07058385519096, Eval reward: 11.772727784876452, TD loss   : 41.77744148135185, Episode   :     85\n",
      "Iteration :   8200, Train reward: -110.93205157600633, Eval reward: 11.772727784876452, TD loss   : 30.341494600772858, Episode   :     86\n",
      "Iteration :   8300, Train reward: -111.7912468622394, Eval reward: 11.772727784876452, TD loss   : 33.117038942575455, Episode   :     87\n",
      "Iteration :   8400, Train reward: -107.38575962574296, Eval reward: 11.772727784876452, TD loss   : 32.2430584192276, Episode   :     88\n",
      "Iteration :   8500, Train reward: -109.64463513660705, Eval reward: -6.50058210881526, TD loss   : 41.06649472355843, Episode   :     89\n",
      "Iteration :   8600, Train reward: -103.24550205031241, Eval reward: -6.50058210881526, TD loss   : 34.52211740136146, Episode   :     90\n",
      "Iteration :   8700, Train reward: -89.94696046186243, Eval reward: -6.50058210881526, TD loss   : 42.91108936548233, Episode   :     91\n",
      "Iteration :   8800, Train reward: -87.78443657336209, Eval reward: -6.50058210881526, TD loss   : 37.955496487617495, Episode   :     92\n",
      "Iteration :   8900, Train reward: -93.26969214601272, Eval reward: -6.50058210881526, TD loss   : 38.471881421804426, Episode   :     93\n",
      "Iteration :   9000, Train reward: -93.26969214601272, Eval reward: 40.79947623226164, TD loss   : 29.807860689163206, Episode   :     93\n",
      "Iteration :   9100, Train reward: -94.02367255365169, Eval reward: 40.79947623226164, TD loss   : 33.90875698924064, Episode   :     94\n",
      "Iteration :   9200, Train reward: -95.74236673431597, Eval reward: 40.79947623226164, TD loss   : 42.36109639525414, Episode   :     95\n",
      "Iteration :   9300, Train reward: -90.74969182876549, Eval reward: 40.79947623226164, TD loss   : 28.863262169361114, Episode   :     96\n",
      "Iteration :   9400, Train reward: -94.69095209619982, Eval reward: 40.79947623226164, TD loss   : 33.49517725348473, Episode   :     97\n",
      "Iteration :   9500, Train reward: -99.19993432232374, Eval reward: -108.93758379810306, TD loss   : 35.89249544501305, Episode   :     98\n",
      "Iteration :   9600, Train reward: -96.24374108293357, Eval reward: -108.93758379810306, TD loss   : 28.252417542934417, Episode   :    100\n",
      "Iteration :   9700, Train reward: -92.33786709769376, Eval reward: -108.93758379810306, TD loss   : 43.03220784425736, Episode   :    101\n",
      "Iteration :   9800, Train reward: -91.93917156468046, Eval reward: -108.93758379810306, TD loss   : 23.586038518548012, Episode   :    102\n",
      "Iteration :   9900, Train reward: -91.93917156468046, Eval reward: -108.93758379810306, TD loss   : 30.18939584851265, Episode   :    102\n",
      "Iteration :  10000, Train reward: -82.96154738612435, Eval reward: -29.58701031946371, TD loss   : 36.20637672305107, Episode   :    103\n",
      "Iteration :  10100, Train reward: -80.50876997280999, Eval reward: -29.58701031946371, TD loss   : 22.939274108409883, Episode   :    104\n",
      "Iteration :  10200, Train reward: -84.62810885682923, Eval reward: -29.58701031946371, TD loss   : 42.176772694587704, Episode   :    105\n",
      "Iteration :  10300, Train reward: -84.62810885682923, Eval reward: -29.58701031946371, TD loss   : 29.709785472154618, Episode   :    105\n",
      "Iteration :  10400, Train reward: -84.34336401338258, Eval reward: -29.58701031946371, TD loss   : 31.52344247817993, Episode   :    106\n",
      "Iteration :  10500, Train reward: -83.74431307384933, Eval reward: -82.1346167139014, TD loss   : 27.760650337934493, Episode   :    107\n",
      "Iteration :  10600, Train reward: -80.3743500383439, Eval reward: -82.1346167139014, TD loss   : 24.675082873106003, Episode   :    108\n",
      "Iteration :  10700, Train reward: -82.09409382169363, Eval reward: -82.1346167139014, TD loss   : 21.412047435045242, Episode   :    109\n",
      "Iteration :  10800, Train reward: -82.09409382169363, Eval reward: -82.1346167139014, TD loss   : 34.75443637013436, Episode   :    109\n",
      "Iteration :  10900, Train reward: -84.18433210246968, Eval reward: -82.1346167139014, TD loss   : 28.0677938079834, Episode   :    111\n",
      "Iteration :  11000, Train reward: -84.18433210246968, Eval reward: 11.191485828334152, TD loss   : 31.505294649600984, Episode   :    111\n",
      "Iteration :  11100, Train reward: -77.50372225570433, Eval reward: 11.191485828334152, TD loss   : 41.47671320438385, Episode   :    113\n",
      "Iteration :  11200, Train reward: -77.50372225570433, Eval reward: 11.191485828334152, TD loss   : 33.428653864860536, Episode   :    113\n",
      "Iteration :  11300, Train reward: -81.98225614518648, Eval reward: 11.191485828334152, TD loss   : 32.17669423699379, Episode   :    114\n",
      "Iteration :  11400, Train reward: -77.30567892399037, Eval reward: 11.191485828334152, TD loss   : 26.897573705911636, Episode   :    115\n",
      "Iteration :  11500, Train reward: -81.78759474250127, Eval reward: 21.272251207647056, TD loss   : 24.71684938788414, Episode   :    116\n",
      "Iteration :  11600, Train reward: -73.69793363437888, Eval reward: 21.272251207647056, TD loss   : 34.93964244008064, Episode   :    117\n",
      "Iteration :  11700, Train reward: -74.14780665367539, Eval reward: 21.272251207647056, TD loss   : 31.61151330590248, Episode   :    118\n",
      "Iteration :  11800, Train reward: -87.17663683789642, Eval reward: 21.272251207647056, TD loss   : 20.235181805491447, Episode   :    119\n",
      "Iteration :  11900, Train reward: -86.35615196936423, Eval reward: 21.272251207647056, TD loss   : 37.84252428293228, Episode   :    120\n",
      "Iteration :  12000, Train reward: -86.35615196936423, Eval reward: -57.28665221316172, TD loss   : 30.017213920354845, Episode   :    120\n",
      "Iteration :  12100, Train reward: -83.34338956894725, Eval reward: -57.28665221316172, TD loss   : 40.20609785318375, Episode   :    121\n",
      "Iteration :  12200, Train reward: -81.66635814769579, Eval reward: -57.28665221316172, TD loss   : 29.731304149627686, Episode   :    122\n",
      "Iteration :  12300, Train reward: -81.1372562951336, Eval reward: -57.28665221316172, TD loss   : 35.88074339389801, Episode   :    123\n",
      "Iteration :  12400, Train reward: -81.1372562951336, Eval reward: -57.28665221316172, TD loss   : 30.16722365617752, Episode   :    123\n",
      "Iteration :  12500, Train reward: -85.70054156468417, Eval reward: 13.239205579797533, TD loss   : 28.75732261419296, Episode   :    124\n",
      "Iteration :  12600, Train reward: -80.29810873640659, Eval reward: 13.239205579797533, TD loss   : 28.743586393594743, Episode   :    125\n",
      "Iteration :  12700, Train reward: -81.8960974572328, Eval reward: 13.239205579797533, TD loss   : 31.17350854754448, Episode   :    126\n",
      "Iteration :  12800, Train reward: -84.22542201999863, Eval reward: 13.239205579797533, TD loss   : 24.796654636859895, Episode   :    127\n",
      "Iteration :  12900, Train reward: -91.40997374657334, Eval reward: 13.239205579797533, TD loss   : 23.867982367277147, Episode   :    128\n",
      "Iteration :  13000, Train reward: -91.40997374657334, Eval reward: 61.13518292360923, TD loss   : 17.189570811986922, Episode   :    128\n",
      "Iteration :  13100, Train reward: -86.924024009255, Eval reward: 61.13518292360923, TD loss   : 29.83724050760269, Episode   :    129\n",
      "Iteration :  13200, Train reward: -84.97130593777887, Eval reward: 61.13518292360923, TD loss   : 29.551426202058792, Episode   :    130\n",
      "Iteration :  13300, Train reward: -87.65769687316609, Eval reward: 61.13518292360923, TD loss   : 25.426695030927657, Episode   :    131\n",
      "Iteration :  13400, Train reward: -87.65769687316609, Eval reward: 61.13518292360923, TD loss   : 32.12090844631195, Episode   :    131\n",
      "Iteration :  13500, Train reward: -86.41588881465012, Eval reward: 33.298661806795806, TD loss   : 33.20141611337662, Episode   :    132\n",
      "Iteration :  13600, Train reward: -81.22077948052089, Eval reward: 33.298661806795806, TD loss   : 37.119247986078264, Episode   :    133\n",
      "Iteration :  13700, Train reward: -77.67603937589402, Eval reward: 33.298661806795806, TD loss   : 25.674640769958497, Episode   :    134\n",
      "Iteration :  13800, Train reward: -82.75690450200611, Eval reward: 33.298661806795806, TD loss   : 17.695279730558397, Episode   :    135\n",
      "Iteration :  13900, Train reward: -82.75690450200611, Eval reward: 33.298661806795806, TD loss   : 29.655889970064162, Episode   :    135\n",
      "Iteration :  14000, Train reward: -81.33285864663698, Eval reward: 31.03157127125987, TD loss   : 23.122974668741225, Episode   :    136\n",
      "Iteration :  14100, Train reward: -81.17468346750141, Eval reward: 31.03157127125987, TD loss   : 17.136340312957763, Episode   :    137\n",
      "Iteration :  14200, Train reward: -64.33342850058297, Eval reward: 31.03157127125987, TD loss   : 26.328351870775222, Episode   :    139\n",
      "Iteration :  14300, Train reward: -65.79513900163803, Eval reward: 31.03157127125987, TD loss   : 21.48912180185318, Episode   :    140\n",
      "Iteration :  14400, Train reward: -65.79513900163803, Eval reward: 31.03157127125987, TD loss   : 25.683836739063263, Episode   :    140\n",
      "Iteration :  14500, Train reward: -67.79358747121456, Eval reward: -22.28921103081614, TD loss   : 27.48377064704895, Episode   :    141\n",
      "Iteration :  14600, Train reward: -60.97330261872188, Eval reward: -22.28921103081614, TD loss   : 35.59598632931709, Episode   :    142\n",
      "Iteration :  14700, Train reward: -62.766253988124376, Eval reward: -22.28921103081614, TD loss   : 35.568626672029495, Episode   :    143\n",
      "Iteration :  14800, Train reward: -62.766253988124376, Eval reward: -22.28921103081614, TD loss   : 20.248058989048005, Episode   :    143\n",
      "Iteration :  14900, Train reward: -58.269274251245655, Eval reward: -22.28921103081614, TD loss   : 34.54440695405006, Episode   :    144\n",
      "Iteration :  15000, Train reward: -60.98867657884887, Eval reward: 74.4724822142653, TD loss   : 34.11458558559418, Episode   :    145\n",
      "Iteration :  15100, Train reward: -58.31086290636142, Eval reward: 74.4724822142653, TD loss   : 28.405429722070693, Episode   :    146\n",
      "Iteration :  15200, Train reward: -61.181578060459955, Eval reward: 74.4724822142653, TD loss   : 26.548581944704054, Episode   :    147\n",
      "Iteration :  15300, Train reward: -61.181578060459955, Eval reward: 74.4724822142653, TD loss   : 29.78809502005577, Episode   :    147\n",
      "Iteration :  15400, Train reward: -49.65416022983253, Eval reward: 74.4724822142653, TD loss   : 26.98061232447624, Episode   :    148\n",
      "Iteration :  15500, Train reward: -55.2613171626276, Eval reward: 19.37896983690028, TD loss   : 18.42155977845192, Episode   :    149\n",
      "Iteration :  15600, Train reward: -54.82893795424716, Eval reward: 19.37896983690028, TD loss   : 30.521317604780197, Episode   :    150\n",
      "Iteration :  15700, Train reward: -53.29171306454849, Eval reward: 19.37896983690028, TD loss   : 25.19356987833977, Episode   :    151\n",
      "Iteration :  15800, Train reward: -55.159824023319594, Eval reward: 19.37896983690028, TD loss   : 36.79115362405777, Episode   :    152\n",
      "Iteration :  15900, Train reward: -55.159824023319594, Eval reward: 19.37896983690028, TD loss   : 26.58452233314514, Episode   :    152\n",
      "Iteration :  16000, Train reward: -62.153064801487496, Eval reward: -41.04532613901325, TD loss   : 30.83788820505142, Episode   :    153\n",
      "Iteration :  16100, Train reward: -65.80180310166934, Eval reward: -41.04532613901325, TD loss   : 25.673458008766175, Episode   :    154\n",
      "Iteration :  16200, Train reward: -62.88558566389738, Eval reward: -41.04532613901325, TD loss   : 26.262654221057893, Episode   :    155\n",
      "Iteration :  16300, Train reward: -61.98760263528042, Eval reward: -41.04532613901325, TD loss   : 23.559134749174117, Episode   :    156\n",
      "Iteration :  16400, Train reward: -66.24778498185384, Eval reward: -41.04532613901325, TD loss   : 31.74274555206299, Episode   :    157\n",
      "Iteration :  16500, Train reward: -66.24778498185384, Eval reward: 27.910513477999377, TD loss   : 37.667904121875765, Episode   :    157\n",
      "Iteration :  16600, Train reward: -66.01703466774646, Eval reward: 27.910513477999377, TD loss   : 23.502604916095734, Episode   :    158\n",
      "Iteration :  16700, Train reward: -70.31619036534889, Eval reward: 27.910513477999377, TD loss   : 20.352897280454634, Episode   :    159\n",
      "Iteration :  16800, Train reward: -72.69597849214706, Eval reward: 27.910513477999377, TD loss   : 28.401463552713395, Episode   :    160\n",
      "Iteration :  16900, Train reward: -72.69597849214706, Eval reward: 27.910513477999377, TD loss   : 24.94230625987053, Episode   :    160\n",
      "Iteration :  17000, Train reward: -74.47961913643982, Eval reward: 63.8799168203469, TD loss   : 29.05695363342762, Episode   :    161\n",
      "Iteration :  17100, Train reward: -74.02540800713055, Eval reward: 63.8799168203469, TD loss   : 36.25848209619522, Episode   :    162\n",
      "Iteration :  17200, Train reward: -71.97159534464328, Eval reward: 63.8799168203469, TD loss   : 25.537837884426118, Episode   :    163\n",
      "Iteration :  17300, Train reward: -71.97159534464328, Eval reward: 63.8799168203469, TD loss   : 13.536001368165016, Episode   :    163\n",
      "Iteration :  17400, Train reward: -71.97159534464328, Eval reward: 63.8799168203469, TD loss   : 29.964017134308815, Episode   :    163\n",
      "Iteration :  17500, Train reward: -66.85887054573178, Eval reward: -22.62434811995918, TD loss   : 24.544888499975205, Episode   :    164\n",
      "Iteration :  17600, Train reward: -63.809902888030976, Eval reward: -22.62434811995918, TD loss   : 25.611133031845092, Episode   :    166\n",
      "Iteration :  17700, Train reward: -63.809902888030976, Eval reward: -22.62434811995918, TD loss   : 35.8241980099678, Episode   :    166\n",
      "Iteration :  17800, Train reward: -56.49205433592283, Eval reward: -22.62434811995918, TD loss   : 19.883704515695573, Episode   :    167\n",
      "Iteration :  17900, Train reward: -54.923298287921355, Eval reward: -22.62434811995918, TD loss   : 22.921318536996843, Episode   :    168\n",
      "Iteration :  18000, Train reward: -54.923298287921355, Eval reward: -12.795031259065158, TD loss   : 27.08107701420784, Episode   :    168\n",
      "Iteration :  18100, Train reward: -51.631742828579775, Eval reward: -12.795031259065158, TD loss   : 26.567499529123307, Episode   :    169\n",
      "Iteration :  18200, Train reward: -53.51933665307083, Eval reward: -12.795031259065158, TD loss   : 23.62377112150192, Episode   :    170\n",
      "Iteration :  18300, Train reward: -53.51933665307083, Eval reward: -12.795031259065158, TD loss   : 21.086953966617585, Episode   :    170\n",
      "Iteration :  18400, Train reward: -47.372743836181165, Eval reward: -12.795031259065158, TD loss   : 27.301568117141723, Episode   :    171\n",
      "Iteration :  18500, Train reward: -47.372743836181165, Eval reward: 18.637340318985885, TD loss   : 22.979026218652724, Episode   :    171\n",
      "Iteration :  18600, Train reward: -40.63187209176699, Eval reward: 18.637340318985885, TD loss   : 27.257509812116623, Episode   :    172\n",
      "Iteration :  18700, Train reward: -33.275438380233275, Eval reward: 18.637340318985885, TD loss   : 27.109856173992156, Episode   :    173\n",
      "Iteration :  18800, Train reward: -33.275438380233275, Eval reward: 18.637340318985885, TD loss   : 22.14586674451828, Episode   :    173\n",
      "Iteration :  18900, Train reward: -27.376019632140277, Eval reward: 18.637340318985885, TD loss   : 25.589534410238265, Episode   :    174\n",
      "Iteration :  19000, Train reward: -27.376019632140277, Eval reward: -179.56808266821864, TD loss   : 30.35328311562538, Episode   :    174\n",
      "Iteration :  19100, Train reward: -20.800735152605043, Eval reward: -179.56808266821864, TD loss   : 26.185642362833022, Episode   :    175\n",
      "Iteration :  19200, Train reward: -17.706622599193004, Eval reward: -179.56808266821864, TD loss   : 31.700397753715514, Episode   :    176\n",
      "Iteration :  19300, Train reward: -17.706622599193004, Eval reward: -179.56808266821864, TD loss   : 36.31260757088661, Episode   :    176\n",
      "Iteration :  19400, Train reward: -17.640883125163562, Eval reward: -179.56808266821864, TD loss   : 23.636999884843828, Episode   :    177\n",
      "Iteration :  19500, Train reward: -17.640883125163562, Eval reward: -0.8844342379795733, TD loss   : 28.24990448474884, Episode   :    177\n",
      "Iteration :  19600, Train reward: -17.01264881757165, Eval reward: -0.8844342379795733, TD loss   : 26.86328312754631, Episode   :    178\n",
      "Iteration :  19700, Train reward: -11.304610566284927, Eval reward: -0.8844342379795733, TD loss   : 26.917168830633162, Episode   :    179\n",
      "Iteration :  19800, Train reward: -11.304610566284927, Eval reward: -0.8844342379795733, TD loss   : 20.545231001377104, Episode   :    179\n",
      "Iteration :  19900, Train reward: -9.650433618132906, Eval reward: -0.8844342379795733, TD loss   : 29.0444056892395, Episode   :    180\n",
      "Iteration :  20000, Train reward: -7.7630953326505985, Eval reward: -18.72707330710372, TD loss   : 24.97043169617653, Episode   :    181\n",
      "Iteration :  20100, Train reward: -6.222612366712904, Eval reward: -18.72707330710372, TD loss   : 21.160140829086302, Episode   :    182\n",
      "Iteration :  20200, Train reward: -11.601984171231424, Eval reward: -18.72707330710372, TD loss   : 13.276551817655564, Episode   :    183\n",
      "Iteration :  20300, Train reward: -20.82848033149734, Eval reward: -18.72707330710372, TD loss   : 22.61403318285942, Episode   :    184\n",
      "Iteration :  20400, Train reward: -20.82848033149734, Eval reward: -18.72707330710372, TD loss   : 23.13947238922119, Episode   :    184\n",
      "Iteration :  20500, Train reward: -20.82848033149734, Eval reward: -111.5094098584196, TD loss   : 25.019674940109255, Episode   :    184\n",
      "Iteration :  20600, Train reward: -14.945701064382376, Eval reward: -111.5094098584196, TD loss   : 21.43247406423092, Episode   :    185\n",
      "Iteration :  20700, Train reward: -16.213059839411176, Eval reward: -111.5094098584196, TD loss   : 25.939190253019333, Episode   :    186\n",
      "Iteration :  20800, Train reward: -16.213059839411176, Eval reward: -111.5094098584196, TD loss   : 27.271047805547713, Episode   :    186\n",
      "Iteration :  20900, Train reward: -16.213059839411176, Eval reward: -111.5094098584196, TD loss   : 18.625428760051726, Episode   :    186\n",
      "Iteration :  21000, Train reward: -6.967933297078046, Eval reward: -4.387658917846309, TD loss   : 15.789194666147232, Episode   :    187\n",
      "Iteration :  21100, Train reward: -7.730048517490526, Eval reward: -4.387658917846309, TD loss   : 27.03664086461067, Episode   :    188\n",
      "Iteration :  21200, Train reward: -7.852985983440682, Eval reward: -4.387658917846309, TD loss   : 23.391640373468398, Episode   :    189\n",
      "Iteration :  21300, Train reward: -7.417362796942365, Eval reward: -4.387658917846309, TD loss   : 29.66155151486397, Episode   :    190\n",
      "Iteration :  21400, Train reward: -7.417362796942365, Eval reward: -4.387658917846309, TD loss   : 28.270063761472702, Episode   :    190\n",
      "Iteration :  21500, Train reward: -11.176908605684138, Eval reward: 21.515162829801696, TD loss   : 23.636614385843277, Episode   :    191\n",
      "Iteration :  21600, Train reward: -10.304796695804479, Eval reward: 21.515162829801696, TD loss   : 27.567526314258576, Episode   :    192\n",
      "Iteration :  21700, Train reward: -14.47220620787066, Eval reward: 21.515162829801696, TD loss   : 20.387724429368973, Episode   :    193\n",
      "Iteration :  21800, Train reward: -14.47220620787066, Eval reward: 21.515162829801696, TD loss   : 28.482324577569962, Episode   :    193\n",
      "Iteration :  21900, Train reward: -14.47220620787066, Eval reward: 21.515162829801696, TD loss   : 24.12650455236435, Episode   :    193\n",
      "Iteration :  22000, Train reward: -12.037167010113562, Eval reward: -111.16842109085323, TD loss   : 28.583944998979568, Episode   :    194\n",
      "Iteration :  22100, Train reward: -11.330062756834408, Eval reward: -111.16842109085323, TD loss   : 20.71684960484505, Episode   :    195\n",
      "Iteration :  22200, Train reward: -12.283400354509755, Eval reward: -111.16842109085323, TD loss   : 21.104412945508958, Episode   :    196\n",
      "Iteration :  22300, Train reward: -12.283400354509755, Eval reward: -111.16842109085323, TD loss   : 21.77186187148094, Episode   :    196\n",
      "Iteration :  22400, Train reward: -12.283400354509755, Eval reward: -111.16842109085323, TD loss   : 16.230048007965088, Episode   :    196\n",
      "Iteration :  22500, Train reward: -14.43508559597584, Eval reward: -1.8379889556735818, TD loss   : 17.547181876897813, Episode   :    197\n",
      "Iteration :  22600, Train reward: -14.819128124277807, Eval reward: -1.8379889556735818, TD loss   : 27.55190082192421, Episode   :    198\n",
      "Iteration :  22700, Train reward: -13.078468147323473, Eval reward: -1.8379889556735818, TD loss   : 15.30573139667511, Episode   :    199\n",
      "Iteration :  22800, Train reward: -13.078468147323473, Eval reward: -1.8379889556735818, TD loss   : 25.93526288032532, Episode   :    199\n",
      "Iteration :  22900, Train reward: -9.60677874283471, Eval reward: -1.8379889556735818, TD loss   : 23.3617952054739, Episode   :    200\n",
      "Iteration :  23000, Train reward: -8.3404753965761, Eval reward: -55.342241033999144, TD loss   : 18.725620480775834, Episode   :    201\n",
      "Iteration :  23100, Train reward: -10.818027960755662, Eval reward: -55.342241033999144, TD loss   : 23.052474240064623, Episode   :    202\n",
      "Iteration :  23200, Train reward: -4.194673215289482, Eval reward: -55.342241033999144, TD loss   : 22.49557085156441, Episode   :    203\n",
      "Iteration :  23300, Train reward: 1.6108008185371818, Eval reward: -55.342241033999144, TD loss   : 25.175178004503252, Episode   :    204\n",
      "Iteration :  23400, Train reward: 1.6108008185371818, Eval reward: -55.342241033999144, TD loss   : 22.93802106142044, Episode   :    204\n",
      "Iteration :  23500, Train reward: -13.52948275347482, Eval reward: 3.265030324530175, TD loss   : 28.28812404513359, Episode   :    205\n",
      "Iteration :  23600, Train reward: -11.711213438192907, Eval reward: 3.265030324530175, TD loss   : 17.68284992337227, Episode   :    206\n",
      "Iteration :  23700, Train reward: -17.195140950564987, Eval reward: 3.265030324530175, TD loss   : 30.82699327468872, Episode   :    207\n",
      "Iteration :  23800, Train reward: -17.195140950564987, Eval reward: 3.265030324530175, TD loss   : 23.71588378190994, Episode   :    207\n",
      "Iteration :  23900, Train reward: -17.195140950564987, Eval reward: 3.265030324530175, TD loss   : 21.657455075979232, Episode   :    207\n",
      "Iteration :  24000, Train reward: -17.13518066283865, Eval reward: 18.493076278569617, TD loss   : 22.685709842443465, Episode   :    208\n",
      "Iteration :  24100, Train reward: -12.640879645415907, Eval reward: 18.493076278569617, TD loss   : 26.75271075963974, Episode   :    209\n",
      "Iteration :  24200, Train reward: -14.047751966732509, Eval reward: 18.493076278569617, TD loss   : 25.09294746875763, Episode   :    210\n",
      "Iteration :  24300, Train reward: -14.047751966732509, Eval reward: 18.493076278569617, TD loss   : 21.963157596588136, Episode   :    210\n",
      "Iteration :  24400, Train reward: -14.047751966732509, Eval reward: 18.493076278569617, TD loss   : 22.937500149011612, Episode   :    210\n",
      "Iteration :  24500, Train reward: -12.923671269041648, Eval reward: -57.97366484673805, TD loss   : 34.553857811689376, Episode   :    211\n",
      "Iteration :  24600, Train reward: -15.911055667689974, Eval reward: -57.97366484673805, TD loss   : 27.342088590860367, Episode   :    212\n",
      "Iteration :  24700, Train reward: -15.911055667689974, Eval reward: -57.97366484673805, TD loss   : 23.744132311344146, Episode   :    212\n",
      "Iteration :  24800, Train reward: -15.911055667689974, Eval reward: -57.97366484673805, TD loss   : 21.831087461709977, Episode   :    212\n",
      "Iteration :  24900, Train reward: -15.281017170327114, Eval reward: -57.97366484673805, TD loss   : 22.34241159915924, Episode   :    214\n",
      "Iteration :  25000, Train reward: -15.281017170327114, Eval reward: -77.2703045347316, TD loss   : 24.416430864334107, Episode   :    214\n",
      "Iteration :  25100, Train reward: -10.195109489755144, Eval reward: -77.2703045347316, TD loss   : 37.98856167435646, Episode   :    215\n",
      "Iteration :  25200, Train reward: -10.195109489755144, Eval reward: -77.2703045347316, TD loss   : 23.6946017742157, Episode   :    215\n",
      "Iteration :  25300, Train reward: -10.195109489755144, Eval reward: -77.2703045347316, TD loss   : 14.277453968524933, Episode   :    215\n",
      "Iteration :  25400, Train reward: -8.437875455602782, Eval reward: -77.2703045347316, TD loss   : 20.794316873550414, Episode   :    216\n",
      "Iteration :  25500, Train reward: -8.437875455602782, Eval reward: -15.161184193359173, TD loss   : 22.064406682252883, Episode   :    216\n",
      "Iteration :  25600, Train reward: 0.7999360005633864, Eval reward: -15.161184193359173, TD loss   : 24.096063562631606, Episode   :    217\n",
      "Iteration :  25700, Train reward: 0.7999360005633864, Eval reward: -15.161184193359173, TD loss   : 23.249259022474288, Episode   :    217\n",
      "Iteration :  25800, Train reward: 0.7999360005633864, Eval reward: -15.161184193359173, TD loss   : 23.01999153971672, Episode   :    217\n",
      "Iteration :  25900, Train reward: 4.4587236264309045, Eval reward: -15.161184193359173, TD loss   : 15.56140829563141, Episode   :    218\n",
      "Iteration :  26000, Train reward: 4.4587236264309045, Eval reward: 4.5337957665490745, TD loss   : 25.9554436647892, Episode   :    218\n",
      "Iteration :  26100, Train reward: 8.988807718805651, Eval reward: 4.5337957665490745, TD loss   : 28.059935797452926, Episode   :    219\n",
      "Iteration :  26200, Train reward: 8.988807718805651, Eval reward: 4.5337957665490745, TD loss   : 23.306280117034913, Episode   :    219\n",
      "Iteration :  26300, Train reward: 10.792029530841637, Eval reward: 4.5337957665490745, TD loss   : 29.33026424884796, Episode   :    220\n",
      "Iteration :  26400, Train reward: 10.792029530841637, Eval reward: 4.5337957665490745, TD loss   : 17.842798508405686, Episode   :    220\n",
      "Iteration :  26500, Train reward: 10.792029530841637, Eval reward: -155.92239736712196, TD loss   : 21.57533648133278, Episode   :    220\n",
      "Iteration :  26600, Train reward: 12.988727141278392, Eval reward: -155.92239736712196, TD loss   : 31.65870890259743, Episode   :    221\n",
      "Iteration :  26700, Train reward: 15.590185379619314, Eval reward: -155.92239736712196, TD loss   : 32.166304923295975, Episode   :    222\n",
      "Iteration :  26800, Train reward: 15.590185379619314, Eval reward: -155.92239736712196, TD loss   : 20.27285561323166, Episode   :    222\n",
      "Iteration :  26900, Train reward: 15.590185379619314, Eval reward: -155.92239736712196, TD loss   : 20.013631422519683, Episode   :    222\n",
      "Iteration :  27000, Train reward: 14.76335984946516, Eval reward: 9.344766037117466, TD loss   : 20.248774905204773, Episode   :    223\n",
      "Iteration :  27100, Train reward: 14.31449556274801, Eval reward: 9.344766037117466, TD loss   : 27.721799303293228, Episode   :    224\n",
      "Iteration :  27200, Train reward: 14.31449556274801, Eval reward: 9.344766037117466, TD loss   : 31.69445760011673, Episode   :    224\n",
      "Iteration :  27300, Train reward: 14.31449556274801, Eval reward: 9.344766037117466, TD loss   : 31.599228065013886, Episode   :    224\n",
      "Iteration :  27400, Train reward: 23.14571093703001, Eval reward: 9.344766037117466, TD loss   : 14.142607640028, Episode   :    225\n",
      "Iteration :  27500, Train reward: 25.072545850776436, Eval reward: -6.094711307129742, TD loss   : 33.92893102645874, Episode   :    226\n",
      "Iteration :  27600, Train reward: 24.914349612385926, Eval reward: -6.094711307129742, TD loss   : 28.74620040655136, Episode   :    227\n",
      "Iteration :  27700, Train reward: 28.269129371477767, Eval reward: -6.094711307129742, TD loss   : 23.532333750724792, Episode   :    228\n",
      "Iteration :  27800, Train reward: 28.269129371477767, Eval reward: -6.094711307129742, TD loss   : 32.01720497727394, Episode   :    228\n",
      "Iteration :  27900, Train reward: 28.269129371477767, Eval reward: -6.094711307129742, TD loss   : 17.35234119772911, Episode   :    228\n",
      "Iteration :  28000, Train reward: 24.51984766543863, Eval reward: -594.8409743642791, TD loss   : 27.901144709587097, Episode   :    229\n",
      "Iteration :  28100, Train reward: 20.033380947989624, Eval reward: -594.8409743642791, TD loss   : 26.434340139627455, Episode   :    230\n",
      "Iteration :  28200, Train reward: 20.033380947989624, Eval reward: -594.8409743642791, TD loss   : 23.043486833572388, Episode   :    230\n",
      "Iteration :  28300, Train reward: 20.033380947989624, Eval reward: -594.8409743642791, TD loss   : 25.396514912843703, Episode   :    230\n",
      "Iteration :  28400, Train reward: 21.951537829525698, Eval reward: -594.8409743642791, TD loss   : 23.011115311384202, Episode   :    231\n",
      "Iteration :  28500, Train reward: 21.951537829525698, Eval reward: 21.496681589422558, TD loss   : 22.03336244225502, Episode   :    231\n",
      "Iteration :  28600, Train reward: 23.528474595960905, Eval reward: 21.496681589422558, TD loss   : 33.85654997229576, Episode   :    232\n",
      "Iteration :  28700, Train reward: 23.528474595960905, Eval reward: 21.496681589422558, TD loss   : 18.93859210729599, Episode   :    232\n",
      "Iteration :  28800, Train reward: 23.528474595960905, Eval reward: 21.496681589422558, TD loss   : 21.685141338706018, Episode   :    232\n",
      "Iteration :  28900, Train reward: 25.782722577435152, Eval reward: 21.496681589422558, TD loss   : 19.36939769744873, Episode   :    233\n",
      "Iteration :  29000, Train reward: 25.782722577435152, Eval reward: -37.49701656053831, TD loss   : 24.215181368589402, Episode   :    233\n",
      "Iteration :  29100, Train reward: 27.812285185584262, Eval reward: -37.49701656053831, TD loss   : 30.1772949385643, Episode   :    234\n",
      "Iteration :  29200, Train reward: 27.812285185584262, Eval reward: -37.49701656053831, TD loss   : 17.60015207529068, Episode   :    234\n",
      "Iteration :  29300, Train reward: 27.812285185584262, Eval reward: -37.49701656053831, TD loss   : 17.8740304094553, Episode   :    234\n",
      "Iteration :  29400, Train reward: 26.19601290920817, Eval reward: -37.49701656053831, TD loss   : 20.716581892967223, Episode   :    235\n",
      "Iteration :  29500, Train reward: 26.19601290920817, Eval reward: 8.24976664961113, TD loss   : 19.92650137066841, Episode   :    235\n",
      "Iteration :  29600, Train reward: 33.26982723380364, Eval reward: 8.24976664961113, TD loss   : 23.495785855054855, Episode   :    236\n",
      "Iteration :  29700, Train reward: 33.26982723380364, Eval reward: 8.24976664961113, TD loss   : 22.160283809900285, Episode   :    236\n",
      "Iteration :  29800, Train reward: 33.26982723380364, Eval reward: 8.24976664961113, TD loss   : 31.932804177999497, Episode   :    236\n",
      "Iteration :  29900, Train reward: 30.33408230359105, Eval reward: 8.24976664961113, TD loss   : 32.633458044528965, Episode   :    237\n",
      "Iteration :  30000, Train reward: 30.33408230359105, Eval reward: -13.677371192262523, TD loss   : 19.408373767137526, Episode   :    237\n",
      "Iteration :  30100, Train reward: 29.513110197825103, Eval reward: -13.677371192262523, TD loss   : 26.75159187078476, Episode   :    238\n",
      "Iteration :  30200, Train reward: 29.513110197825103, Eval reward: -13.677371192262523, TD loss   : 26.40080642938614, Episode   :    238\n",
      "Iteration :  30300, Train reward: 29.513110197825103, Eval reward: -13.677371192262523, TD loss   : 23.752617835998535, Episode   :    238\n",
      "Iteration :  30400, Train reward: 32.500236382166996, Eval reward: -13.677371192262523, TD loss   : 20.41590501189232, Episode   :    239\n",
      "Iteration :  30500, Train reward: 32.500236382166996, Eval reward: -7.6129269515266715, TD loss   : 23.112722849845888, Episode   :    239\n",
      "Iteration :  30600, Train reward: 31.57633632029303, Eval reward: -7.6129269515266715, TD loss   : 26.519348515272142, Episode   :    240\n",
      "Iteration :  30700, Train reward: 31.57633632029303, Eval reward: -7.6129269515266715, TD loss   : 22.22627383351326, Episode   :    240\n",
      "Iteration :  30800, Train reward: 31.57633632029303, Eval reward: -7.6129269515266715, TD loss   : 18.541483101844786, Episode   :    240\n",
      "Iteration :  30900, Train reward: 28.751746130145523, Eval reward: -7.6129269515266715, TD loss   : 14.349444724321366, Episode   :    241\n",
      "Iteration :  31000, Train reward: 28.751746130145523, Eval reward: -75.00861956380525, TD loss   : 20.969580436944963, Episode   :    241\n",
      "Iteration :  31100, Train reward: 27.469967331104847, Eval reward: -75.00861956380525, TD loss   : 19.721911355257035, Episode   :    242\n",
      "Iteration :  31200, Train reward: 28.764352538837365, Eval reward: -75.00861956380525, TD loss   : 24.355132038593293, Episode   :    243\n",
      "Iteration :  31300, Train reward: 28.764352538837365, Eval reward: -75.00861956380525, TD loss   : 18.623664380311965, Episode   :    243\n",
      "Iteration :  31400, Train reward: 28.764352538837365, Eval reward: -75.00861956380525, TD loss   : 23.1680144906044, Episode   :    243\n",
      "Iteration :  31500, Train reward: 26.30642728354234, Eval reward: -6.700124467834939, TD loss   : 19.31647996544838, Episode   :    244\n",
      "Iteration :  31600, Train reward: 19.215476463337335, Eval reward: -6.700124467834939, TD loss   : 18.202623759508132, Episode   :    246\n",
      "Iteration :  31700, Train reward: 19.215476463337335, Eval reward: -6.700124467834939, TD loss   : 23.87818200945854, Episode   :    246\n",
      "Iteration :  31800, Train reward: 19.215476463337335, Eval reward: -6.700124467834939, TD loss   : 24.37085891723633, Episode   :    246\n",
      "Iteration :  31900, Train reward: 18.37907519452971, Eval reward: -6.700124467834939, TD loss   : 30.467214970588685, Episode   :    247\n",
      "Iteration :  32000, Train reward: 18.37907519452971, Eval reward: -20.16756844195948, TD loss   : 20.793690962791445, Episode   :    247\n",
      "Iteration :  32100, Train reward: 18.577506269546724, Eval reward: -20.16756844195948, TD loss   : 18.752633332014085, Episode   :    248\n",
      "Iteration :  32200, Train reward: 18.577506269546724, Eval reward: -20.16756844195948, TD loss   : 17.29591992855072, Episode   :    248\n",
      "Iteration :  32300, Train reward: 18.577506269546724, Eval reward: -20.16756844195948, TD loss   : 19.067916556596757, Episode   :    248\n",
      "Iteration :  32400, Train reward: 20.238780886745722, Eval reward: -20.16756844195948, TD loss   : 17.701972826719285, Episode   :    249\n",
      "Iteration :  32500, Train reward: 20.238780886745722, Eval reward: -20.10363167096454, TD loss   : 21.526270492076875, Episode   :    249\n",
      "Iteration :  32600, Train reward: 25.894775774379845, Eval reward: -20.10363167096454, TD loss   : 19.701795979738236, Episode   :    250\n",
      "Iteration :  32700, Train reward: 25.894775774379845, Eval reward: -20.10363167096454, TD loss   : 18.28277755737305, Episode   :    250\n",
      "Iteration :  32800, Train reward: 25.894775774379845, Eval reward: -20.10363167096454, TD loss   : 19.72647353887558, Episode   :    250\n",
      "Iteration :  32900, Train reward: 26.814029242210303, Eval reward: -20.10363167096454, TD loss   : 26.41131771802902, Episode   :    251\n",
      "Iteration :  33000, Train reward: 26.814029242210303, Eval reward: 5.504539176029759, TD loss   : 19.298122565746308, Episode   :    251\n",
      "Iteration :  33100, Train reward: 26.662720804289915, Eval reward: 5.504539176029759, TD loss   : 18.072036867141723, Episode   :    252\n",
      "Iteration :  33200, Train reward: 26.662720804289915, Eval reward: 5.504539176029759, TD loss   : 16.765162113904953, Episode   :    252\n",
      "Iteration :  33300, Train reward: 26.662720804289915, Eval reward: 5.504539176029759, TD loss   : 18.241473809480667, Episode   :    252\n",
      "Iteration :  33400, Train reward: 23.657509174443014, Eval reward: 5.504539176029759, TD loss   : 18.634085426330568, Episode   :    253\n",
      "Iteration :  33500, Train reward: 23.657509174443014, Eval reward: 5.154876025902391, TD loss   : 27.081510350704193, Episode   :    253\n",
      "Iteration :  33600, Train reward: 22.1092402874744, Eval reward: 5.154876025902391, TD loss   : 24.571256464719774, Episode   :    254\n",
      "Iteration :  33700, Train reward: 14.494902629242432, Eval reward: 5.154876025902391, TD loss   : 16.483060606718063, Episode   :    255\n",
      "Iteration :  33800, Train reward: 14.494902629242432, Eval reward: 5.154876025902391, TD loss   : 18.243338327407837, Episode   :    255\n",
      "Iteration :  33900, Train reward: 14.494902629242432, Eval reward: 5.154876025902391, TD loss   : 24.168038297891616, Episode   :    255\n",
      "Iteration :  34000, Train reward: 5.048112066165348, Eval reward: -0.7465043097983465, TD loss   : 19.512468135356904, Episode   :    256\n",
      "Iteration :  34100, Train reward: 12.095386703008256, Eval reward: -0.7465043097983465, TD loss   : 22.85417217493057, Episode   :    257\n",
      "Iteration :  34200, Train reward: 12.095386703008256, Eval reward: -0.7465043097983465, TD loss   : 18.577167801856994, Episode   :    257\n",
      "Iteration :  34300, Train reward: 12.095386703008256, Eval reward: -0.7465043097983465, TD loss   : 19.395980657339095, Episode   :    257\n",
      "Iteration :  34400, Train reward: 6.690281110274566, Eval reward: -0.7465043097983465, TD loss   : 21.886742082834242, Episode   :    258\n",
      "Iteration :  34500, Train reward: 6.690281110274566, Eval reward: -3.1885928391018643, TD loss   : 24.301874438524248, Episode   :    258\n",
      "Iteration :  34600, Train reward: 2.4186651223065665, Eval reward: -3.1885928391018643, TD loss   : 23.852920997142792, Episode   :    259\n",
      "Iteration :  34700, Train reward: 2.4186651223065665, Eval reward: -3.1885928391018643, TD loss   : 34.527105717659, Episode   :    259\n",
      "Iteration :  34800, Train reward: 2.4186651223065665, Eval reward: -3.1885928391018643, TD loss   : 22.58680639266968, Episode   :    259\n",
      "Iteration :  34900, Train reward: 4.23145499887975, Eval reward: -3.1885928391018643, TD loss   : 21.423136152029038, Episode   :    260\n",
      "Iteration :  35000, Train reward: 4.23145499887975, Eval reward: -14.236886388309822, TD loss   : 25.438926116228103, Episode   :    260\n",
      "Iteration :  35100, Train reward: 8.177061373884234, Eval reward: -14.236886388309822, TD loss   : 19.3686597430706, Episode   :    261\n",
      "Iteration :  35200, Train reward: 8.177061373884234, Eval reward: -14.236886388309822, TD loss   : 18.672435059547425, Episode   :    261\n",
      "Iteration :  35300, Train reward: 8.177061373884234, Eval reward: -14.236886388309822, TD loss   : 20.428900277614595, Episode   :    261\n",
      "Iteration :  35400, Train reward: 8.785137270811408, Eval reward: -14.236886388309822, TD loss   : 17.941408236026763, Episode   :    262\n",
      "Iteration :  35500, Train reward: 8.785137270811408, Eval reward: -12.625852529722687, TD loss   : 29.01039900779724, Episode   :    262\n",
      "Iteration :  35600, Train reward: 9.541653242111785, Eval reward: -12.625852529722687, TD loss   : 19.681713790893554, Episode   :    263\n",
      "Iteration :  35700, Train reward: 9.541653242111785, Eval reward: -12.625852529722687, TD loss   : 19.524116278886794, Episode   :    263\n",
      "Iteration :  35800, Train reward: 9.541653242111785, Eval reward: -12.625852529722687, TD loss   : 20.680392739772795, Episode   :    263\n",
      "Iteration :  35900, Train reward: 10.715518861944604, Eval reward: -12.625852529722687, TD loss   : 25.68114889740944, Episode   :    264\n",
      "Iteration :  36000, Train reward: 10.715518861944604, Eval reward: 24.913776862366667, TD loss   : 18.96247950553894, Episode   :    264\n",
      "Iteration :  36100, Train reward: 12.912755029281865, Eval reward: 24.913776862366667, TD loss   : 23.14958304286003, Episode   :    265\n",
      "Iteration :  36200, Train reward: 12.912755029281865, Eval reward: 24.913776862366667, TD loss   : 23.58514012694359, Episode   :    265\n",
      "Iteration :  36300, Train reward: 12.912755029281865, Eval reward: 24.913776862366667, TD loss   : 25.72042758345604, Episode   :    265\n",
      "Iteration :  36400, Train reward: 17.005425934258053, Eval reward: 24.913776862366667, TD loss   : 22.614814200401305, Episode   :    266\n",
      "Iteration :  36500, Train reward: 17.005425934258053, Eval reward: -9.973953359454976, TD loss   : 21.038764935731887, Episode   :    266\n",
      "Iteration :  36600, Train reward: 20.160150557747023, Eval reward: -9.973953359454976, TD loss   : 18.69403779387474, Episode   :    267\n",
      "Iteration :  36700, Train reward: 20.160150557747023, Eval reward: -9.973953359454976, TD loss   : 19.241822518110276, Episode   :    267\n",
      "Iteration :  36800, Train reward: 20.160150557747023, Eval reward: -9.973953359454976, TD loss   : 15.316863683462143, Episode   :    267\n",
      "Iteration :  36900, Train reward: 17.38679242154313, Eval reward: -9.973953359454976, TD loss   : 17.84585593819618, Episode   :    268\n",
      "Iteration :  37000, Train reward: 17.38679242154313, Eval reward: 10.93108748328524, TD loss   : 17.27379525780678, Episode   :    268\n",
      "Iteration :  37100, Train reward: 16.667413030944637, Eval reward: 10.93108748328524, TD loss   : 20.624573950767516, Episode   :    269\n",
      "Iteration :  37200, Train reward: 16.667413030944637, Eval reward: 10.93108748328524, TD loss   : 25.67928808569908, Episode   :    269\n",
      "Iteration :  37300, Train reward: 16.667413030944637, Eval reward: 10.93108748328524, TD loss   : 17.30197696685791, Episode   :    269\n",
      "Iteration :  37400, Train reward: 19.579187799380733, Eval reward: 10.93108748328524, TD loss   : 20.309417548179628, Episode   :    270\n",
      "Iteration :  37500, Train reward: 19.579187799380733, Eval reward: -7.453589406256445, TD loss   : 17.667903389930725, Episode   :    270\n",
      "Iteration :  37600, Train reward: 19.83373060893065, Eval reward: -7.453589406256445, TD loss   : 13.50178896546364, Episode   :    271\n",
      "Iteration :  37700, Train reward: 19.83373060893065, Eval reward: -7.453589406256445, TD loss   : 20.911969344615937, Episode   :    271\n",
      "Iteration :  37800, Train reward: 19.83373060893065, Eval reward: -7.453589406256445, TD loss   : 18.026265363693238, Episode   :    271\n",
      "Iteration :  37900, Train reward: 17.369706806677332, Eval reward: -7.453589406256445, TD loss   : 17.99535949587822, Episode   :    272\n",
      "Iteration :  38000, Train reward: 17.369706806677332, Eval reward: 42.93676636788656, TD loss   : 31.51917815685272, Episode   :    272\n",
      "Iteration :  38100, Train reward: 17.718760892494185, Eval reward: 42.93676636788656, TD loss   : 20.44507227897644, Episode   :    273\n",
      "Iteration :  38200, Train reward: 17.718760892494185, Eval reward: 42.93676636788656, TD loss   : 25.383904156684874, Episode   :    273\n",
      "Iteration :  38300, Train reward: 17.718760892494185, Eval reward: 42.93676636788656, TD loss   : 18.77829015851021, Episode   :    273\n",
      "Iteration :  38400, Train reward: 19.166278479271917, Eval reward: 42.93676636788656, TD loss   : 15.70151264309883, Episode   :    274\n",
      "Iteration :  38500, Train reward: 19.166278479271917, Eval reward: 27.656805697461202, TD loss   : 17.142865277528763, Episode   :    274\n",
      "Iteration :  38600, Train reward: 26.141226104793805, Eval reward: 27.656805697461202, TD loss   : 20.945792050361632, Episode   :    275\n",
      "Iteration :  38700, Train reward: 26.141226104793805, Eval reward: 27.656805697461202, TD loss   : 15.653800331354141, Episode   :    275\n",
      "Iteration :  38800, Train reward: 26.141226104793805, Eval reward: 27.656805697461202, TD loss   : 21.71389783024788, Episode   :    275\n",
      "Iteration :  38900, Train reward: 27.69913425674013, Eval reward: 27.656805697461202, TD loss   : 22.47430490374565, Episode   :    276\n",
      "Iteration :  39000, Train reward: 27.69913425674013, Eval reward: -69.79221608191847, TD loss   : 21.133744611740113, Episode   :    276\n",
      "Iteration :  39100, Train reward: 22.190059304673774, Eval reward: -69.79221608191847, TD loss   : 21.681336246728897, Episode   :    277\n",
      "Iteration :  39200, Train reward: 22.190059304673774, Eval reward: -69.79221608191847, TD loss   : 22.64796679973602, Episode   :    277\n",
      "Iteration :  39300, Train reward: 22.190059304673774, Eval reward: -69.79221608191847, TD loss   : 20.480263061523438, Episode   :    277\n",
      "Iteration :  39400, Train reward: 25.068514090410485, Eval reward: -69.79221608191847, TD loss   : 32.582609933614734, Episode   :    278\n",
      "Iteration :  39500, Train reward: 25.068514090410485, Eval reward: 18.390073350227212, TD loss   : 20.145106868743895, Episode   :    278\n",
      "Iteration :  39600, Train reward: 26.08019602563769, Eval reward: 18.390073350227212, TD loss   : 17.049919928312303, Episode   :    279\n",
      "Iteration :  39700, Train reward: 26.08019602563769, Eval reward: 18.390073350227212, TD loss   : 15.605742629766464, Episode   :    279\n",
      "Iteration :  39800, Train reward: 26.08019602563769, Eval reward: 18.390073350227212, TD loss   : 12.145642811059952, Episode   :    279\n",
      "Iteration :  39900, Train reward: 25.40295315542331, Eval reward: 18.390073350227212, TD loss   : 17.025023247003556, Episode   :    280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HasanErdin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\HasanErdin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :      0, Train reward:    nan, Eval reward: -677.0891855900886, TD loss   :    nan, Episode   :      0\n",
      "Iteration :    100, Train reward: -102.57442695483869, Eval reward: -677.0891855900886, TD loss   : 158.17340087890625, Episode   :      2\n",
      "Iteration :    200, Train reward: -129.12136939701574, Eval reward: -677.0891855900886, TD loss   : 160.69048428416252, Episode   :      3\n",
      "Iteration :    300, Train reward: -161.72066548235824, Eval reward: -677.0891855900886, TD loss   : 102.66026482820511, Episode   :      4\n",
      "Iteration :    400, Train reward: -148.3878444158402, Eval reward: -677.0891855900886, TD loss   : 128.36060485601425, Episode   :      5\n",
      "Iteration :    500, Train reward: -166.15450373923133, Eval reward: -660.8292024360962, TD loss   : 92.2274450969696, Episode   :      6\n",
      "Iteration :    600, Train reward: -177.39533581979862, Eval reward: -660.8292024360962, TD loss   : 85.8929300904274, Episode   :      8\n",
      "Iteration :    700, Train reward: -177.39533581979862, Eval reward: -660.8292024360962, TD loss   : 74.85326575040817, Episode   :      8\n",
      "Iteration :    800, Train reward: -159.4607178652737, Eval reward: -660.8292024360962, TD loss   : 83.30059949398041, Episode   :     10\n",
      "Iteration :    900, Train reward: -149.36556568175502, Eval reward: -660.8292024360962, TD loss   : 67.57894438743591, Episode   :     11\n",
      "Iteration :   1000, Train reward: -148.69686260968513, Eval reward: -149.74258132395966, TD loss   : 58.232430999279025, Episode   :     12\n",
      "Iteration :   1100, Train reward: -139.84068523324055, Eval reward: -149.74258132395966, TD loss   : 53.58809094905853, Episode   :     13\n",
      "Iteration :   1200, Train reward: -140.69510401573956, Eval reward: -149.74258132395966, TD loss   : 52.07356634736061, Episode   :     14\n",
      "Iteration :   1300, Train reward: -130.95274117115588, Eval reward: -149.74258132395966, TD loss   : 55.772901318073274, Episode   :     15\n",
      "Iteration :   1400, Train reward: -126.51870782021317, Eval reward: -149.74258132395966, TD loss   : 49.78483148097992, Episode   :     16\n",
      "Iteration :   1500, Train reward: -145.16672138451864, Eval reward: -387.9964679088168, TD loss   : 54.46572021842003, Episode   :     17\n",
      "Iteration :   1600, Train reward: -142.68524270154583, Eval reward: -387.9964679088168, TD loss   : 58.765330817699436, Episode   :     18\n",
      "Iteration :   1700, Train reward: -160.29108063295774, Eval reward: -387.9964679088168, TD loss   : 58.535821504592896, Episode   :     19\n",
      "Iteration :   1800, Train reward: -164.27674728383437, Eval reward: -387.9964679088168, TD loss   : 65.93482835054398, Episode   :     20\n",
      "Iteration :   1900, Train reward: -169.73659517779402, Eval reward: -387.9964679088168, TD loss   : 52.551557779312134, Episode   :     22\n",
      "Iteration :   2000, Train reward: -165.80074571792437, Eval reward: -308.779970591228, TD loss   : 53.29632136940956, Episode   :     23\n",
      "Iteration :   2100, Train reward: -160.01311779052875, Eval reward: -308.779970591228, TD loss   : 44.025671529769895, Episode   :     24\n",
      "Iteration :   2200, Train reward: -151.6074434643425, Eval reward: -308.779970591228, TD loss   : 53.7418062543869, Episode   :     26\n",
      "Iteration :   2300, Train reward: -151.6074434643425, Eval reward: -308.779970591228, TD loss   : 59.17055519342423, Episode   :     26\n",
      "Iteration :   2400, Train reward: -149.09941693167548, Eval reward: -308.779970591228, TD loss   : 62.56763306379318, Episode   :     27\n",
      "Iteration :   2500, Train reward: -140.74639917678923, Eval reward: -181.71209007738207, TD loss   : 51.2941983628273, Episode   :     28\n",
      "Iteration :   2600, Train reward: -140.8930848320391, Eval reward: -181.71209007738207, TD loss   : 62.65056961774826, Episode   :     30\n",
      "Iteration :   2700, Train reward: -143.00437110420583, Eval reward: -181.71209007738207, TD loss   : 71.49158608436585, Episode   :     31\n",
      "Iteration :   2800, Train reward: -142.87004488858094, Eval reward: -181.71209007738207, TD loss   : 59.70031074762344, Episode   :     32\n",
      "Iteration :   2900, Train reward: -148.17716500133858, Eval reward: -181.71209007738207, TD loss   : 65.14374519586563, Episode   :     33\n",
      "Iteration :   3000, Train reward: -145.52108511290476, Eval reward: -222.5519757566239, TD loss   : 36.45800177335739, Episode   :     34\n",
      "Iteration :   3100, Train reward: -158.5607915895691, Eval reward: -222.5519757566239, TD loss   : 60.26094496011734, Episode   :     36\n",
      "Iteration :   3200, Train reward: -141.88375356687652, Eval reward: -222.5519757566239, TD loss   : 58.90907287359238, Episode   :     37\n",
      "Iteration :   3300, Train reward: -141.9799202846039, Eval reward: -222.5519757566239, TD loss   : 60.08453145503998, Episode   :     38\n",
      "Iteration :   3400, Train reward: -123.77899350727225, Eval reward: -222.5519757566239, TD loss   : 54.9708469414711, Episode   :     39\n",
      "Iteration :   3500, Train reward: -117.79318981707316, Eval reward: -150.0662531492606, TD loss   : 54.670040645599364, Episode   :     40\n",
      "Iteration :   3600, Train reward: -116.85452439151614, Eval reward: -150.0662531492606, TD loss   : 55.61491706132889, Episode   :     41\n",
      "Iteration :   3700, Train reward: -109.1962688276047, Eval reward: -150.0662531492606, TD loss   : 51.906097531318665, Episode   :     42\n",
      "Iteration :   3800, Train reward: -113.25574916879422, Eval reward: -150.0662531492606, TD loss   : 44.55698337316513, Episode   :     43\n",
      "Iteration :   3900, Train reward: -107.35144984872029, Eval reward: -150.0662531492606, TD loss   : 58.75410768270493, Episode   :     44\n",
      "Iteration :   4000, Train reward: -112.67321405396395, Eval reward: -265.27237633225957, TD loss   : 45.39907834768295, Episode   :     45\n",
      "Iteration :   4100, Train reward: -116.17831879040038, Eval reward: -265.27237633225957, TD loss   : 75.17251878738404, Episode   :     47\n",
      "Iteration :   4200, Train reward: -115.53307193604226, Eval reward: -265.27237633225957, TD loss   : 64.2622406232357, Episode   :     48\n",
      "Iteration :   4300, Train reward: -117.42106351864888, Eval reward: -265.27237633225957, TD loss   : 49.07404970407486, Episode   :     49\n",
      "Iteration :   4400, Train reward: -114.35090425216599, Eval reward: -265.27237633225957, TD loss   : 54.48429006576538, Episode   :     50\n",
      "Iteration :   4500, Train reward: -114.35090425216599, Eval reward: -140.52956361970757, TD loss   : 53.458315670490265, Episode   :     50\n",
      "Iteration :   4600, Train reward: -116.87221784414814, Eval reward: -140.52956361970757, TD loss   : 47.45368868708611, Episode   :     51\n",
      "Iteration :   4700, Train reward: -120.78610256924237, Eval reward: -140.52956361970757, TD loss   : 74.63357259631157, Episode   :     52\n",
      "Iteration :   4800, Train reward: -120.54878454528357, Eval reward: -140.52956361970757, TD loss   : 54.803595690727235, Episode   :     53\n",
      "Iteration :   4900, Train reward: -119.48190801679, Eval reward: -140.52956361970757, TD loss   : 57.10286499023437, Episode   :     54\n",
      "Iteration :   5000, Train reward: -110.34082000320689, Eval reward: -185.01532758935437, TD loss   : 51.50295884013176, Episode   :     55\n",
      "Iteration :   5100, Train reward: -109.54093774293395, Eval reward: -185.01532758935437, TD loss   : 61.26356117725372, Episode   :     56\n",
      "Iteration :   5200, Train reward: -109.4174392995803, Eval reward: -185.01532758935437, TD loss   : 50.7787467288971, Episode   :     57\n",
      "Iteration :   5300, Train reward: -109.10715940045483, Eval reward: -185.01532758935437, TD loss   : 58.21128793716431, Episode   :     58\n",
      "Iteration :   5400, Train reward: -118.45806445900958, Eval reward: -185.01532758935437, TD loss   : 55.74025612831116, Episode   :     59\n",
      "Iteration :   5500, Train reward: -121.41667153445162, Eval reward: -458.1453053722004, TD loss   : 55.4790994656086, Episode   :     60\n",
      "Iteration :   5600, Train reward: -125.46006207053979, Eval reward: -458.1453053722004, TD loss   : 43.11998390197754, Episode   :     61\n",
      "Iteration :   5700, Train reward: -123.2176345294735, Eval reward: -458.1453053722004, TD loss   : 47.23543053507805, Episode   :     62\n",
      "Iteration :   5800, Train reward: -119.72242873178512, Eval reward: -458.1453053722004, TD loss   : 72.03933435559273, Episode   :     63\n",
      "Iteration :   5900, Train reward: -134.75650248538773, Eval reward: -458.1453053722004, TD loss   : 65.03150618076324, Episode   :     64\n",
      "Iteration :   6000, Train reward: -134.75650248538773, Eval reward: -426.27617209518195, TD loss   : 57.02127061605454, Episode   :     64\n",
      "Iteration :   6100, Train reward: -129.20988699456413, Eval reward: -426.27617209518195, TD loss   : 59.436163996458056, Episode   :     65\n",
      "Iteration :   6200, Train reward: -128.9991762578792, Eval reward: -426.27617209518195, TD loss   : 48.25629376292229, Episode   :     66\n",
      "Iteration :   6300, Train reward: -129.89755010174457, Eval reward: -426.27617209518195, TD loss   : 44.594290709495546, Episode   :     68\n",
      "Iteration :   6400, Train reward: -129.89755010174457, Eval reward: -426.27617209518195, TD loss   : 53.501887466907505, Episode   :     68\n",
      "Iteration :   6500, Train reward: -125.16758003967198, Eval reward: -436.10095308310156, TD loss   : 52.805635154247284, Episode   :     69\n",
      "Iteration :   6600, Train reward: -129.39642617460498, Eval reward: -436.10095308310156, TD loss   : 37.88356035709381, Episode   :     70\n",
      "Iteration :   6700, Train reward: -128.65664614633562, Eval reward: -436.10095308310156, TD loss   : 54.268295047283175, Episode   :     71\n",
      "Iteration :   6800, Train reward: -117.11274747455305, Eval reward: -436.10095308310156, TD loss   : 49.74679545760155, Episode   :     72\n",
      "Iteration :   6900, Train reward: -123.67342245573965, Eval reward: -436.10095308310156, TD loss   : 53.47323821663856, Episode   :     73\n",
      "Iteration :   7000, Train reward: -125.2037884336693, Eval reward: -46.57816515184703, TD loss   : 59.77781895518303, Episode   :     74\n",
      "Iteration :   7100, Train reward: -123.83062015133058, Eval reward: -46.57816515184703, TD loss   : 48.7225634598732, Episode   :     75\n",
      "Iteration :   7200, Train reward: -132.08079608509863, Eval reward: -46.57816515184703, TD loss   : 49.747463876008986, Episode   :     77\n",
      "Iteration :   7300, Train reward: -132.08079608509863, Eval reward: -46.57816515184703, TD loss   : 47.33743924260139, Episode   :     77\n",
      "Iteration :   7400, Train reward: -130.90971788937105, Eval reward: -46.57816515184703, TD loss   : 54.73639449834823, Episode   :     78\n",
      "Iteration :   7500, Train reward: -120.48809754544463, Eval reward: -39.05788082447527, TD loss   : 57.836095176935196, Episode   :     79\n",
      "Iteration :   7600, Train reward: -113.49966187499186, Eval reward: -39.05788082447527, TD loss   : 46.872556546926496, Episode   :     81\n",
      "Iteration :   7700, Train reward: -113.49966187499186, Eval reward: -39.05788082447527, TD loss   : 56.568720030784604, Episode   :     81\n",
      "Iteration :   7800, Train reward: -115.57916685966202, Eval reward: -39.05788082447527, TD loss   : 38.76094926714897, Episode   :     82\n",
      "Iteration :   7900, Train reward: -100.50795868275009, Eval reward: -39.05788082447527, TD loss   : 43.436990311145784, Episode   :     84\n",
      "Iteration :   8000, Train reward: -100.50795868275009, Eval reward: -35.98425733118379, TD loss   : 46.498811876773836, Episode   :     84\n",
      "Iteration :   8100, Train reward: -101.79069928130318, Eval reward: -35.98425733118379, TD loss   : 49.6341279554367, Episode   :     85\n",
      "Iteration :   8200, Train reward: -96.77805321173742, Eval reward: -35.98425733118379, TD loss   : 42.649343425035475, Episode   :     86\n",
      "Iteration :   8300, Train reward: -98.34330955793132, Eval reward: -35.98425733118379, TD loss   : 65.62469064950943, Episode   :     87\n",
      "Iteration :   8400, Train reward: -99.0764039099878, Eval reward: -35.98425733118379, TD loss   : 51.695442054271695, Episode   :     88\n",
      "Iteration :   8500, Train reward: -100.05061203671212, Eval reward: -70.51116014801387, TD loss   : 44.01048892974853, Episode   :     89\n",
      "Iteration :   8600, Train reward: -96.92230069013755, Eval reward: -70.51116014801387, TD loss   : 36.37608943343162, Episode   :     90\n",
      "Iteration :   8700, Train reward: -99.87042465889388, Eval reward: -70.51116014801387, TD loss   : 45.52954300522804, Episode   :     91\n",
      "Iteration :   8800, Train reward: -113.93580645881143, Eval reward: -70.51116014801387, TD loss   : 34.395992785692215, Episode   :     92\n",
      "Iteration :   8900, Train reward: -104.87605387549254, Eval reward: -70.51116014801387, TD loss   : 41.70813386917114, Episode   :     93\n",
      "Iteration :   9000, Train reward: -99.93760348255765, Eval reward: 33.46231957062277, TD loss   : 41.524317007064816, Episode   :     94\n",
      "Iteration :   9100, Train reward: -89.52671973929354, Eval reward: 33.46231957062277, TD loss   : 55.00538292884826, Episode   :     96\n",
      "Iteration :   9200, Train reward: -89.52671973929354, Eval reward: 33.46231957062277, TD loss   : 44.2525504386425, Episode   :     96\n",
      "Iteration :   9300, Train reward: -88.86467169511374, Eval reward: 33.46231957062277, TD loss   : 38.74583173036575, Episode   :     98\n",
      "Iteration :   9400, Train reward: -88.86467169511374, Eval reward: 33.46231957062277, TD loss   : 45.10629018187523, Episode   :     98\n",
      "Iteration :   9500, Train reward: -87.6098769179803, Eval reward: -19.31669411102208, TD loss   : 38.31350387096405, Episode   :     99\n",
      "Iteration :   9600, Train reward: -89.96226837823856, Eval reward: -19.31669411102208, TD loss   : 32.455462819337846, Episode   :    101\n",
      "Iteration :   9700, Train reward: -89.96226837823856, Eval reward: -19.31669411102208, TD loss   : 48.588877856731415, Episode   :    101\n",
      "Iteration :   9800, Train reward: -86.39223428131638, Eval reward: -19.31669411102208, TD loss   : 33.678751044273376, Episode   :    102\n",
      "Iteration :   9900, Train reward: -89.01241495205659, Eval reward: -19.31669411102208, TD loss   : 39.72296516299248, Episode   :    104\n",
      "Iteration :  10000, Train reward: -101.88770409958472, Eval reward: 48.08922875189103, TD loss   : 35.858010449409484, Episode   :    105\n",
      "Iteration :  10100, Train reward: -98.3660858180146, Eval reward: 48.08922875189103, TD loss   : 48.979754378795626, Episode   :    106\n",
      "Iteration :  10200, Train reward: -99.41903599816472, Eval reward: 48.08922875189103, TD loss   : 50.81296782374382, Episode   :    107\n",
      "Iteration :  10300, Train reward: -99.85222526056415, Eval reward: 48.08922875189103, TD loss   : 29.974169303178787, Episode   :    108\n",
      "Iteration :  10400, Train reward: -105.37035495137675, Eval reward: 48.08922875189103, TD loss   : 43.72049532532692, Episode   :    109\n",
      "Iteration :  10500, Train reward: -107.30168736842802, Eval reward: -11.047398716996009, TD loss   : 34.47093636274338, Episode   :    110\n",
      "Iteration :  10600, Train reward: -87.80885148937986, Eval reward: -11.047398716996009, TD loss   : 51.98888083457947, Episode   :    112\n",
      "Iteration :  10700, Train reward: -89.02025623885284, Eval reward: -11.047398716996009, TD loss   : 41.21028146982193, Episode   :    113\n",
      "Iteration :  10800, Train reward: -89.02025623885284, Eval reward: -11.047398716996009, TD loss   : 40.97390257716179, Episode   :    113\n",
      "Iteration :  10900, Train reward: -91.26386948472668, Eval reward: -11.047398716996009, TD loss   : 37.16252539634704, Episode   :    114\n",
      "Iteration :  11000, Train reward: -96.3893410244249, Eval reward: -60.71557899803437, TD loss   : 32.39843371033668, Episode   :    115\n",
      "Iteration :  11100, Train reward: -91.22745015928464, Eval reward: -60.71557899803437, TD loss   : 42.86021322965622, Episode   :    116\n",
      "Iteration :  11200, Train reward: -99.29823194731264, Eval reward: -60.71557899803437, TD loss   : 40.00909727692604, Episode   :    117\n",
      "Iteration :  11300, Train reward: -100.69318847406569, Eval reward: -60.71557899803437, TD loss   : 40.82324890494347, Episode   :    118\n",
      "Iteration :  11400, Train reward: -100.6080142703148, Eval reward: -60.71557899803437, TD loss   : 37.185301579236985, Episode   :    119\n",
      "Iteration :  11500, Train reward: -100.6080142703148, Eval reward: -67.91271003462339, TD loss   : 40.734200546741484, Episode   :    119\n",
      "Iteration :  11600, Train reward: -95.79815459019328, Eval reward: -67.91271003462339, TD loss   : 39.08888983130455, Episode   :    121\n",
      "Iteration :  11700, Train reward: -96.4096745552377, Eval reward: -67.91271003462339, TD loss   : 35.681308244466784, Episode   :    122\n",
      "Iteration :  11800, Train reward: -96.4096745552377, Eval reward: -67.91271003462339, TD loss   : 35.032729432582855, Episode   :    122\n",
      "Iteration :  11900, Train reward: -106.11852250196921, Eval reward: -67.91271003462339, TD loss   : 21.36208835363388, Episode   :    123\n",
      "Iteration :  12000, Train reward: -113.41650717506619, Eval reward: 14.303200240037402, TD loss   : 40.23702049970627, Episode   :    124\n",
      "Iteration :  12100, Train reward: -98.15427624685839, Eval reward: 14.303200240037402, TD loss   : 33.249174416065216, Episode   :    126\n",
      "Iteration :  12200, Train reward: -98.95070660194575, Eval reward: 14.303200240037402, TD loss   : 37.21287351727486, Episode   :    127\n",
      "Iteration :  12300, Train reward: -98.95070660194575, Eval reward: 14.303200240037402, TD loss   : 29.470619543790818, Episode   :    127\n",
      "Iteration :  12400, Train reward: -97.56597250664353, Eval reward: 14.303200240037402, TD loss   : 26.241894688606262, Episode   :    128\n",
      "Iteration :  12500, Train reward: -92.44702920267959, Eval reward: 28.132256077967224, TD loss   : 29.718583360910415, Episode   :    129\n",
      "Iteration :  12600, Train reward: -88.90212615255703, Eval reward: 28.132256077967224, TD loss   : 35.422685605287555, Episode   :    130\n",
      "Iteration :  12700, Train reward: -90.19998921516768, Eval reward: 28.132256077967224, TD loss   : 42.783870338201524, Episode   :    131\n",
      "Iteration :  12800, Train reward: -90.19998921516768, Eval reward: 28.132256077967224, TD loss   : 22.76386200428009, Episode   :    131\n",
      "Iteration :  12900, Train reward: -93.67784941985323, Eval reward: 28.132256077967224, TD loss   : 44.269154235720634, Episode   :    132\n",
      "Iteration :  13000, Train reward: -93.67784941985323, Eval reward: 18.205198660996775, TD loss   : 44.08438608288765, Episode   :    132\n",
      "Iteration :  13100, Train reward: -90.76549942236532, Eval reward: 18.205198660996775, TD loss   : 29.52068990468979, Episode   :    134\n",
      "Iteration :  13200, Train reward: -90.76549942236532, Eval reward: 18.205198660996775, TD loss   : 33.73070582509041, Episode   :    134\n",
      "Iteration :  13300, Train reward: -86.19690737455993, Eval reward: 18.205198660996775, TD loss   : 35.27148557424545, Episode   :    135\n",
      "Iteration :  13400, Train reward: -88.180834080489, Eval reward: 18.205198660996775, TD loss   : 31.831042371988296, Episode   :    136\n",
      "Iteration :  13500, Train reward: -81.74683978483164, Eval reward: 13.095495949874362, TD loss   : 29.949088767766952, Episode   :    137\n",
      "Iteration :  13600, Train reward: -76.89722414492118, Eval reward: 13.095495949874362, TD loss   : 40.0255602657795, Episode   :    139\n",
      "Iteration :  13700, Train reward: -78.99438209998786, Eval reward: 13.095495949874362, TD loss   : 39.09669824004173, Episode   :    140\n",
      "Iteration :  13800, Train reward: -74.73296275032271, Eval reward: 13.095495949874362, TD loss   : 39.498492254018785, Episode   :    141\n",
      "Iteration :  13900, Train reward: -74.73296275032271, Eval reward: 13.095495949874362, TD loss   : 40.66218235254288, Episode   :    141\n",
      "Iteration :  14000, Train reward: -77.47138952184511, Eval reward: -6.174376073179889, TD loss   : 42.28931053638458, Episode   :    142\n",
      "Iteration :  14100, Train reward: -53.36454725737006, Eval reward: -6.174376073179889, TD loss   : 31.69758255004883, Episode   :    144\n",
      "Iteration :  14200, Train reward: -53.36454725737006, Eval reward: -6.174376073179889, TD loss   : 45.93334128379822, Episode   :    144\n",
      "Iteration :  14300, Train reward: -57.67853992868227, Eval reward: -6.174376073179889, TD loss   : 44.47045072555542, Episode   :    145\n",
      "Iteration :  14400, Train reward: -57.35790011906401, Eval reward: -6.174376073179889, TD loss   : 25.93919630885124, Episode   :    146\n",
      "Iteration :  14500, Train reward: -53.61234951669227, Eval reward: 24.839827385320653, TD loss   : 30.19323667526245, Episode   :    147\n",
      "Iteration :  14600, Train reward: -49.89203542153676, Eval reward: 24.839827385320653, TD loss   : 24.385240626335143, Episode   :    148\n",
      "Iteration :  14700, Train reward: -56.16493013232158, Eval reward: 24.839827385320653, TD loss   : 34.428183702230456, Episode   :    149\n",
      "Iteration :  14800, Train reward: -60.548808097920144, Eval reward: 24.839827385320653, TD loss   : 43.83567556977272, Episode   :    150\n",
      "Iteration :  14900, Train reward: -57.57743109608774, Eval reward: 24.839827385320653, TD loss   : 33.65669603765011, Episode   :    151\n",
      "Iteration :  15000, Train reward: -57.57743109608774, Eval reward: 3.0145769695771016, TD loss   : 28.09276749372482, Episode   :    151\n",
      "Iteration :  15100, Train reward: -52.63006361381122, Eval reward: 3.0145769695771016, TD loss   : 41.22190139532089, Episode   :    152\n",
      "Iteration :  15200, Train reward: -59.87425122368809, Eval reward: 3.0145769695771016, TD loss   : 39.16646248698235, Episode   :    153\n",
      "Iteration :  15300, Train reward: -53.68769129314718, Eval reward: 3.0145769695771016, TD loss   : 26.495545563697814, Episode   :    154\n",
      "Iteration :  15400, Train reward: -55.714478461932956, Eval reward: 3.0145769695771016, TD loss   : 29.126722464561464, Episode   :    155\n",
      "Iteration :  15500, Train reward: -55.496074204306225, Eval reward: -8.265725506366444, TD loss   : 37.75037661552429, Episode   :    156\n",
      "Iteration :  15600, Train reward: -50.45163810519245, Eval reward: -8.265725506366444, TD loss   : 34.83415328383446, Episode   :    157\n",
      "Iteration :  15700, Train reward: -51.51082782226066, Eval reward: -8.265725506366444, TD loss   : 38.04886208772659, Episode   :    158\n",
      "Iteration :  15800, Train reward: -51.51082782226066, Eval reward: -8.265725506366444, TD loss   : 20.711147856116295, Episode   :    158\n",
      "Iteration :  15900, Train reward: -51.51082782226066, Eval reward: -8.265725506366444, TD loss   : 40.61005625009537, Episode   :    158\n",
      "Iteration :  16000, Train reward: -50.684828537045256, Eval reward: -37.97437248302746, TD loss   : 28.142377108335495, Episode   :    160\n",
      "Iteration :  16100, Train reward: -51.155952353786205, Eval reward: -37.97437248302746, TD loss   : 28.009303567409514, Episode   :    161\n",
      "Iteration :  16200, Train reward: -45.96167351029743, Eval reward: -37.97437248302746, TD loss   : 38.15639907956123, Episode   :    162\n",
      "Iteration :  16300, Train reward: -45.96167351029743, Eval reward: -37.97437248302746, TD loss   : 41.826579966545104, Episode   :    162\n",
      "Iteration :  16400, Train reward: -45.96167351029743, Eval reward: -37.97437248302746, TD loss   : 35.87349058032036, Episode   :    162\n",
      "Iteration :  16500, Train reward: -40.14663218208801, Eval reward: 2.2178218786337824, TD loss   : 20.051052923202516, Episode   :    163\n",
      "Iteration :  16600, Train reward: -35.777580586155736, Eval reward: 2.2178218786337824, TD loss   : 26.64507474064827, Episode   :    164\n",
      "Iteration :  16700, Train reward: -33.8458710236198, Eval reward: 2.2178218786337824, TD loss   : 39.06548722624779, Episode   :    165\n",
      "Iteration :  16800, Train reward: -34.40551146592478, Eval reward: 2.2178218786337824, TD loss   : 39.90960441231728, Episode   :    166\n",
      "Iteration :  16900, Train reward: -34.40551146592478, Eval reward: 2.2178218786337824, TD loss   : 27.930386193990707, Episode   :    166\n",
      "Iteration :  17000, Train reward: -30.013851101093206, Eval reward: 30.349439638568413, TD loss   : 36.61456034660339, Episode   :    167\n",
      "Iteration :  17100, Train reward: -29.99130799515017, Eval reward: 30.349439638568413, TD loss   : 39.07787625670433, Episode   :    168\n",
      "Iteration :  17200, Train reward: -22.601119741758243, Eval reward: 30.349439638568413, TD loss   : 30.864552274942398, Episode   :    169\n",
      "Iteration :  17300, Train reward: -19.077003625358408, Eval reward: 30.349439638568413, TD loss   : 28.619584270715713, Episode   :    170\n",
      "Iteration :  17400, Train reward: -22.747364950877305, Eval reward: 30.349439638568413, TD loss   : 45.509799290895465, Episode   :    171\n",
      "Iteration :  17500, Train reward: -22.747364950877305, Eval reward: 24.927916765287243, TD loss   : 36.430507950782776, Episode   :    171\n",
      "Iteration :  17600, Train reward: -21.59422966399537, Eval reward: 24.927916765287243, TD loss   : 29.953037190437318, Episode   :    172\n",
      "Iteration :  17700, Train reward: -20.207457558430193, Eval reward: 24.927916765287243, TD loss   : 39.20461000442505, Episode   :    173\n",
      "Iteration :  17800, Train reward: -20.207457558430193, Eval reward: 24.927916765287243, TD loss   : 28.50399415373802, Episode   :    173\n",
      "Iteration :  17900, Train reward: -20.207457558430193, Eval reward: 24.927916765287243, TD loss   : 38.93649993419647, Episode   :    173\n",
      "Iteration :  18000, Train reward: -15.842584388161967, Eval reward: -17.50455563302584, TD loss   : 29.32250812768936, Episode   :    174\n",
      "Iteration :  18100, Train reward: -12.07116405862588, Eval reward: -17.50455563302584, TD loss   : 30.498826732635496, Episode   :    175\n",
      "Iteration :  18200, Train reward: -12.07116405862588, Eval reward: -17.50455563302584, TD loss   : 22.19873572587967, Episode   :    175\n",
      "Iteration :  18300, Train reward: -12.07116405862588, Eval reward: -17.50455563302584, TD loss   : 20.303592326641084, Episode   :    175\n",
      "Iteration :  18400, Train reward: -7.58298047582411, Eval reward: -17.50455563302584, TD loss   : 40.46868521928787, Episode   :    176\n",
      "Iteration :  18500, Train reward: -6.7802071356958935, Eval reward: 11.58916409400247, TD loss   : 32.373217737674715, Episode   :    177\n",
      "Iteration :  18600, Train reward: -4.437216773615988, Eval reward: 11.58916409400247, TD loss   : 33.25384733200073, Episode   :    178\n",
      "Iteration :  18700, Train reward: -3.658680209870748, Eval reward: 11.58916409400247, TD loss   : 31.206264052391052, Episode   :    179\n",
      "Iteration :  18800, Train reward: -3.658680209870748, Eval reward: 11.58916409400247, TD loss   : 28.07969297647476, Episode   :    179\n",
      "Iteration :  18900, Train reward: -6.221514063660707, Eval reward: 11.58916409400247, TD loss   : 28.12173848748207, Episode   :    180\n",
      "Iteration :  19000, Train reward: -8.625495026458628, Eval reward: -11.36327192866573, TD loss   : 21.12454562664032, Episode   :    181\n",
      "Iteration :  19100, Train reward: -6.854690837279696, Eval reward: -11.36327192866573, TD loss   : 38.55853155255318, Episode   :    182\n",
      "Iteration :  19200, Train reward: -6.854690837279696, Eval reward: -11.36327192866573, TD loss   : 31.10102962732315, Episode   :    182\n",
      "Iteration :  19300, Train reward: -6.854690837279696, Eval reward: -11.36327192866573, TD loss   : 27.989833619594574, Episode   :    182\n",
      "Iteration :  19400, Train reward: -11.023731356170636, Eval reward: -11.36327192866573, TD loss   : 30.277258452177048, Episode   :    183\n",
      "Iteration :  19500, Train reward: -11.023731356170636, Eval reward: 26.95908412675005, TD loss   : 37.187900068759916, Episode   :    183\n",
      "Iteration :  19600, Train reward: -11.936743871854997, Eval reward: 26.95908412675005, TD loss   : 20.60803404211998, Episode   :    184\n",
      "Iteration :  19700, Train reward: -8.722425649187496, Eval reward: 26.95908412675005, TD loss   : 26.09505028605461, Episode   :    185\n",
      "Iteration :  19800, Train reward: -8.722425649187496, Eval reward: 26.95908412675005, TD loss   : 27.45817404747009, Episode   :    185\n",
      "Iteration :  19900, Train reward: -8.722425649187496, Eval reward: 26.95908412675005, TD loss   : 38.53339808225632, Episode   :    185\n",
      "Iteration :  20000, Train reward: -4.997364934235215, Eval reward: 5.1278932176990955, TD loss   : 33.63274083971977, Episode   :    186\n",
      "Iteration :  20100, Train reward: -3.7285480702352403, Eval reward: 5.1278932176990955, TD loss   : 29.071721382141114, Episode   :    187\n",
      "Iteration :  20200, Train reward: -3.7285480702352403, Eval reward: 5.1278932176990955, TD loss   : 34.66794350743294, Episode   :    187\n",
      "Iteration :  20300, Train reward: -5.5413169153960595, Eval reward: 5.1278932176990955, TD loss   : 32.67669553756714, Episode   :    188\n",
      "Iteration :  20400, Train reward: -5.5413169153960595, Eval reward: 5.1278932176990955, TD loss   : 28.070566586256028, Episode   :    188\n",
      "Iteration :  20500, Train reward: -13.719935651289877, Eval reward: -6.771464615195185, TD loss   : 31.9237637925148, Episode   :    189\n",
      "Iteration :  20600, Train reward: -12.959394923393058, Eval reward: -6.771464615195185, TD loss   : 17.86205726146698, Episode   :    190\n",
      "Iteration :  20700, Train reward: -8.468291315536677, Eval reward: -6.771464615195185, TD loss   : 29.901866343021393, Episode   :    191\n",
      "Iteration :  20800, Train reward: -8.494270185173582, Eval reward: -6.771464615195185, TD loss   : 26.27842369914055, Episode   :    192\n",
      "Iteration :  20900, Train reward: -5.499840452123096, Eval reward: -6.771464615195185, TD loss   : 25.405843369960785, Episode   :    193\n",
      "Iteration :  21000, Train reward: -11.395664648572467, Eval reward: 25.83684775121793, TD loss   : 39.25145272731781, Episode   :    194\n",
      "Iteration :  21100, Train reward: -15.476778581957271, Eval reward: 25.83684775121793, TD loss   : 38.21540439963341, Episode   :    196\n",
      "Iteration :  21200, Train reward: -15.476778581957271, Eval reward: 25.83684775121793, TD loss   : 28.50197415947914, Episode   :    196\n",
      "Iteration :  21300, Train reward: -15.476778581957271, Eval reward: 25.83684775121793, TD loss   : 28.504050629138945, Episode   :    196\n",
      "Iteration :  21400, Train reward: -18.598439897694668, Eval reward: 25.83684775121793, TD loss   : 35.20777203559876, Episode   :    197\n",
      "Iteration :  21500, Train reward: -18.598439897694668, Eval reward: 4.611368161186446, TD loss   : 29.684538453817368, Episode   :    197\n",
      "Iteration :  21600, Train reward: -17.4576324283643, Eval reward: 4.611368161186446, TD loss   : 30.460604432821274, Episode   :    198\n",
      "Iteration :  21700, Train reward: -14.45593058783677, Eval reward: 4.611368161186446, TD loss   : 24.22192771077156, Episode   :    199\n",
      "Iteration :  21800, Train reward: -12.59228116901078, Eval reward: 4.611368161186446, TD loss   : 31.819089525938033, Episode   :    200\n",
      "Iteration :  21900, Train reward: -12.59228116901078, Eval reward: 4.611368161186446, TD loss   : 29.28759506583214, Episode   :    200\n",
      "Iteration :  22000, Train reward: -12.59228116901078, Eval reward: 62.25228023617783, TD loss   : 18.651253080368043, Episode   :    200\n",
      "Iteration :  22100, Train reward: -5.993837096538978, Eval reward: 62.25228023617783, TD loss   : 33.470448179245, Episode   :    201\n",
      "Iteration :  22200, Train reward: -9.353944577730065, Eval reward: 62.25228023617783, TD loss   : 31.183208673000337, Episode   :    202\n",
      "Iteration :  22300, Train reward: -9.353944577730065, Eval reward: 62.25228023617783, TD loss   : 31.914628357887267, Episode   :    202\n",
      "Iteration :  22400, Train reward: -9.353944577730065, Eval reward: 62.25228023617783, TD loss   : 43.39075986981392, Episode   :    202\n",
      "Iteration :  22500, Train reward: -12.334247076955574, Eval reward: -20.672939792112498, TD loss   : 28.78245375752449, Episode   :    203\n",
      "Iteration :  22600, Train reward: -12.822222817025846, Eval reward: -20.672939792112498, TD loss   : 31.746569632291795, Episode   :    204\n",
      "Iteration :  22700, Train reward: -12.822222817025846, Eval reward: -20.672939792112498, TD loss   : 26.98331712961197, Episode   :    204\n",
      "Iteration :  22800, Train reward: -12.822222817025846, Eval reward: -20.672939792112498, TD loss   : 35.118856414556504, Episode   :    204\n",
      "Iteration :  22900, Train reward: -8.183161243602433, Eval reward: -20.672939792112498, TD loss   : 33.68295332074165, Episode   :    205\n",
      "Iteration :  23000, Train reward: -8.183161243602433, Eval reward: 12.929309164371329, TD loss   : 20.609734016656876, Episode   :    205\n",
      "Iteration :  23100, Train reward: -6.714688028409569, Eval reward: 12.929309164371329, TD loss   : 29.25661716103554, Episode   :    206\n",
      "Iteration :  23200, Train reward: -6.17001755707359, Eval reward: 12.929309164371329, TD loss   : 29.205505962371827, Episode   :    207\n",
      "Iteration :  23300, Train reward: -6.17001755707359, Eval reward: 12.929309164371329, TD loss   : 34.36491547346115, Episode   :    207\n",
      "Iteration :  23400, Train reward: -6.17001755707359, Eval reward: 12.929309164371329, TD loss   : 32.09303394794464, Episode   :    207\n",
      "Iteration :  23500, Train reward: 1.2609047828657551, Eval reward: 18.94830778364794, TD loss   : 33.49377768874169, Episode   :    208\n",
      "Iteration :  23600, Train reward: 12.264039225457669, Eval reward: 18.94830778364794, TD loss   : 38.98292424678802, Episode   :    209\n",
      "Iteration :  23700, Train reward: 10.331317707934314, Eval reward: 18.94830778364794, TD loss   : 38.5622839808464, Episode   :    210\n",
      "Iteration :  23800, Train reward: 9.659515933166166, Eval reward: 18.94830778364794, TD loss   : 35.77374712944031, Episode   :    211\n",
      "Iteration :  23900, Train reward: 9.659515933166166, Eval reward: 18.94830778364794, TD loss   : 25.94312136888504, Episode   :    211\n",
      "Iteration :  24000, Train reward: 9.659515933166166, Eval reward: -39.84633426134077, TD loss   : 22.833937940597533, Episode   :    211\n",
      "Iteration :  24100, Train reward: 9.508918418098817, Eval reward: -39.84633426134077, TD loss   : 20.350075974464417, Episode   :    212\n",
      "Iteration :  24200, Train reward: 9.508918418098817, Eval reward: -39.84633426134077, TD loss   : 30.057298135757446, Episode   :    212\n",
      "Iteration :  24300, Train reward: 9.508918418098817, Eval reward: -39.84633426134077, TD loss   : 29.625956486463547, Episode   :    212\n",
      "Iteration :  24400, Train reward: 4.234781325676279, Eval reward: -39.84633426134077, TD loss   : 42.617318031787875, Episode   :    213\n",
      "Iteration :  24500, Train reward: 4.234781325676279, Eval reward: 17.62573158955933, TD loss   : 27.33424224615097, Episode   :    213\n",
      "Iteration :  24600, Train reward: 11.024611116693, Eval reward: 17.62573158955933, TD loss   : 38.922241178750994, Episode   :    214\n",
      "Iteration :  24700, Train reward: 11.024611116693, Eval reward: 17.62573158955933, TD loss   : 30.809848635196687, Episode   :    214\n",
      "Iteration :  24800, Train reward: 11.024611116693, Eval reward: 17.62573158955933, TD loss   : 29.962881932258608, Episode   :    214\n",
      "Iteration :  24900, Train reward: 11.25655331094954, Eval reward: 17.62573158955933, TD loss   : 24.446998040676117, Episode   :    215\n",
      "Iteration :  25000, Train reward: 11.25655331094954, Eval reward: 48.822655325770235, TD loss   : 27.340323166847227, Episode   :    215\n",
      "Iteration :  25100, Train reward: 13.442097140018788, Eval reward: 48.822655325770235, TD loss   : 21.482156991958618, Episode   :    216\n",
      "Iteration :  25200, Train reward: 13.442097140018788, Eval reward: 48.822655325770235, TD loss   : 24.820494438409806, Episode   :    216\n",
      "Iteration :  25300, Train reward: 13.442097140018788, Eval reward: 48.822655325770235, TD loss   : 36.48953128099441, Episode   :    216\n",
      "Iteration :  25400, Train reward: 17.56401882399491, Eval reward: 48.822655325770235, TD loss   : 17.78675819993019, Episode   :    217\n",
      "Iteration :  25500, Train reward: 17.56401882399491, Eval reward: 19.6750126962489, TD loss   : 33.90963725328445, Episode   :    217\n",
      "Iteration :  25600, Train reward: 21.928133827895824, Eval reward: 19.6750126962489, TD loss   : 27.185169596672058, Episode   :    218\n",
      "Iteration :  25700, Train reward: 21.928133827895824, Eval reward: 19.6750126962489, TD loss   : 35.72313627004623, Episode   :    218\n",
      "Iteration :  25800, Train reward: 21.928133827895824, Eval reward: 19.6750126962489, TD loss   : 22.440034168958665, Episode   :    218\n",
      "Iteration :  25900, Train reward: 24.025674551372322, Eval reward: 19.6750126962489, TD loss   : 17.799297618865968, Episode   :    219\n",
      "Iteration :  26000, Train reward: 24.025674551372322, Eval reward: 34.38885119589114, TD loss   : 37.198479818105696, Episode   :    219\n",
      "Iteration :  26100, Train reward: 28.062382024592598, Eval reward: 34.38885119589114, TD loss   : 37.81178006529808, Episode   :    220\n",
      "Iteration :  26200, Train reward: 22.736432791198748, Eval reward: 34.38885119589114, TD loss   : 24.265901284217833, Episode   :    221\n",
      "Iteration :  26300, Train reward: 22.736432791198748, Eval reward: 34.38885119589114, TD loss   : 31.38890506029129, Episode   :    221\n",
      "Iteration :  26400, Train reward: 14.69949926494048, Eval reward: 34.38885119589114, TD loss   : 32.555579798221586, Episode   :    222\n",
      "Iteration :  26500, Train reward: 14.69949926494048, Eval reward: -1.9413819952483742, TD loss   : 22.30686199426651, Episode   :    222\n",
      "Iteration :  26600, Train reward: 17.394962772218438, Eval reward: -1.9413819952483742, TD loss   : 35.08636963367462, Episode   :    223\n",
      "Iteration :  26700, Train reward: 17.394962772218438, Eval reward: -1.9413819952483742, TD loss   : 24.116897757053376, Episode   :    223\n",
      "Iteration :  26800, Train reward: 17.394962772218438, Eval reward: -1.9413819952483742, TD loss   : 18.876325339078903, Episode   :    223\n",
      "Iteration :  26900, Train reward: 18.36554207519689, Eval reward: -1.9413819952483742, TD loss   : 22.838029233217238, Episode   :    224\n",
      "Iteration :  27000, Train reward: 18.36554207519689, Eval reward: -3.324026140797071, TD loss   : 24.775487904548644, Episode   :    224\n",
      "Iteration :  27100, Train reward: 12.91542609994749, Eval reward: -3.324026140797071, TD loss   : 33.22434160470962, Episode   :    225\n",
      "Iteration :  27200, Train reward: 12.91542609994749, Eval reward: -3.324026140797071, TD loss   : 27.098382543325425, Episode   :    225\n",
      "Iteration :  27300, Train reward: 12.91542609994749, Eval reward: -3.324026140797071, TD loss   : 27.27992898106575, Episode   :    225\n",
      "Iteration :  27400, Train reward: 15.667390259208148, Eval reward: -3.324026140797071, TD loss   : 34.72211714982986, Episode   :    226\n",
      "Iteration :  27500, Train reward: 15.667390259208148, Eval reward: -51.29877452429582, TD loss   : 36.313169617652896, Episode   :    226\n",
      "Iteration :  27600, Train reward: 17.950747872878885, Eval reward: -51.29877452429582, TD loss   : 29.567758502960206, Episode   :    227\n",
      "Iteration :  27700, Train reward: 10.88829779695279, Eval reward: -51.29877452429582, TD loss   : 42.59765307426453, Episode   :    228\n",
      "Iteration :  27800, Train reward: 10.88829779695279, Eval reward: -51.29877452429582, TD loss   : 26.991681690216065, Episode   :    228\n",
      "Iteration :  27900, Train reward: 3.9652254795158712, Eval reward: -51.29877452429582, TD loss   : 24.974289169311522, Episode   :    229\n",
      "Iteration :  28000, Train reward: 3.9652254795158712, Eval reward: -7.34566850064436, TD loss   : 21.57531934380531, Episode   :    229\n",
      "Iteration :  28100, Train reward: 2.8869294896967164, Eval reward: -7.34566850064436, TD loss   : 34.0383744764328, Episode   :    230\n",
      "Iteration :  28200, Train reward: 2.8869294896967164, Eval reward: -7.34566850064436, TD loss   : 35.40097828626633, Episode   :    230\n",
      "Iteration :  28300, Train reward: 2.8869294896967164, Eval reward: -7.34566850064436, TD loss   : 32.88857548713684, Episode   :    230\n",
      "Iteration :  28400, Train reward: 8.094082338304371, Eval reward: -7.34566850064436, TD loss   : 26.76642037987709, Episode   :    231\n",
      "Iteration :  28500, Train reward: 8.094082338304371, Eval reward: -48.4139827161965, TD loss   : 28.518559920787812, Episode   :    231\n",
      "Iteration :  28600, Train reward: 10.79622653123557, Eval reward: -48.4139827161965, TD loss   : 30.677886601686478, Episode   :    232\n",
      "Iteration :  28700, Train reward: 13.627343076283271, Eval reward: -48.4139827161965, TD loss   : 28.14006466984749, Episode   :    233\n",
      "Iteration :  28800, Train reward: 13.627343076283271, Eval reward: -48.4139827161965, TD loss   : 27.777743480205537, Episode   :    233\n",
      "Iteration :  28900, Train reward: 13.627343076283271, Eval reward: -48.4139827161965, TD loss   : 28.018954080343246, Episode   :    233\n",
      "Iteration :  29000, Train reward: 11.87810562888124, Eval reward: 45.67548568442079, TD loss   : 31.327034609317778, Episode   :    234\n",
      "Iteration :  29100, Train reward: 12.213190349862955, Eval reward: 45.67548568442079, TD loss   : 26.663293380737304, Episode   :    235\n",
      "Iteration :  29200, Train reward: 12.213190349862955, Eval reward: 45.67548568442079, TD loss   : 26.9756680727005, Episode   :    235\n",
      "Iteration :  29300, Train reward: 12.213190349862955, Eval reward: 45.67548568442079, TD loss   : 20.436907864809037, Episode   :    235\n",
      "Iteration :  29400, Train reward: 15.90050003446163, Eval reward: 45.67548568442079, TD loss   : 30.163373180627822, Episode   :    236\n",
      "Iteration :  29500, Train reward: 3.567245516290889, Eval reward: -48.460742827025534, TD loss   : 32.38249885559082, Episode   :    237\n",
      "Iteration :  29600, Train reward: -3.3464541938850885, Eval reward: -48.460742827025534, TD loss   : 35.06251574516296, Episode   :    238\n",
      "Iteration :  29700, Train reward: -3.3464541938850885, Eval reward: -48.460742827025534, TD loss   : 37.98958689332008, Episode   :    238\n",
      "Iteration :  29800, Train reward: -3.3464541938850885, Eval reward: -48.460742827025534, TD loss   : 21.503368064165116, Episode   :    238\n",
      "Iteration :  29900, Train reward: -4.220813476294117, Eval reward: -48.460742827025534, TD loss   : 40.6869838476181, Episode   :    239\n",
      "Iteration :  30000, Train reward: -4.220813476294117, Eval reward: -12.072027833372653, TD loss   : 24.805198512077332, Episode   :    239\n",
      "Iteration :  30100, Train reward: -8.760574004409037, Eval reward: -12.072027833372653, TD loss   : 25.843757183551787, Episode   :    240\n",
      "Iteration :  30200, Train reward: -8.760574004409037, Eval reward: -12.072027833372653, TD loss   : 31.906741765737532, Episode   :    240\n",
      "Iteration :  30300, Train reward: -8.760574004409037, Eval reward: -12.072027833372653, TD loss   : 28.25746289372444, Episode   :    240\n",
      "Iteration :  30400, Train reward: -4.7897198194182815, Eval reward: -12.072027833372653, TD loss   : 26.80830716609955, Episode   :    241\n",
      "Iteration :  30500, Train reward: -4.7897198194182815, Eval reward: 64.34668867854205, TD loss   : 36.36744297623634, Episode   :    241\n",
      "Iteration :  30600, Train reward: 8.38423419746619, Eval reward: 64.34668867854205, TD loss   : 23.209098576307298, Episode   :    242\n",
      "Iteration :  30700, Train reward: 8.38423419746619, Eval reward: 64.34668867854205, TD loss   : 34.62060425519943, Episode   :    242\n",
      "Iteration :  30800, Train reward: 8.38423419746619, Eval reward: 64.34668867854205, TD loss   : 30.440078371763228, Episode   :    242\n",
      "Iteration :  30900, Train reward: 10.303181047288371, Eval reward: 64.34668867854205, TD loss   : 28.768904283046723, Episode   :    243\n",
      "Iteration :  31000, Train reward: 10.303181047288371, Eval reward: 59.704652575550405, TD loss   : 20.361571696996688, Episode   :    243\n",
      "Iteration :  31100, Train reward: 12.311652368473357, Eval reward: 59.704652575550405, TD loss   : 30.59910374760628, Episode   :    244\n",
      "Iteration :  31200, Train reward: 12.311652368473357, Eval reward: 59.704652575550405, TD loss   : 37.97261278629303, Episode   :    244\n",
      "Iteration :  31300, Train reward: 12.311652368473357, Eval reward: 59.704652575550405, TD loss   : 29.326934654712677, Episode   :    244\n",
      "Iteration :  31400, Train reward: 19.049307823814424, Eval reward: 59.704652575550405, TD loss   : 29.71222922682762, Episode   :    245\n",
      "Iteration :  31500, Train reward: 19.049307823814424, Eval reward: 8.040792406245993, TD loss   : 28.854569526910783, Episode   :    245\n",
      "Iteration :  31600, Train reward: 15.727793394775489, Eval reward: 8.040792406245993, TD loss   : 34.50654014825821, Episode   :    246\n",
      "Iteration :  31700, Train reward: 15.727793394775489, Eval reward: 8.040792406245993, TD loss   : 24.62044950008392, Episode   :    246\n",
      "Iteration :  31800, Train reward: 15.727793394775489, Eval reward: 8.040792406245993, TD loss   : 24.645420093536377, Episode   :    246\n",
      "Iteration :  31900, Train reward: 15.046840024108343, Eval reward: 8.040792406245993, TD loss   : 20.378767366409303, Episode   :    247\n",
      "Iteration :  32000, Train reward: 15.046840024108343, Eval reward: 52.909418501767675, TD loss   : 29.917684259414674, Episode   :    247\n",
      "Iteration :  32100, Train reward: 20.232937567881958, Eval reward: 52.909418501767675, TD loss   : 24.821475777626038, Episode   :    248\n",
      "Iteration :  32200, Train reward: 20.232937567881958, Eval reward: 52.909418501767675, TD loss   : 25.707528331279754, Episode   :    248\n",
      "Iteration :  32300, Train reward: 20.232937567881958, Eval reward: 52.909418501767675, TD loss   : 25.082807768583297, Episode   :    248\n",
      "Iteration :  32400, Train reward: 29.747532478279993, Eval reward: 52.909418501767675, TD loss   : 24.037698208093644, Episode   :    249\n",
      "Iteration :  32500, Train reward: 29.747532478279993, Eval reward: 39.19486159529625, TD loss   : 19.65046191453934, Episode   :    249\n",
      "Iteration :  32600, Train reward: 36.17321987027208, Eval reward: 39.19486159529625, TD loss   : 26.97745151638985, Episode   :    250\n",
      "Iteration :  32700, Train reward: 10.07982425702387, Eval reward: 39.19486159529625, TD loss   : 25.62857766032219, Episode   :    251\n",
      "Iteration :  32800, Train reward: 10.07982425702387, Eval reward: 39.19486159529625, TD loss   : 17.889875556230546, Episode   :    251\n",
      "Iteration :  32900, Train reward: 10.07982425702387, Eval reward: 39.19486159529625, TD loss   : 34.373629286289216, Episode   :    251\n",
      "Iteration :  33000, Train reward: 10.963948768979265, Eval reward: 59.63530188279155, TD loss   : 26.703217177391053, Episode   :    252\n",
      "Iteration :  33100, Train reward: 14.133514458368186, Eval reward: 59.63530188279155, TD loss   : 27.18724825978279, Episode   :    253\n",
      "Iteration :  33200, Train reward: 14.133514458368186, Eval reward: 59.63530188279155, TD loss   : 24.613689198493958, Episode   :    253\n",
      "Iteration :  33300, Train reward: 14.133514458368186, Eval reward: 59.63530188279155, TD loss   : 25.57511862516403, Episode   :    253\n",
      "Iteration :  33400, Train reward: 15.146815902988944, Eval reward: 59.63530188279155, TD loss   : 30.60014631986618, Episode   :    254\n",
      "Iteration :  33500, Train reward: 15.146815902988944, Eval reward: 48.56803490845241, TD loss   : 18.3538774228096, Episode   :    254\n",
      "Iteration :  33600, Train reward: 18.145928102835086, Eval reward: 48.56803490845241, TD loss   : 21.109436254501343, Episode   :    255\n",
      "Iteration :  33700, Train reward: 18.145928102835086, Eval reward: 48.56803490845241, TD loss   : 27.057750554084777, Episode   :    255\n",
      "Iteration :  33800, Train reward: 18.145928102835086, Eval reward: 48.56803490845241, TD loss   : 27.441000077724457, Episode   :    255\n",
      "Iteration :  33900, Train reward: 13.442122958253984, Eval reward: 48.56803490845241, TD loss   : 15.727290120124817, Episode   :    256\n",
      "Iteration :  34000, Train reward: 13.442122958253984, Eval reward: 3.7290560685030747, TD loss   : 26.968792902231215, Episode   :    256\n",
      "Iteration :  34100, Train reward: 27.59540469656365, Eval reward: 3.7290560685030747, TD loss   : 33.47796210885048, Episode   :    257\n",
      "Iteration :  34200, Train reward: 27.59540469656365, Eval reward: 3.7290560685030747, TD loss   : 22.076706734895705, Episode   :    257\n",
      "Iteration :  34300, Train reward: 27.59540469656365, Eval reward: 3.7290560685030747, TD loss   : 18.707784053087234, Episode   :    257\n",
      "Iteration :  34400, Train reward: 29.668853722793017, Eval reward: 3.7290560685030747, TD loss   : 26.423503748178483, Episode   :    258\n",
      "Iteration :  34500, Train reward: 29.668853722793017, Eval reward: 0.0752100004449872, TD loss   : 29.53737407207489, Episode   :    258\n",
      "Iteration :  34600, Train reward: 31.485573990223777, Eval reward: 0.0752100004449872, TD loss   : 20.823842232227324, Episode   :    259\n",
      "Iteration :  34700, Train reward: 29.03151592394292, Eval reward: 0.0752100004449872, TD loss   : 39.65952748775482, Episode   :    260\n",
      "Iteration :  34800, Train reward: 29.03151592394292, Eval reward: 0.0752100004449872, TD loss   : 25.636902014017107, Episode   :    260\n",
      "Iteration :  34900, Train reward: 29.03151592394292, Eval reward: 0.0752100004449872, TD loss   : 20.18216220855713, Episode   :    260\n",
      "Iteration :  35000, Train reward: 29.408320358615264, Eval reward: 82.67714892926156, TD loss   : 19.483211940526964, Episode   :    261\n",
      "Iteration :  35100, Train reward: 26.41009000662723, Eval reward: 82.67714892926156, TD loss   : 23.316625978946686, Episode   :    262\n",
      "Iteration :  35200, Train reward: 26.41009000662723, Eval reward: 82.67714892926156, TD loss   : 22.659131803512572, Episode   :    262\n",
      "Iteration :  35300, Train reward: 26.41009000662723, Eval reward: 82.67714892926156, TD loss   : 20.318160235881805, Episode   :    262\n",
      "Iteration :  35400, Train reward: 26.400546469614447, Eval reward: 82.67714892926156, TD loss   : 30.377931895256044, Episode   :    263\n",
      "Iteration :  35500, Train reward: 26.400546469614447, Eval reward: 33.899213857203236, TD loss   : 34.95857689499855, Episode   :    263\n",
      "Iteration :  35600, Train reward: 28.2355031532472, Eval reward: 33.899213857203236, TD loss   : 21.19613284945488, Episode   :    264\n",
      "Iteration :  35700, Train reward: 28.2355031532472, Eval reward: 33.899213857203236, TD loss   : 20.388693495988846, Episode   :    264\n",
      "Iteration :  35800, Train reward: 28.2355031532472, Eval reward: 33.899213857203236, TD loss   : 29.1903502202034, Episode   :    264\n",
      "Iteration :  35900, Train reward: 24.575090483458343, Eval reward: 33.899213857203236, TD loss   : 24.132306814193726, Episode   :    265\n",
      "Iteration :  36000, Train reward: 24.575090483458343, Eval reward: 7.719603109626462, TD loss   : 24.54703998565674, Episode   :    265\n",
      "Iteration :  36100, Train reward: 21.987887569275266, Eval reward: 7.719603109626462, TD loss   : 23.130804138183592, Episode   :    266\n",
      "Iteration :  36200, Train reward: 21.987887569275266, Eval reward: 7.719603109626462, TD loss   : 23.0512032520771, Episode   :    266\n",
      "Iteration :  36300, Train reward: 21.987887569275266, Eval reward: 7.719603109626462, TD loss   : 29.891342948675156, Episode   :    266\n",
      "Iteration :  36400, Train reward: 22.144756389818397, Eval reward: 7.719603109626462, TD loss   : 29.706318781375884, Episode   :    267\n",
      "Iteration :  36500, Train reward: 22.144756389818397, Eval reward: 33.466526195119215, TD loss   : 28.020509006977083, Episode   :    267\n",
      "Iteration :  36600, Train reward: 18.03873093568115, Eval reward: 33.466526195119215, TD loss   : 21.19754249572754, Episode   :    268\n",
      "Iteration :  36700, Train reward: 18.03873093568115, Eval reward: 33.466526195119215, TD loss   : 22.36901215672493, Episode   :    268\n",
      "Iteration :  36800, Train reward: 18.03873093568115, Eval reward: 33.466526195119215, TD loss   : 23.485142538547517, Episode   :    268\n",
      "Iteration :  36900, Train reward: 18.02240732798104, Eval reward: 33.466526195119215, TD loss   : 27.55063706755638, Episode   :    269\n",
      "Iteration :  37000, Train reward: 18.02240732798104, Eval reward: 51.45069585562502, TD loss   : 26.520564581155778, Episode   :    269\n",
      "Iteration :  37100, Train reward: 17.514268567998265, Eval reward: 51.45069585562502, TD loss   : 20.455017437934874, Episode   :    270\n",
      "Iteration :  37200, Train reward: 17.514268567998265, Eval reward: 51.45069585562502, TD loss   : 27.484830594062807, Episode   :    270\n",
      "Iteration :  37300, Train reward: 17.514268567998265, Eval reward: 51.45069585562502, TD loss   : 25.316886270046233, Episode   :    270\n",
      "Iteration :  37400, Train reward: 39.76275877711434, Eval reward: 51.45069585562502, TD loss   : 24.219035897254944, Episode   :    271\n",
      "Iteration :  37500, Train reward: 39.76275877711434, Eval reward: 28.78819408441047, TD loss   : 24.12791494846344, Episode   :    271\n",
      "Iteration :  37600, Train reward: 31.847453587431243, Eval reward: 28.78819408441047, TD loss   : 24.581536730527876, Episode   :    272\n",
      "Iteration :  37700, Train reward: 31.847453587431243, Eval reward: 28.78819408441047, TD loss   : 16.70070614337921, Episode   :    272\n",
      "Iteration :  37800, Train reward: 31.847453587431243, Eval reward: 28.78819408441047, TD loss   : 21.191814925670624, Episode   :    272\n",
      "Iteration :  37900, Train reward: 34.00138833649228, Eval reward: 28.78819408441047, TD loss   : 20.670546585321425, Episode   :    273\n",
      "Iteration :  38000, Train reward: 34.00138833649228, Eval reward: -61.10868776870241, TD loss   : 23.79167334198952, Episode   :    273\n",
      "Iteration :  38100, Train reward: 29.58786671408052, Eval reward: -61.10868776870241, TD loss   : 39.25847848296166, Episode   :    274\n",
      "Iteration :  38200, Train reward: 29.58786671408052, Eval reward: -61.10868776870241, TD loss   : 21.08932139992714, Episode   :    274\n",
      "Iteration :  38300, Train reward: 29.58786671408052, Eval reward: -61.10868776870241, TD loss   : 26.1098402094841, Episode   :    274\n",
      "Iteration :  38400, Train reward: 25.3819511680519, Eval reward: -61.10868776870241, TD loss   : 24.503532395362853, Episode   :    275\n",
      "Iteration :  38500, Train reward: 25.3819511680519, Eval reward: 48.97809128056384, TD loss   : 25.9092993247509, Episode   :    275\n",
      "Iteration :  38600, Train reward: 22.01206156013665, Eval reward: 48.97809128056384, TD loss   : 35.08386145949364, Episode   :    276\n",
      "Iteration :  38700, Train reward: 22.01206156013665, Eval reward: 48.97809128056384, TD loss   : 28.77105302453041, Episode   :    276\n",
      "Iteration :  38800, Train reward: 22.01206156013665, Eval reward: 48.97809128056384, TD loss   : 20.328367257118224, Episode   :    276\n",
      "Iteration :  38900, Train reward: 22.236225269183088, Eval reward: 48.97809128056384, TD loss   : 23.790709567070007, Episode   :    277\n",
      "Iteration :  39000, Train reward: 22.236225269183088, Eval reward: 6.599583334750387, TD loss   : 24.89353588104248, Episode   :    277\n",
      "Iteration :  39100, Train reward: 24.52177024504041, Eval reward: 6.599583334750387, TD loss   : 19.21995422720909, Episode   :    278\n",
      "Iteration :  39200, Train reward: 24.52177024504041, Eval reward: 6.599583334750387, TD loss   : 13.166249047517777, Episode   :    278\n",
      "Iteration :  39300, Train reward: 24.52177024504041, Eval reward: 6.599583334750387, TD loss   : 25.95324616909027, Episode   :    278\n",
      "Iteration :  39400, Train reward: 21.872723199435956, Eval reward: 6.599583334750387, TD loss   : 30.061889151334764, Episode   :    279\n",
      "Iteration :  39500, Train reward: 21.89472041969367, Eval reward: 31.19394378778071, TD loss   : 24.443945124149323, Episode   :    280\n",
      "Iteration :  39600, Train reward: 20.418941648767625, Eval reward: 31.19394378778071, TD loss   : 15.315756958723068, Episode   :    281\n",
      "Iteration :  39700, Train reward: 20.418941648767625, Eval reward: 31.19394378778071, TD loss   : 24.478811928033828, Episode   :    281\n",
      "Iteration :  39800, Train reward: 20.418941648767625, Eval reward: 31.19394378778071, TD loss   : 20.23302272081375, Episode   :    281\n",
      "Iteration :  39900, Train reward: 19.92948739912337, Eval reward: 31.19394378778071, TD loss   : 25.87668886423111, Episode   :    282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HasanErdin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\HasanErdin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :      0, Train reward:    nan, Eval reward: -122.94908688913247, TD loss   :    nan, Episode   :      0\n",
      "Iteration :    100, Train reward: -26.292714233827787, Eval reward: -122.94908688913247, TD loss   : 327.94134521484375, Episode   :      2\n",
      "Iteration :    200, Train reward: -117.88918828736405, Eval reward: -122.94908688913247, TD loss   : 250.4326784658432, Episode   :      3\n",
      "Iteration :    300, Train reward: -187.20159582334188, Eval reward: -122.94908688913247, TD loss   : 228.92760361671446, Episode   :      4\n",
      "Iteration :    400, Train reward: -177.14189488444222, Eval reward: -122.94908688913247, TD loss   : 133.40705760478974, Episode   :      5\n",
      "Iteration :    500, Train reward: -210.4263071363583, Eval reward: -772.6090968926761, TD loss   : 146.27827796936035, Episode   :      6\n",
      "Iteration :    600, Train reward: -195.75083251744113, Eval reward: -772.6090968926761, TD loss   : 130.8261897468567, Episode   :      7\n",
      "Iteration :    700, Train reward: -193.79386467435035, Eval reward: -772.6090968926761, TD loss   : 154.69533877372743, Episode   :      8\n",
      "Iteration :    800, Train reward: -206.38963775503842, Eval reward: -772.6090968926761, TD loss   : 159.37333275318144, Episode   :      9\n",
      "Iteration :    900, Train reward: -195.89423543374429, Eval reward: -772.6090968926761, TD loss   : 124.14316238880157, Episode   :     10\n",
      "Iteration :   1000, Train reward: -184.23141766174638, Eval reward: -110.23754641396383, TD loss   : 133.93333225250245, Episode   :     11\n",
      "Iteration :   1100, Train reward: -184.0362504139016, Eval reward: -110.23754641396383, TD loss   : 131.10455048799514, Episode   :     12\n",
      "Iteration :   1200, Train reward: -172.1594810799231, Eval reward: -110.23754641396383, TD loss   : 119.20841326951981, Episode   :     14\n",
      "Iteration :   1300, Train reward: -161.4251920451856, Eval reward: -110.23754641396383, TD loss   : 131.10943086862565, Episode   :     15\n",
      "Iteration :   1400, Train reward: -160.88196900043005, Eval reward: -110.23754641396383, TD loss   : 142.43936337471007, Episode   :     16\n",
      "Iteration :   1500, Train reward: -159.13116431113772, Eval reward: -139.76013102349458, TD loss   : 130.1924489426613, Episode   :     17\n",
      "Iteration :   1600, Train reward: -156.5354999755098, Eval reward: -139.76013102349458, TD loss   : 155.81757771492005, Episode   :     18\n",
      "Iteration :   1700, Train reward: -153.0173034895807, Eval reward: -139.76013102349458, TD loss   : 125.93491314411163, Episode   :     19\n",
      "Iteration :   1800, Train reward: -159.58406042960698, Eval reward: -139.76013102349458, TD loss   : 126.72432563781739, Episode   :     20\n",
      "Iteration :   1900, Train reward: -159.72277399279216, Eval reward: -139.76013102349458, TD loss   : 139.30505808353425, Episode   :     21\n",
      "Iteration :   2000, Train reward: -169.2353626674125, Eval reward: -115.04520819956204, TD loss   : 122.73312698841094, Episode   :     22\n",
      "Iteration :   2100, Train reward: -159.9344567114132, Eval reward: -115.04520819956204, TD loss   : 117.93115199804306, Episode   :     23\n",
      "Iteration :   2200, Train reward: -147.5929303879391, Eval reward: -115.04520819956204, TD loss   : 112.70979122161866, Episode   :     24\n",
      "Iteration :   2300, Train reward: -147.33143441808144, Eval reward: -115.04520819956204, TD loss   : 94.87370040893555, Episode   :     25\n",
      "Iteration :   2400, Train reward: -140.0849345140243, Eval reward: -115.04520819956204, TD loss   : 107.23964094877243, Episode   :     26\n",
      "Iteration :   2500, Train reward: -141.38757902821504, Eval reward: 16.825495684757886, TD loss   : 108.8445190668106, Episode   :     27\n",
      "Iteration :   2600, Train reward: -137.66947001446786, Eval reward: 16.825495684757886, TD loss   : 106.04938126683236, Episode   :     28\n",
      "Iteration :   2700, Train reward: -127.42122220621681, Eval reward: 16.825495684757886, TD loss   : 103.14895109891891, Episode   :     30\n",
      "Iteration :   2800, Train reward: -141.08809131850757, Eval reward: 16.825495684757886, TD loss   : 114.21971041440963, Episode   :     31\n",
      "Iteration :   2900, Train reward: -139.7118211070112, Eval reward: 16.825495684757886, TD loss   : 83.43309041500092, Episode   :     32\n",
      "Iteration :   3000, Train reward: -143.69733331926417, Eval reward: -157.46135707997794, TD loss   : 110.68849713087081, Episode   :     33\n",
      "Iteration :   3100, Train reward: -145.28370045067115, Eval reward: -157.46135707997794, TD loss   : 115.1291169500351, Episode   :     34\n",
      "Iteration :   3200, Train reward: -158.08370460738598, Eval reward: -157.46135707997794, TD loss   : 84.71727538108826, Episode   :     35\n",
      "Iteration :   3300, Train reward: -159.29280633429178, Eval reward: -157.46135707997794, TD loss   : 96.04882180929184, Episode   :     36\n",
      "Iteration :   3400, Train reward: -159.34943059488842, Eval reward: -157.46135707997794, TD loss   : 77.96258994102477, Episode   :     37\n",
      "Iteration :   3500, Train reward: -161.0784869982202, Eval reward: -11.204109691693938, TD loss   : 82.06968571543693, Episode   :     38\n",
      "Iteration :   3600, Train reward: -161.43610135725766, Eval reward: -11.204109691693938, TD loss   : 91.90601962327958, Episode   :     39\n",
      "Iteration :   3700, Train reward: -151.4176726124303, Eval reward: -11.204109691693938, TD loss   : 83.45186767339706, Episode   :     41\n",
      "Iteration :   3800, Train reward: -149.05905231337687, Eval reward: -11.204109691693938, TD loss   : 71.39788722157478, Episode   :     42\n",
      "Iteration :   3900, Train reward: -149.05905231337687, Eval reward: -11.204109691693938, TD loss   : 79.14311577558517, Episode   :     42\n",
      "Iteration :   4000, Train reward: -155.88261822718638, Eval reward: -97.28768127142082, TD loss   : 67.31580322265626, Episode   :     43\n",
      "Iteration :   4100, Train reward: -155.34438288133933, Eval reward: -97.28768127142082, TD loss   : 70.01235578775406, Episode   :     45\n",
      "Iteration :   4200, Train reward: -141.70448853211528, Eval reward: -97.28768127142082, TD loss   : 88.66901982784272, Episode   :     46\n",
      "Iteration :   4300, Train reward: -137.87301184490337, Eval reward: -97.28768127142082, TD loss   : 82.2363244330883, Episode   :     47\n",
      "Iteration :   4400, Train reward: -137.06970139448566, Eval reward: -97.28768127142082, TD loss   : 79.75524307250977, Episode   :     48\n",
      "Iteration :   4500, Train reward: -137.06970139448566, Eval reward: -35.51373895108124, TD loss   : 86.37142152547837, Episode   :     48\n",
      "Iteration :   4600, Train reward: -141.83235498632078, Eval reward: -35.51373895108124, TD loss   : 80.03285932779312, Episode   :     49\n",
      "Iteration :   4700, Train reward: -147.03184735343436, Eval reward: -35.51373895108124, TD loss   : 65.2919111585617, Episode   :     50\n",
      "Iteration :   4800, Train reward: -135.5201449692544, Eval reward: -35.51373895108124, TD loss   : 69.18407071352004, Episode   :     51\n",
      "Iteration :   4900, Train reward: -133.8885209189647, Eval reward: -35.51373895108124, TD loss   : 67.73444780468941, Episode   :     52\n",
      "Iteration :   5000, Train reward: -131.0482259163742, Eval reward: -36.672303895505195, TD loss   : 66.50525020241737, Episode   :     53\n",
      "Iteration :   5100, Train reward: -114.86814305303412, Eval reward: -36.672303895505195, TD loss   : 71.55064387083054, Episode   :     55\n",
      "Iteration :   5200, Train reward: -114.89606785824404, Eval reward: -36.672303895505195, TD loss   : 80.0812518620491, Episode   :     56\n",
      "Iteration :   5300, Train reward: -114.89606785824404, Eval reward: -36.672303895505195, TD loss   : 54.38717413425446, Episode   :     56\n",
      "Iteration :   5400, Train reward: -110.1474531116703, Eval reward: -36.672303895505195, TD loss   : 59.17049137949944, Episode   :     58\n",
      "Iteration :   5500, Train reward: -108.55101511519224, Eval reward: -68.49514580430974, TD loss   : 62.30982870697975, Episode   :     59\n",
      "Iteration :   5600, Train reward: -108.44883507931272, Eval reward: -68.49514580430974, TD loss   : 57.581383001804355, Episode   :     60\n",
      "Iteration :   5700, Train reward: -109.23623719799306, Eval reward: -68.49514580430974, TD loss   : 65.22405020356179, Episode   :     61\n",
      "Iteration :   5800, Train reward: -111.58226567076974, Eval reward: -68.49514580430974, TD loss   : 52.92133716702461, Episode   :     62\n",
      "Iteration :   5900, Train reward: -107.99193741357344, Eval reward: -68.49514580430974, TD loss   : 55.53555082321167, Episode   :     63\n",
      "Iteration :   6000, Train reward: -104.73750862099828, Eval reward: -50.95786232579368, TD loss   : 65.67960088133812, Episode   :     64\n",
      "Iteration :   6100, Train reward: -116.58049912059434, Eval reward: -50.95786232579368, TD loss   : 42.61127552986145, Episode   :     66\n",
      "Iteration :   6200, Train reward: -116.58049912059434, Eval reward: -50.95786232579368, TD loss   : 77.33925518155098, Episode   :     66\n",
      "Iteration :   6300, Train reward: -121.45457994905658, Eval reward: -50.95786232579368, TD loss   : 66.67986160039902, Episode   :     67\n",
      "Iteration :   6400, Train reward: -119.84730725677798, Eval reward: -50.95786232579368, TD loss   : 55.113090637922284, Episode   :     68\n",
      "Iteration :   6500, Train reward: -121.54000246883486, Eval reward: 8.794460627185625, TD loss   : 49.20532721638679, Episode   :     69\n",
      "Iteration :   6600, Train reward: -114.09202077586122, Eval reward: 8.794460627185625, TD loss   : 61.255216372013095, Episode   :     71\n",
      "Iteration :   6700, Train reward: -117.34186229532278, Eval reward: 8.794460627185625, TD loss   : 58.327385967969896, Episode   :     72\n",
      "Iteration :   6800, Train reward: -112.1701125411483, Eval reward: 8.794460627185625, TD loss   : 53.71621653676033, Episode   :     73\n",
      "Iteration :   6900, Train reward: -118.20978291928529, Eval reward: 8.794460627185625, TD loss   : 56.0885460537672, Episode   :     74\n",
      "Iteration :   7000, Train reward: -119.63358457153882, Eval reward: -52.738305816809145, TD loss   : 71.68689227819442, Episode   :     75\n",
      "Iteration :   7100, Train reward: -110.81771048225998, Eval reward: -52.738305816809145, TD loss   : 69.77564821720124, Episode   :     76\n",
      "Iteration :   7200, Train reward: -116.61365923525841, Eval reward: -52.738305816809145, TD loss   : 63.805791778564455, Episode   :     78\n",
      "Iteration :   7300, Train reward: -119.05510242581849, Eval reward: -52.738305816809145, TD loss   : 59.75686796665192, Episode   :     79\n",
      "Iteration :   7400, Train reward: -119.82491937168405, Eval reward: -52.738305816809145, TD loss   : 59.57139757514, Episode   :     80\n",
      "Iteration :   7500, Train reward: -120.84762927126368, Eval reward: -84.74793852469716, TD loss   : 53.47665571212769, Episode   :     81\n",
      "Iteration :   7600, Train reward: -109.22818067731255, Eval reward: -84.74793852469716, TD loss   : 52.52102364897728, Episode   :     83\n",
      "Iteration :   7700, Train reward: -116.19933199839095, Eval reward: -84.74793852469716, TD loss   : 64.96734645843506, Episode   :     84\n",
      "Iteration :   7800, Train reward: -122.41041622810096, Eval reward: -84.74793852469716, TD loss   : 54.67607830286026, Episode   :     85\n",
      "Iteration :   7900, Train reward: -117.79616541195583, Eval reward: -84.74793852469716, TD loss   : 67.81891349554061, Episode   :     86\n",
      "Iteration :   8000, Train reward: -117.79616541195583, Eval reward: -87.94906325932777, TD loss   : 63.72642689466476, Episode   :     86\n",
      "Iteration :   8100, Train reward: -115.0891711592702, Eval reward: -87.94906325932777, TD loss   : 60.81369096279144, Episode   :     88\n",
      "Iteration :   8200, Train reward: -115.0891711592702, Eval reward: -87.94906325932777, TD loss   : 75.73490060687065, Episode   :     88\n",
      "Iteration :   8300, Train reward: -113.35888769101533, Eval reward: -87.94906325932777, TD loss   : 48.15611930727959, Episode   :     89\n",
      "Iteration :   8400, Train reward: -108.79895598215697, Eval reward: -87.94906325932777, TD loss   : 61.08135573267937, Episode   :     90\n",
      "Iteration :   8500, Train reward: -109.69480468363129, Eval reward: -59.98051725959649, TD loss   : 53.144795315265654, Episode   :     91\n",
      "Iteration :   8600, Train reward: -103.54442992156453, Eval reward: -59.98051725959649, TD loss   : 56.24442463755608, Episode   :     93\n",
      "Iteration :   8700, Train reward: -105.70291609314754, Eval reward: -59.98051725959649, TD loss   : 70.69789894223213, Episode   :     94\n",
      "Iteration :   8800, Train reward: -106.38454910692539, Eval reward: -59.98051725959649, TD loss   : 63.699932312965394, Episode   :     95\n",
      "Iteration :   8900, Train reward: -107.10149071589179, Eval reward: -59.98051725959649, TD loss   : 66.0613471543789, Episode   :     96\n",
      "Iteration :   9000, Train reward: -103.73285337090972, Eval reward: -31.54653995137204, TD loss   : 69.00971628904342, Episode   :     97\n",
      "Iteration :   9100, Train reward: -98.5632274419738, Eval reward: -31.54653995137204, TD loss   : 61.37441307783127, Episode   :     98\n",
      "Iteration :   9200, Train reward: -96.76884695524693, Eval reward: -31.54653995137204, TD loss   : 41.56481726884842, Episode   :     99\n",
      "Iteration :   9300, Train reward: -96.94586120041079, Eval reward: -31.54653995137204, TD loss   : 63.51772384405136, Episode   :    100\n",
      "Iteration :   9400, Train reward: -96.94586120041079, Eval reward: -31.54653995137204, TD loss   : 54.686857380867, Episode   :    100\n",
      "Iteration :   9500, Train reward: -96.79655581452514, Eval reward: 8.757975302346862, TD loss   : 63.92983275771141, Episode   :    101\n",
      "Iteration :   9600, Train reward: -96.83335571724949, Eval reward: 8.757975302346862, TD loss   : 59.82107464194298, Episode   :    102\n",
      "Iteration :   9700, Train reward: -102.18397225635076, Eval reward: 8.757975302346862, TD loss   : 53.021304928064346, Episode   :    103\n",
      "Iteration :   9800, Train reward: -92.33774802960059, Eval reward: 8.757975302346862, TD loss   : 50.65202730417251, Episode   :    105\n",
      "Iteration :   9900, Train reward: -92.33774802960059, Eval reward: 8.757975302346862, TD loss   : 55.30185008049011, Episode   :    105\n",
      "Iteration :  10000, Train reward: -87.29531089824931, Eval reward: -125.12867530345284, TD loss   : 52.20096524715424, Episode   :    106\n",
      "Iteration :  10100, Train reward: -83.53200964715326, Eval reward: -125.12867530345284, TD loss   : 54.98770353674889, Episode   :    107\n",
      "Iteration :  10200, Train reward: -88.75948904541784, Eval reward: -125.12867530345284, TD loss   : 63.97500795006752, Episode   :    108\n",
      "Iteration :  10300, Train reward: -81.28406997023066, Eval reward: -125.12867530345284, TD loss   : 49.03506135582924, Episode   :    109\n",
      "Iteration :  10400, Train reward: -86.56645536629739, Eval reward: -125.12867530345284, TD loss   : 59.48542023420334, Episode   :    110\n",
      "Iteration :  10500, Train reward: -84.00859980292361, Eval reward: 12.384598455843284, TD loss   : 63.6611036670208, Episode   :    111\n",
      "Iteration :  10600, Train reward: -85.9527919815171, Eval reward: 12.384598455843284, TD loss   : 48.318765913248065, Episode   :    112\n",
      "Iteration :  10700, Train reward: -92.47449913172149, Eval reward: 12.384598455843284, TD loss   : 71.68575997829437, Episode   :    113\n",
      "Iteration :  10800, Train reward: -90.7944980257692, Eval reward: 12.384598455843284, TD loss   : 49.70766506791115, Episode   :    114\n",
      "Iteration :  10900, Train reward: -102.83136878046953, Eval reward: 12.384598455843284, TD loss   : 44.18222915053368, Episode   :    115\n",
      "Iteration :  11000, Train reward: -102.83136878046953, Eval reward: -36.65143693845637, TD loss   : 67.10559577703476, Episode   :    115\n",
      "Iteration :  11100, Train reward: -104.61046005594571, Eval reward: -36.65143693845637, TD loss   : 40.9992211484909, Episode   :    116\n",
      "Iteration :  11200, Train reward: -103.19821934410334, Eval reward: -36.65143693845637, TD loss   : 52.200830578804016, Episode   :    117\n",
      "Iteration :  11300, Train reward: -117.70621071242905, Eval reward: -36.65143693845637, TD loss   : 44.821902517080304, Episode   :    118\n",
      "Iteration :  11400, Train reward: -117.70621071242905, Eval reward: -36.65143693845637, TD loss   : 43.183472890853885, Episode   :    118\n",
      "Iteration :  11500, Train reward: -118.43016421258274, Eval reward: 7.30658198270041, TD loss   : 55.14896187067032, Episode   :    119\n",
      "Iteration :  11600, Train reward: -116.86189410184981, Eval reward: 7.30658198270041, TD loss   : 51.72762320280075, Episode   :    120\n",
      "Iteration :  11700, Train reward: -117.10395629630804, Eval reward: 7.30658198270041, TD loss   : 70.77259598255158, Episode   :    122\n",
      "Iteration :  11800, Train reward: -117.10395629630804, Eval reward: 7.30658198270041, TD loss   : 40.89418462753296, Episode   :    122\n",
      "Iteration :  11900, Train reward: -113.44580019774669, Eval reward: 7.30658198270041, TD loss   : 50.96033893764019, Episode   :    123\n",
      "Iteration :  12000, Train reward: -109.69457446452039, Eval reward: 23.538666335125686, TD loss   : 61.77242215871811, Episode   :    124\n",
      "Iteration :  12100, Train reward: -108.275862443558, Eval reward: 23.538666335125686, TD loss   : 45.62956120967865, Episode   :    126\n",
      "Iteration :  12200, Train reward: -110.44729384656132, Eval reward: 23.538666335125686, TD loss   : 49.17858227968216, Episode   :    127\n",
      "Iteration :  12300, Train reward: -110.44729384656132, Eval reward: 23.538666335125686, TD loss   : 50.516213898658755, Episode   :    127\n",
      "Iteration :  12400, Train reward: -107.94052272864936, Eval reward: 23.538666335125686, TD loss   : 51.76939381957054, Episode   :    128\n",
      "Iteration :  12500, Train reward: -107.94052272864936, Eval reward: 58.72018095084318, TD loss   : 54.30289093136788, Episode   :    128\n",
      "Iteration :  12600, Train reward: -104.83696008259452, Eval reward: 58.72018095084318, TD loss   : 48.816683436632154, Episode   :    129\n",
      "Iteration :  12700, Train reward: -104.83696008259452, Eval reward: 58.72018095084318, TD loss   : 62.448372166156766, Episode   :    129\n",
      "Iteration :  12800, Train reward: -99.97645835950645, Eval reward: 58.72018095084318, TD loss   : 34.71000185847282, Episode   :    130\n",
      "Iteration :  12900, Train reward: -99.97645835950645, Eval reward: 58.72018095084318, TD loss   : 51.877961362600324, Episode   :    130\n",
      "Iteration :  13000, Train reward: -101.58461711332828, Eval reward: 50.530753090989684, TD loss   : 42.921470890045164, Episode   :    131\n",
      "Iteration :  13100, Train reward: -100.36810787065758, Eval reward: 50.530753090989684, TD loss   : 58.84493444442749, Episode   :    132\n",
      "Iteration :  13200, Train reward: -115.3109093415512, Eval reward: 50.530753090989684, TD loss   : 52.367894316911695, Episode   :    133\n",
      "Iteration :  13300, Train reward: -113.8089690147413, Eval reward: 50.530753090989684, TD loss   : 44.027527256011965, Episode   :    134\n",
      "Iteration :  13400, Train reward: -97.99915439892446, Eval reward: 50.530753090989684, TD loss   : 49.09413472414017, Episode   :    135\n",
      "Iteration :  13500, Train reward: -97.99915439892446, Eval reward: 42.2566257219141, TD loss   : 46.35407816529274, Episode   :    135\n",
      "Iteration :  13600, Train reward: -95.16149539818934, Eval reward: 42.2566257219141, TD loss   : 42.85806847929955, Episode   :    136\n",
      "Iteration :  13700, Train reward: -90.97145415767044, Eval reward: 42.2566257219141, TD loss   : 43.69546196103096, Episode   :    137\n",
      "Iteration :  13800, Train reward: -78.18509374137923, Eval reward: 42.2566257219141, TD loss   : 37.832853585481644, Episode   :    138\n",
      "Iteration :  13900, Train reward: -78.18509374137923, Eval reward: 42.2566257219141, TD loss   : 39.362124650478364, Episode   :    138\n",
      "Iteration :  14000, Train reward: -75.47938234507971, Eval reward: 9.504299979597212, TD loss   : 37.55510838150978, Episode   :    139\n",
      "Iteration :  14100, Train reward: -67.89635216524604, Eval reward: 9.504299979597212, TD loss   : 39.18668670415878, Episode   :    141\n",
      "Iteration :  14200, Train reward: -67.89635216524604, Eval reward: 9.504299979597212, TD loss   : 43.48587445855141, Episode   :    141\n",
      "Iteration :  14300, Train reward: -69.62176056282698, Eval reward: 9.504299979597212, TD loss   : 48.04802128791809, Episode   :    142\n",
      "Iteration :  14400, Train reward: -69.62176056282698, Eval reward: 9.504299979597212, TD loss   : 32.838251391649244, Episode   :    142\n",
      "Iteration :  14500, Train reward: -64.65042438842406, Eval reward: 34.04894840599359, TD loss   : 38.4921012711525, Episode   :    143\n",
      "Iteration :  14600, Train reward: -63.77278657994689, Eval reward: 34.04894840599359, TD loss   : 44.60178608179093, Episode   :    144\n",
      "Iteration :  14700, Train reward: -66.6890552665402, Eval reward: 34.04894840599359, TD loss   : 37.879045000076296, Episode   :    145\n",
      "Iteration :  14800, Train reward: -66.6890552665402, Eval reward: 34.04894840599359, TD loss   : 44.364837939739225, Episode   :    145\n",
      "Iteration :  14900, Train reward: -66.81279155719287, Eval reward: 34.04894840599359, TD loss   : 35.716632812023164, Episode   :    146\n",
      "Iteration :  15000, Train reward: -66.08084211701853, Eval reward: 11.099657027961701, TD loss   : 34.89110057234764, Episode   :    147\n",
      "Iteration :  15100, Train reward: -60.38370543544623, Eval reward: 11.099657027961701, TD loss   : 32.515710028409956, Episode   :    148\n",
      "Iteration :  15200, Train reward: -60.38370543544623, Eval reward: 11.099657027961701, TD loss   : 43.095494103431705, Episode   :    148\n",
      "Iteration :  15300, Train reward: -60.38370543544623, Eval reward: 11.099657027961701, TD loss   : 39.70138776421547, Episode   :    148\n",
      "Iteration :  15400, Train reward: -54.44275418096269, Eval reward: 11.099657027961701, TD loss   : 45.510623545646666, Episode   :    149\n",
      "Iteration :  15500, Train reward: -57.47045486411615, Eval reward: -44.43150242841771, TD loss   : 32.2470634841919, Episode   :    150\n",
      "Iteration :  15600, Train reward: -56.13136015187098, Eval reward: -44.43150242841771, TD loss   : 36.41006591081619, Episode   :    152\n",
      "Iteration :  15700, Train reward: -56.13136015187098, Eval reward: -44.43150242841771, TD loss   : 45.19921908140182, Episode   :    152\n",
      "Iteration :  15800, Train reward: -33.30695027507845, Eval reward: -44.43150242841771, TD loss   : 51.169608006477354, Episode   :    153\n",
      "Iteration :  15900, Train reward: -33.30695027507845, Eval reward: -44.43150242841771, TD loss   : 45.61676340341568, Episode   :    153\n",
      "Iteration :  16000, Train reward: -32.73573748687805, Eval reward: 29.398805972694948, TD loss   : 33.30916758775711, Episode   :    154\n",
      "Iteration :  16100, Train reward: -32.43540731705412, Eval reward: 29.398805972694948, TD loss   : 36.86274376988411, Episode   :    155\n",
      "Iteration :  16200, Train reward: -33.9024824676126, Eval reward: 29.398805972694948, TD loss   : 40.08434943675995, Episode   :    156\n",
      "Iteration :  16300, Train reward: -34.7657953925949, Eval reward: 29.398805972694948, TD loss   : 46.866105864048, Episode   :    157\n",
      "Iteration :  16400, Train reward: -42.217092470829776, Eval reward: 29.398805972694948, TD loss   : 44.00515766024589, Episode   :    158\n",
      "Iteration :  16500, Train reward: -42.217092470829776, Eval reward: 8.377438482503504, TD loss   : 33.64297995686531, Episode   :    158\n",
      "Iteration :  16600, Train reward: -39.661729653276716, Eval reward: 8.377438482503504, TD loss   : 44.26585265159607, Episode   :    159\n",
      "Iteration :  16700, Train reward: -43.797488612182846, Eval reward: 8.377438482503504, TD loss   : 36.437780141830444, Episode   :    160\n",
      "Iteration :  16800, Train reward: -44.313852088545694, Eval reward: 8.377438482503504, TD loss   : 30.269317432641984, Episode   :    161\n",
      "Iteration :  16900, Train reward: -44.313852088545694, Eval reward: 8.377438482503504, TD loss   : 43.80647970318794, Episode   :    161\n",
      "Iteration :  17000, Train reward: -43.64600350003593, Eval reward: 19.834192031113098, TD loss   : 33.42808490753174, Episode   :    162\n",
      "Iteration :  17100, Train reward: -43.00623719861924, Eval reward: 19.834192031113098, TD loss   : 36.68383289337158, Episode   :    163\n",
      "Iteration :  17200, Train reward: -44.99645991387934, Eval reward: 19.834192031113098, TD loss   : 42.38211405277252, Episode   :    164\n",
      "Iteration :  17300, Train reward: -44.07612446870018, Eval reward: 19.834192031113098, TD loss   : 36.46447876751423, Episode   :    165\n",
      "Iteration :  17400, Train reward: -41.21281173580566, Eval reward: 19.834192031113098, TD loss   : 36.92750732898712, Episode   :    166\n",
      "Iteration :  17500, Train reward: -40.69255250140789, Eval reward: -27.001357520610707, TD loss   : 38.887579531669616, Episode   :    167\n",
      "Iteration :  17600, Train reward: -41.74145786394438, Eval reward: -27.001357520610707, TD loss   : 37.26853060603142, Episode   :    168\n",
      "Iteration :  17700, Train reward: -41.74145786394438, Eval reward: -27.001357520610707, TD loss   : 41.156351803541185, Episode   :    168\n",
      "Iteration :  17800, Train reward: -51.01955193203575, Eval reward: -27.001357520610707, TD loss   : 41.84761838674545, Episode   :    169\n",
      "Iteration :  17900, Train reward: -51.01955193203575, Eval reward: -27.001357520610707, TD loss   : 51.42475292563439, Episode   :    169\n",
      "Iteration :  18000, Train reward: -48.51782284949011, Eval reward: 9.94913627617614, TD loss   : 32.53831577181816, Episode   :    170\n",
      "Iteration :  18100, Train reward: -47.22771667287483, Eval reward: 9.94913627617614, TD loss   : 40.45243289351463, Episode   :    171\n",
      "Iteration :  18200, Train reward: -42.7854689404958, Eval reward: 9.94913627617614, TD loss   : 41.7029771566391, Episode   :    172\n",
      "Iteration :  18300, Train reward: -42.7854689404958, Eval reward: 9.94913627617614, TD loss   : 33.996606163978576, Episode   :    172\n",
      "Iteration :  18400, Train reward: -39.744812588383425, Eval reward: 9.94913627617614, TD loss   : 42.538511081933976, Episode   :    173\n",
      "Iteration :  18500, Train reward: -39.744812588383425, Eval reward: -2.4729245615275204, TD loss   : 34.60601090550423, Episode   :    173\n",
      "Iteration :  18600, Train reward: -35.34781734806065, Eval reward: -2.4729245615275204, TD loss   : 32.759522790312765, Episode   :    174\n",
      "Iteration :  18700, Train reward: -37.33088520183969, Eval reward: -2.4729245615275204, TD loss   : 31.53654867887497, Episode   :    175\n",
      "Iteration :  18800, Train reward: -36.88428222138684, Eval reward: -2.4729245615275204, TD loss   : 24.621817343235016, Episode   :    176\n",
      "Iteration :  18900, Train reward: -38.0166468691311, Eval reward: -2.4729245615275204, TD loss   : 34.64236278772354, Episode   :    177\n",
      "Iteration :  19000, Train reward: -38.0166468691311, Eval reward: 63.350445936800064, TD loss   : 36.17213342308998, Episode   :    177\n",
      "Iteration :  19100, Train reward: -24.99559776571371, Eval reward: 63.350445936800064, TD loss   : 34.76256379127503, Episode   :    178\n",
      "Iteration :  19200, Train reward: -29.94986393538457, Eval reward: 63.350445936800064, TD loss   : 36.19274546027184, Episode   :    179\n",
      "Iteration :  19300, Train reward: -25.52407929251682, Eval reward: 63.350445936800064, TD loss   : 35.991197259426116, Episode   :    180\n",
      "Iteration :  19400, Train reward: -25.52407929251682, Eval reward: 63.350445936800064, TD loss   : 31.43353611946106, Episode   :    180\n",
      "Iteration :  19500, Train reward: -23.95079843228725, Eval reward: -29.002788837800107, TD loss   : 33.87363208889961, Episode   :    181\n",
      "Iteration :  19600, Train reward: -17.39863094564144, Eval reward: -29.002788837800107, TD loss   : 28.791330931782724, Episode   :    182\n",
      "Iteration :  19700, Train reward: -18.100271583664558, Eval reward: -29.002788837800107, TD loss   : 38.61371365189552, Episode   :    183\n",
      "Iteration :  19800, Train reward: -14.700753454423785, Eval reward: -29.002788837800107, TD loss   : 34.331121175289155, Episode   :    184\n",
      "Iteration :  19900, Train reward: -14.700753454423785, Eval reward: -29.002788837800107, TD loss   : 35.236857974529265, Episode   :    184\n",
      "Iteration :  20000, Train reward: -14.700753454423785, Eval reward: -16.22359275013175, TD loss   : 33.819967163801195, Episode   :    184\n",
      "Iteration :  20100, Train reward: -7.765290883806978, Eval reward: -16.22359275013175, TD loss   : 36.383149104118345, Episode   :    185\n",
      "Iteration :  20200, Train reward: -6.540556086378712, Eval reward: -16.22359275013175, TD loss   : 34.342261098623275, Episode   :    186\n",
      "Iteration :  20300, Train reward: -6.540556086378712, Eval reward: -16.22359275013175, TD loss   : 39.139408919811245, Episode   :    186\n",
      "Iteration :  20400, Train reward: -6.540556086378712, Eval reward: -16.22359275013175, TD loss   : 33.25431399583817, Episode   :    186\n",
      "Iteration :  20500, Train reward: -6.682129792642567, Eval reward: -32.949298996478745, TD loss   : 40.75077616691589, Episode   :    187\n",
      "Iteration :  20600, Train reward: -5.537137223121858, Eval reward: -32.949298996478745, TD loss   : 33.27127066612243, Episode   :    188\n",
      "Iteration :  20700, Train reward: -4.251094936527332, Eval reward: -32.949298996478745, TD loss   : 30.747387733459473, Episode   :    189\n",
      "Iteration :  20800, Train reward: -4.251094936527332, Eval reward: -32.949298996478745, TD loss   : 40.19556290626526, Episode   :    189\n",
      "Iteration :  20900, Train reward: -4.251094936527332, Eval reward: -32.949298996478745, TD loss   : 40.387352689504624, Episode   :    189\n",
      "Iteration :  21000, Train reward: -3.483580055259826, Eval reward: -7.1672037783171065, TD loss   : 26.666306821107863, Episode   :    190\n",
      "Iteration :  21100, Train reward: -6.9327478477969064, Eval reward: -7.1672037783171065, TD loss   : 38.6347175526619, Episode   :    191\n",
      "Iteration :  21200, Train reward: -16.566947398368818, Eval reward: -7.1672037783171065, TD loss   : 28.89624955177307, Episode   :    192\n",
      "Iteration :  21300, Train reward: -16.566947398368818, Eval reward: -7.1672037783171065, TD loss   : 30.596191495656967, Episode   :    192\n",
      "Iteration :  21400, Train reward: -16.85142107954122, Eval reward: -7.1672037783171065, TD loss   : 43.97609300851822, Episode   :    193\n",
      "Iteration :  21500, Train reward: -19.808473723775656, Eval reward: 27.40083116518856, TD loss   : 39.71447574853897, Episode   :    194\n",
      "Iteration :  21600, Train reward: -22.310067099833027, Eval reward: 27.40083116518856, TD loss   : 37.36594008564949, Episode   :    195\n",
      "Iteration :  21700, Train reward: -21.670265685963535, Eval reward: 27.40083116518856, TD loss   : 34.20424040913582, Episode   :    197\n",
      "Iteration :  21800, Train reward: -21.670265685963535, Eval reward: 27.40083116518856, TD loss   : 33.72273936748505, Episode   :    197\n",
      "Iteration :  21900, Train reward: -21.670265685963535, Eval reward: 27.40083116518856, TD loss   : 24.890089062452315, Episode   :    197\n",
      "Iteration :  22000, Train reward: -28.381747920212547, Eval reward: 69.90757525345262, TD loss   : 30.66094826698303, Episode   :    198\n",
      "Iteration :  22100, Train reward: -22.859284649565435, Eval reward: 69.90757525345262, TD loss   : 31.552647025585173, Episode   :    199\n",
      "Iteration :  22200, Train reward: -22.859284649565435, Eval reward: 69.90757525345262, TD loss   : 43.54687913179398, Episode   :    199\n",
      "Iteration :  22300, Train reward: -22.859284649565435, Eval reward: 69.90757525345262, TD loss   : 39.13497086048126, Episode   :    199\n",
      "Iteration :  22400, Train reward: -20.581569899163814, Eval reward: 69.90757525345262, TD loss   : 36.775470998287204, Episode   :    201\n",
      "Iteration :  22500, Train reward: -20.581569899163814, Eval reward: -14.036696390702867, TD loss   : 35.72077074885368, Episode   :    201\n",
      "Iteration :  22600, Train reward: -27.282781666410898, Eval reward: -14.036696390702867, TD loss   : 54.654816353321074, Episode   :    202\n",
      "Iteration :  22700, Train reward: -27.282781666410898, Eval reward: -14.036696390702867, TD loss   : 43.965966846942905, Episode   :    202\n",
      "Iteration :  22800, Train reward: -29.626001762875376, Eval reward: -14.036696390702867, TD loss   : 36.119169751405714, Episode   :    203\n",
      "Iteration :  22900, Train reward: -29.626001762875376, Eval reward: -14.036696390702867, TD loss   : 40.57701719522476, Episode   :    203\n",
      "Iteration :  23000, Train reward: -29.626001762875376, Eval reward: 61.19461497274324, TD loss   : 35.83163028597832, Episode   :    203\n",
      "Iteration :  23100, Train reward: -22.84867726174827, Eval reward: 61.19461497274324, TD loss   : 52.33031120538712, Episode   :    204\n",
      "Iteration :  23200, Train reward: -22.84867726174827, Eval reward: 61.19461497274324, TD loss   : 26.03550949215889, Episode   :    204\n",
      "Iteration :  23300, Train reward: -22.84867726174827, Eval reward: 61.19461497274324, TD loss   : 43.06284371495247, Episode   :    204\n",
      "Iteration :  23400, Train reward: -24.914588249599266, Eval reward: 61.19461497274324, TD loss   : 33.84619227170944, Episode   :    205\n",
      "Iteration :  23500, Train reward: -35.19891697171356, Eval reward: 13.713305821460114, TD loss   : 40.194489537477494, Episode   :    206\n",
      "Iteration :  23600, Train reward: -33.046826841213246, Eval reward: 13.713305821460114, TD loss   : 35.09000389575958, Episode   :    207\n",
      "Iteration :  23700, Train reward: -31.578435790527287, Eval reward: 13.713305821460114, TD loss   : 35.24955838918686, Episode   :    208\n",
      "Iteration :  23800, Train reward: -31.578435790527287, Eval reward: 13.713305821460114, TD loss   : 34.3872914648056, Episode   :    208\n",
      "Iteration :  23900, Train reward: -31.578435790527287, Eval reward: 13.713305821460114, TD loss   : 40.72553483128548, Episode   :    208\n",
      "Iteration :  24000, Train reward: -26.252689162035757, Eval reward: -36.05580299425026, TD loss   : 29.661024891138076, Episode   :    209\n",
      "Iteration :  24100, Train reward: -26.305324373425872, Eval reward: -36.05580299425026, TD loss   : 32.40062037229538, Episode   :    210\n",
      "Iteration :  24200, Train reward: -25.95071329966462, Eval reward: -36.05580299425026, TD loss   : 25.977303749322893, Episode   :    211\n",
      "Iteration :  24300, Train reward: -25.95071329966462, Eval reward: -36.05580299425026, TD loss   : 40.23729263305664, Episode   :    211\n",
      "Iteration :  24400, Train reward: -16.483111594965873, Eval reward: -36.05580299425026, TD loss   : 40.10468038082123, Episode   :    212\n",
      "Iteration :  24500, Train reward: -16.483111594965873, Eval reward: -75.45200409338585, TD loss   : 31.70263080596924, Episode   :    212\n",
      "Iteration :  24600, Train reward: -18.19106471850582, Eval reward: -75.45200409338585, TD loss   : 34.093092843294144, Episode   :    213\n",
      "Iteration :  24700, Train reward: -18.19106471850582, Eval reward: -75.45200409338585, TD loss   : 31.4408458173275, Episode   :    213\n",
      "Iteration :  24800, Train reward: -18.19106471850582, Eval reward: -75.45200409338585, TD loss   : 39.00953579187393, Episode   :    213\n",
      "Iteration :  24900, Train reward: -12.730207104142462, Eval reward: -75.45200409338585, TD loss   : 35.23319134235382, Episode   :    214\n",
      "Iteration :  25000, Train reward: -12.730207104142462, Eval reward: -41.92054230082965, TD loss   : 24.959782383441926, Episode   :    214\n",
      "Iteration :  25100, Train reward: -1.2362669200992613, Eval reward: -41.92054230082965, TD loss   : 28.175189782381057, Episode   :    215\n",
      "Iteration :  25200, Train reward: 0.9104097094009639, Eval reward: -41.92054230082965, TD loss   : 37.454797339439395, Episode   :    216\n",
      "Iteration :  25300, Train reward: 0.9104097094009639, Eval reward: -41.92054230082965, TD loss   : 30.449966065883636, Episode   :    216\n",
      "Iteration :  25400, Train reward: 0.9104097094009639, Eval reward: -41.92054230082965, TD loss   : 36.53853177309036, Episode   :    216\n",
      "Iteration :  25500, Train reward: 4.886861543574166, Eval reward: -70.2924584382877, TD loss   : 30.75719576716423, Episode   :    217\n",
      "Iteration :  25600, Train reward: 7.2877610259031, Eval reward: -70.2924584382877, TD loss   : 34.628434215784075, Episode   :    218\n",
      "Iteration :  25700, Train reward: 7.2877610259031, Eval reward: -70.2924584382877, TD loss   : 41.29364596128464, Episode   :    218\n",
      "Iteration :  25800, Train reward: 7.2877610259031, Eval reward: -70.2924584382877, TD loss   : 25.961422222852708, Episode   :    218\n",
      "Iteration :  25900, Train reward: 10.136722428415704, Eval reward: -70.2924584382877, TD loss   : 29.66941037654877, Episode   :    219\n",
      "Iteration :  26000, Train reward: 10.136722428415704, Eval reward: -16.174311777384123, TD loss   : 30.826679792404175, Episode   :    219\n",
      "Iteration :  26100, Train reward: 6.36005849636099, Eval reward: -16.174311777384123, TD loss   : 31.842516407966613, Episode   :    220\n",
      "Iteration :  26200, Train reward: 6.36005849636099, Eval reward: -16.174311777384123, TD loss   : 32.89527641534805, Episode   :    220\n",
      "Iteration :  26300, Train reward: 3.3040328513669195, Eval reward: -16.174311777384123, TD loss   : 36.448551206588746, Episode   :    221\n",
      "Iteration :  26400, Train reward: 3.3040328513669195, Eval reward: -16.174311777384123, TD loss   : 30.317380187511443, Episode   :    221\n",
      "Iteration :  26500, Train reward: 6.4810972953633215, Eval reward: 16.5143554004741, TD loss   : 35.36568614244461, Episode   :    222\n",
      "Iteration :  26600, Train reward: 9.276959323480666, Eval reward: 16.5143554004741, TD loss   : 41.156877801418304, Episode   :    223\n",
      "Iteration :  26700, Train reward: 9.276959323480666, Eval reward: 16.5143554004741, TD loss   : 31.3566178303957, Episode   :    223\n",
      "Iteration :  26800, Train reward: -0.19199713585170386, Eval reward: 16.5143554004741, TD loss   : 26.048080703020094, Episode   :    224\n",
      "Iteration :  26900, Train reward: -0.19199713585170386, Eval reward: 16.5143554004741, TD loss   : 34.648579691648486, Episode   :    224\n",
      "Iteration :  27000, Train reward: -0.19199713585170386, Eval reward: -54.004660783815346, TD loss   : 25.815155992507936, Episode   :    224\n",
      "Iteration :  27100, Train reward: -7.109230301891614, Eval reward: -54.004660783815346, TD loss   : 37.22691864490509, Episode   :    225\n",
      "Iteration :  27200, Train reward: -7.109230301891614, Eval reward: -54.004660783815346, TD loss   : 29.30891061782837, Episode   :    225\n",
      "Iteration :  27300, Train reward: -7.109230301891614, Eval reward: -54.004660783815346, TD loss   : 26.107033451795576, Episode   :    225\n",
      "Iteration :  27400, Train reward: 5.591652308515316, Eval reward: -54.004660783815346, TD loss   : 27.348407427072527, Episode   :    226\n",
      "Iteration :  27500, Train reward: 5.591652308515316, Eval reward: -92.46654939752021, TD loss   : 32.93937539935112, Episode   :    226\n",
      "Iteration :  27600, Train reward: 1.956080840757437, Eval reward: -92.46654939752021, TD loss   : 36.909902654886245, Episode   :    227\n",
      "Iteration :  27700, Train reward: 1.956080840757437, Eval reward: -92.46654939752021, TD loss   : 30.75137365937233, Episode   :    227\n",
      "Iteration :  27800, Train reward: -0.3605686007971606, Eval reward: -92.46654939752021, TD loss   : 26.864927784204482, Episode   :    228\n",
      "Iteration :  27900, Train reward: -0.3605686007971606, Eval reward: -92.46654939752021, TD loss   : 41.524305872917175, Episode   :    228\n",
      "Iteration :  28000, Train reward: -8.73191036953866, Eval reward: -38.42568940244159, TD loss   : 26.502878538370133, Episode   :    229\n",
      "Iteration :  28100, Train reward: -6.909971973105192, Eval reward: -38.42568940244159, TD loss   : 38.417307893037794, Episode   :    230\n",
      "Iteration :  28200, Train reward: -6.909971973105192, Eval reward: -38.42568940244159, TD loss   : 34.47974095582962, Episode   :    230\n",
      "Iteration :  28300, Train reward: -6.909971973105192, Eval reward: -38.42568940244159, TD loss   : 29.760139046907426, Episode   :    230\n",
      "Iteration :  28400, Train reward: -5.141091810283295, Eval reward: -38.42568940244159, TD loss   : 37.271299469470975, Episode   :    231\n",
      "Iteration :  28500, Train reward: -5.141091810283295, Eval reward: -193.39820775162238, TD loss   : 29.51271254181862, Episode   :    231\n",
      "Iteration :  28600, Train reward: -10.619370722721616, Eval reward: -193.39820775162238, TD loss   : 24.724458988904953, Episode   :    232\n",
      "Iteration :  28700, Train reward: -10.619370722721616, Eval reward: -193.39820775162238, TD loss   : 31.712940677404404, Episode   :    232\n",
      "Iteration :  28800, Train reward: -18.950368074778286, Eval reward: -193.39820775162238, TD loss   : 30.220756789445876, Episode   :    233\n",
      "Iteration :  28900, Train reward: -18.950368074778286, Eval reward: -193.39820775162238, TD loss   : 32.74321210622787, Episode   :    233\n",
      "Iteration :  29000, Train reward: -18.950368074778286, Eval reward: 39.48856775537037, TD loss   : 28.581018333435058, Episode   :    233\n",
      "Iteration :  29100, Train reward: -19.65694136269804, Eval reward: 39.48856775537037, TD loss   : 50.02329162597656, Episode   :    234\n",
      "Iteration :  29200, Train reward: -19.65694136269804, Eval reward: 39.48856775537037, TD loss   : 24.710235159397126, Episode   :    234\n",
      "Iteration :  29300, Train reward: -19.65694136269804, Eval reward: 39.48856775537037, TD loss   : 25.509377377033232, Episode   :    234\n",
      "Iteration :  29400, Train reward: -24.923242019395296, Eval reward: 39.48856775537037, TD loss   : 34.012833398580554, Episode   :    235\n",
      "Iteration :  29500, Train reward: -24.923242019395296, Eval reward: -40.41170536932083, TD loss   : 32.74189259171486, Episode   :    235\n",
      "Iteration :  29600, Train reward: -26.42082987089496, Eval reward: -40.41170536932083, TD loss   : 45.63869061708451, Episode   :    236\n",
      "Iteration :  29700, Train reward: -26.42082987089496, Eval reward: -40.41170536932083, TD loss   : 24.975153617858886, Episode   :    236\n",
      "Iteration :  29800, Train reward: -36.3165467486654, Eval reward: -40.41170536932083, TD loss   : 36.81932032823563, Episode   :    237\n",
      "Iteration :  29900, Train reward: -36.3165467486654, Eval reward: -40.41170536932083, TD loss   : 22.74574129462242, Episode   :    237\n",
      "Iteration :  30000, Train reward: -36.3165467486654, Eval reward: -46.243224970389235, TD loss   : 26.39518356561661, Episode   :    237\n",
      "Iteration :  30100, Train reward: -34.856832238527694, Eval reward: -46.243224970389235, TD loss   : 26.009813129901886, Episode   :    238\n",
      "Iteration :  30200, Train reward: -34.856832238527694, Eval reward: -46.243224970389235, TD loss   : 40.23975998878479, Episode   :    238\n",
      "Iteration :  30300, Train reward: -43.27324977198864, Eval reward: -46.243224970389235, TD loss   : 24.682039431333543, Episode   :    239\n",
      "Iteration :  30400, Train reward: -43.27324977198864, Eval reward: -46.243224970389235, TD loss   : 26.183394392728804, Episode   :    239\n",
      "Iteration :  30500, Train reward: -51.839735148135546, Eval reward: -2.8723088022186145, TD loss   : 26.309565360546113, Episode   :    240\n",
      "Iteration :  30600, Train reward: -46.16626969782202, Eval reward: -2.8723088022186145, TD loss   : 28.978161101341247, Episode   :    241\n",
      "Iteration :  30700, Train reward: -46.16626969782202, Eval reward: -2.8723088022186145, TD loss   : 34.16805927753448, Episode   :    241\n",
      "Iteration :  30800, Train reward: -46.16626969782202, Eval reward: -2.8723088022186145, TD loss   : 34.82273144483566, Episode   :    241\n",
      "Iteration :  30900, Train reward: -43.45006812854973, Eval reward: -2.8723088022186145, TD loss   : 27.92521377325058, Episode   :    242\n",
      "Iteration :  31000, Train reward: -47.658265339104126, Eval reward: -201.9109686393627, TD loss   : 24.27559205532074, Episode   :    243\n",
      "Iteration :  31100, Train reward: -43.70607732715102, Eval reward: -201.9109686393627, TD loss   : 25.502435015439985, Episode   :    244\n",
      "Iteration :  31200, Train reward: -44.95758186420041, Eval reward: -201.9109686393627, TD loss   : 31.589148187637328, Episode   :    245\n",
      "Iteration :  31300, Train reward: -44.95758186420041, Eval reward: -201.9109686393627, TD loss   : 33.05568944692612, Episode   :    245\n",
      "Iteration :  31400, Train reward: -44.95758186420041, Eval reward: -201.9109686393627, TD loss   : 28.233443133831024, Episode   :    245\n",
      "Iteration :  31500, Train reward: -46.55498141649349, Eval reward: 14.692896854551941, TD loss   : 20.792001564502716, Episode   :    246\n",
      "Iteration :  31600, Train reward: -41.96799028036585, Eval reward: 14.692896854551941, TD loss   : 15.355855382680893, Episode   :    247\n",
      "Iteration :  31700, Train reward: -41.96799028036585, Eval reward: 14.692896854551941, TD loss   : 25.786111583709715, Episode   :    247\n",
      "Iteration :  31800, Train reward: -41.96799028036585, Eval reward: 14.692896854551941, TD loss   : 23.7306564283371, Episode   :    247\n",
      "Iteration :  31900, Train reward: -34.48704774180224, Eval reward: 14.692896854551941, TD loss   : 24.22182258486748, Episode   :    248\n",
      "Iteration :  32000, Train reward: -34.48704774180224, Eval reward: -193.65762485907004, TD loss   : 39.247324789762494, Episode   :    248\n",
      "Iteration :  32100, Train reward: -31.077528076609195, Eval reward: -193.65762485907004, TD loss   : 38.186503705978396, Episode   :    249\n",
      "Iteration :  32200, Train reward: -31.077528076609195, Eval reward: -193.65762485907004, TD loss   : 23.414352462291717, Episode   :    249\n",
      "Iteration :  32300, Train reward: -31.077528076609195, Eval reward: -193.65762485907004, TD loss   : 38.78740273952484, Episode   :    249\n",
      "Iteration :  32400, Train reward: -33.31227865704485, Eval reward: -193.65762485907004, TD loss   : 16.303523408174513, Episode   :    250\n",
      "Iteration :  32500, Train reward: -43.33916528484683, Eval reward: -55.168172304515814, TD loss   : 33.788534405231474, Episode   :    251\n",
      "Iteration :  32600, Train reward: -38.37102832963168, Eval reward: -55.168172304515814, TD loss   : 24.52008064985275, Episode   :    252\n",
      "Iteration :  32700, Train reward: -38.37102832963168, Eval reward: -55.168172304515814, TD loss   : 31.379364646673203, Episode   :    252\n",
      "Iteration :  32800, Train reward: -38.37102832963168, Eval reward: -55.168172304515814, TD loss   : 36.6418482708931, Episode   :    252\n",
      "Iteration :  32900, Train reward: -28.326473094144678, Eval reward: -55.168172304515814, TD loss   : 36.23229387164116, Episode   :    253\n",
      "Iteration :  33000, Train reward: -28.326473094144678, Eval reward: -154.48006622956004, TD loss   : 32.89118863582611, Episode   :    253\n",
      "Iteration :  33100, Train reward: -34.82773284123364, Eval reward: -154.48006622956004, TD loss   : 36.38838452458381, Episode   :    254\n",
      "Iteration :  33200, Train reward: -34.82773284123364, Eval reward: -154.48006622956004, TD loss   : 41.62646657466888, Episode   :    254\n",
      "Iteration :  33300, Train reward: -41.30163403268601, Eval reward: -154.48006622956004, TD loss   : 23.92814640045166, Episode   :    255\n",
      "Iteration :  33400, Train reward: -41.30163403268601, Eval reward: -154.48006622956004, TD loss   : 33.06418230175972, Episode   :    255\n",
      "Iteration :  33500, Train reward: -37.250734983985005, Eval reward: -33.3164265157622, TD loss   : 27.924154324531557, Episode   :    256\n",
      "Iteration :  33600, Train reward: -31.215633849701078, Eval reward: -33.3164265157622, TD loss   : 30.9789078271389, Episode   :    257\n",
      "Iteration :  33700, Train reward: -31.215633849701078, Eval reward: -33.3164265157622, TD loss   : 28.230319207906724, Episode   :    257\n",
      "Iteration :  33800, Train reward: -31.215633849701078, Eval reward: -33.3164265157622, TD loss   : 26.419414751529693, Episode   :    257\n",
      "Iteration :  33900, Train reward: -31.455272945944508, Eval reward: -33.3164265157622, TD loss   : 31.448235005140305, Episode   :    258\n",
      "Iteration :  34000, Train reward: -31.455272945944508, Eval reward: -13.37055762711139, TD loss   : 28.043948624134064, Episode   :    258\n",
      "Iteration :  34100, Train reward: -25.519007665631037, Eval reward: -13.37055762711139, TD loss   : 28.4562487244606, Episode   :    259\n",
      "Iteration :  34200, Train reward: -21.500114499657496, Eval reward: -13.37055762711139, TD loss   : 38.03992485880852, Episode   :    260\n",
      "Iteration :  34300, Train reward: -21.500114499657496, Eval reward: -13.37055762711139, TD loss   : 40.9906473505497, Episode   :    260\n",
      "Iteration :  34400, Train reward: -21.500114499657496, Eval reward: -13.37055762711139, TD loss   : 25.046515420675277, Episode   :    260\n",
      "Iteration :  34500, Train reward: -19.64586337778415, Eval reward: 5.723876572305075, TD loss   : 32.30104348301887, Episode   :    261\n",
      "Iteration :  34600, Train reward: -19.871641309938816, Eval reward: 5.723876572305075, TD loss   : 34.20314072608948, Episode   :    262\n",
      "Iteration :  34700, Train reward: -17.06196720308737, Eval reward: 5.723876572305075, TD loss   : 37.69719802856445, Episode   :    263\n",
      "Iteration :  34800, Train reward: -17.06196720308737, Eval reward: 5.723876572305075, TD loss   : 38.864883323907854, Episode   :    263\n",
      "Iteration :  34900, Train reward: -17.06196720308737, Eval reward: 5.723876572305075, TD loss   : 34.575024147033695, Episode   :    263\n",
      "Iteration :  35000, Train reward: -15.993536545652137, Eval reward: 6.849396294519562, TD loss   : 25.138737465143205, Episode   :    264\n",
      "Iteration :  35100, Train reward: -10.679256032305116, Eval reward: 6.849396294519562, TD loss   : 30.682354521751403, Episode   :    265\n",
      "Iteration :  35200, Train reward: -10.679256032305116, Eval reward: 6.849396294519562, TD loss   : 23.155756610631943, Episode   :    265\n",
      "Iteration :  35300, Train reward: -11.533325208101902, Eval reward: 6.849396294519562, TD loss   : 23.594991308450698, Episode   :    266\n",
      "Iteration :  35400, Train reward: -11.533325208101902, Eval reward: 6.849396294519562, TD loss   : 37.94073558092117, Episode   :    266\n",
      "Iteration :  35500, Train reward: -11.533325208101902, Eval reward: 5.115306162793056, TD loss   : 34.56730708837509, Episode   :    266\n",
      "Iteration :  35600, Train reward: -11.76014135078594, Eval reward: 5.115306162793056, TD loss   : 27.923534202575684, Episode   :    267\n",
      "Iteration :  35700, Train reward: -22.918160633107437, Eval reward: 5.115306162793056, TD loss   : 34.46261384725571, Episode   :    268\n",
      "Iteration :  35800, Train reward: -22.918160633107437, Eval reward: 5.115306162793056, TD loss   : 32.30987864494324, Episode   :    268\n",
      "Iteration :  35900, Train reward: -22.918160633107437, Eval reward: 5.115306162793056, TD loss   : 26.300056228637697, Episode   :    268\n",
      "Iteration :  36000, Train reward: -18.309577559881685, Eval reward: 7.261707284503396, TD loss   : 25.642034200429915, Episode   :    269\n",
      "Iteration :  36100, Train reward: -17.369283437917183, Eval reward: 7.261707284503396, TD loss   : 32.11833206534386, Episode   :    270\n",
      "Iteration :  36200, Train reward: -17.369283437917183, Eval reward: 7.261707284503396, TD loss   : 36.94604627370834, Episode   :    270\n",
      "Iteration :  36300, Train reward: -17.369283437917183, Eval reward: 7.261707284503396, TD loss   : 39.42794550180435, Episode   :    270\n",
      "Iteration :  36400, Train reward: -8.692589063913035, Eval reward: 7.261707284503396, TD loss   : 27.797674348354338, Episode   :    271\n",
      "Iteration :  36500, Train reward: -8.692589063913035, Eval reward: 16.916293900649528, TD loss   : 25.076565096378328, Episode   :    271\n",
      "Iteration :  36600, Train reward: -18.165470362443138, Eval reward: 16.916293900649528, TD loss   : 35.74458821415901, Episode   :    272\n",
      "Iteration :  36700, Train reward: -18.165470362443138, Eval reward: 16.916293900649528, TD loss   : 27.689395822286606, Episode   :    272\n",
      "Iteration :  36800, Train reward: -18.165470362443138, Eval reward: 16.916293900649528, TD loss   : 40.158323314189914, Episode   :    272\n",
      "Iteration :  36900, Train reward: -15.299835341316086, Eval reward: 16.916293900649528, TD loss   : 31.024271367788316, Episode   :    273\n",
      "Iteration :  37000, Train reward: -15.299835341316086, Eval reward: -100.7441441955931, TD loss   : 39.66791160941124, Episode   :    273\n",
      "Iteration :  37100, Train reward: -8.863538221918205, Eval reward: -100.7441441955931, TD loss   : 32.005056462287904, Episode   :    274\n",
      "Iteration :  37200, Train reward: -8.863538221918205, Eval reward: -100.7441441955931, TD loss   : 42.548881683349606, Episode   :    274\n",
      "Iteration :  37300, Train reward: -8.863538221918205, Eval reward: -100.7441441955931, TD loss   : 28.188056020736695, Episode   :    274\n",
      "Iteration :  37400, Train reward: -1.0478485830177136, Eval reward: -100.7441441955931, TD loss   : 28.52294378042221, Episode   :    275\n",
      "Iteration :  37500, Train reward: -1.0478485830177136, Eval reward: -11.30274311484848, TD loss   : 29.984831583499908, Episode   :    275\n",
      "Iteration :  37600, Train reward: -3.166876071445743, Eval reward: -11.30274311484848, TD loss   : 34.35286034822464, Episode   :    276\n",
      "Iteration :  37700, Train reward: -3.166876071445743, Eval reward: -11.30274311484848, TD loss   : 30.047802379131316, Episode   :    276\n",
      "Iteration :  37800, Train reward: -3.166876071445743, Eval reward: -11.30274311484848, TD loss   : 34.61469070672989, Episode   :    276\n",
      "Iteration :  37900, Train reward: -0.7026173804055539, Eval reward: -11.30274311484848, TD loss   : 30.318633675575256, Episode   :    277\n",
      "Iteration :  38000, Train reward: -0.7026173804055539, Eval reward: -91.08731814337698, TD loss   : 31.25060464501381, Episode   :    277\n",
      "Iteration :  38100, Train reward: -7.91032577250261, Eval reward: -91.08731814337698, TD loss   : 30.415305552482604, Episode   :    278\n",
      "Iteration :  38200, Train reward: -7.91032577250261, Eval reward: -91.08731814337698, TD loss   : 33.32625441670418, Episode   :    278\n",
      "Iteration :  38300, Train reward: -7.91032577250261, Eval reward: -91.08731814337698, TD loss   : 38.409022092819214, Episode   :    278\n",
      "Iteration :  38400, Train reward: -6.021383759239544, Eval reward: -91.08731814337698, TD loss   : 30.27934909105301, Episode   :    279\n",
      "Iteration :  38500, Train reward: -6.021383759239544, Eval reward: 8.43183799679817, TD loss   : 28.881803971529006, Episode   :    279\n",
      "Iteration :  38600, Train reward: -2.4248152905471265, Eval reward: 8.43183799679817, TD loss   : 22.876628702878953, Episode   :    280\n",
      "Iteration :  38700, Train reward: -2.4248152905471265, Eval reward: 8.43183799679817, TD loss   : 24.676643513441086, Episode   :    280\n",
      "Iteration :  38800, Train reward: -2.4248152905471265, Eval reward: 8.43183799679817, TD loss   : 38.394853241443634, Episode   :    280\n",
      "Iteration :  38900, Train reward: -6.72455203456919, Eval reward: 8.43183799679817, TD loss   : 28.072883129119873, Episode   :    281\n",
      "Iteration :  39000, Train reward: -6.72455203456919, Eval reward: 4.881195829301151, TD loss   : 21.936485574245452, Episode   :    281\n",
      "Iteration :  39100, Train reward: -9.177685046243758, Eval reward: 4.881195829301151, TD loss   : 23.40122534394264, Episode   :    282\n",
      "Iteration :  39200, Train reward: -9.177685046243758, Eval reward: 4.881195829301151, TD loss   : 23.625111503601076, Episode   :    282\n",
      "Iteration :  39300, Train reward: -9.177685046243758, Eval reward: 4.881195829301151, TD loss   : 36.7993205010891, Episode   :    282\n",
      "Iteration :  39400, Train reward: -6.03924630718345, Eval reward: 4.881195829301151, TD loss   : 34.564953068494795, Episode   :    283\n",
      "Iteration :  39500, Train reward: -6.03924630718345, Eval reward: 12.63927952944484, TD loss   : 36.66763527154922, Episode   :    283\n",
      "Iteration :  39600, Train reward: -9.766417398343979, Eval reward: 12.63927952944484, TD loss   : 21.222183730602264, Episode   :    284\n",
      "Iteration :  39700, Train reward: -9.766417398343979, Eval reward: 12.63927952944484, TD loss   : 27.94817623257637, Episode   :    284\n",
      "Iteration :  39800, Train reward: -9.766417398343979, Eval reward: 12.63927952944484, TD loss   : 27.248123140335082, Episode   :    284\n",
      "Iteration :  39900, Train reward: -5.247937830110748, Eval reward: 12.63927952944484, TD loss   : 26.01909973025322, Episode   :    285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HasanErdin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\HasanErdin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :      0, Train reward:    nan, Eval reward: -590.8867900128729, TD loss   :    nan, Episode   :      0\n",
      "Iteration :    100, Train reward: -98.75542784869147, Eval reward: -590.8867900128729, TD loss   : 316.9051818847656, Episode   :      1\n",
      "Iteration :    200, Train reward: -241.93429851156927, Eval reward: -590.8867900128729, TD loss   : 129.68815861940385, Episode   :      2\n",
      "Iteration :    300, Train reward: -199.74592452008832, Eval reward: -590.8867900128729, TD loss   : 99.82859238147735, Episode   :      3\n",
      "Iteration :    400, Train reward: -235.8253783239333, Eval reward: -590.8867900128729, TD loss   : 80.80057673931123, Episode   :      4\n",
      "Iteration :    500, Train reward: -212.7923498716178, Eval reward: -489.3482811598068, TD loss   : 104.37889470815658, Episode   :      5\n",
      "Iteration :    600, Train reward: -189.31773035475968, Eval reward: -489.3482811598068, TD loss   : 109.85372252225876, Episode   :      7\n",
      "Iteration :    700, Train reward: -189.31773035475968, Eval reward: -489.3482811598068, TD loss   : 94.931967856884, Episode   :      7\n",
      "Iteration :    800, Train reward: -199.57706503777717, Eval reward: -489.3482811598068, TD loss   : 89.89129946231841, Episode   :      9\n",
      "Iteration :    900, Train reward: -199.85477460617182, Eval reward: -489.3482811598068, TD loss   : 85.32059223413468, Episode   :     10\n",
      "Iteration :   1000, Train reward: -189.89380410295564, Eval reward: -629.2310063230451, TD loss   : 86.35352328777313, Episode   :     11\n",
      "Iteration :   1100, Train reward: -182.73237039915227, Eval reward: -629.2310063230451, TD loss   : 86.93851907968521, Episode   :     12\n",
      "Iteration :   1200, Train reward: -186.66206972972816, Eval reward: -629.2310063230451, TD loss   : 76.90517663002014, Episode   :     13\n",
      "Iteration :   1300, Train reward: -181.11185145816293, Eval reward: -629.2310063230451, TD loss   : 63.70647867679596, Episode   :     14\n",
      "Iteration :   1400, Train reward: -177.83240936725488, Eval reward: -629.2310063230451, TD loss   : 74.54148475170136, Episode   :     15\n",
      "Iteration :   1500, Train reward: -167.3596294963032, Eval reward: -73.49156242748543, TD loss   : 66.66128443479538, Episode   :     17\n",
      "Iteration :   1600, Train reward: -163.62922735809357, Eval reward: -73.49156242748543, TD loss   : 74.15526943206787, Episode   :     18\n",
      "Iteration :   1700, Train reward: -160.423781808718, Eval reward: -73.49156242748543, TD loss   : 68.8551795911789, Episode   :     20\n",
      "Iteration :   1800, Train reward: -169.71403304252394, Eval reward: -73.49156242748543, TD loss   : 67.80453404664993, Episode   :     21\n",
      "Iteration :   1900, Train reward: -155.12626880829012, Eval reward: -73.49156242748543, TD loss   : 86.00003322839737, Episode   :     22\n",
      "Iteration :   2000, Train reward: -159.0428623582791, Eval reward: -53.43300625429494, TD loss   : 61.6525263607502, Episode   :     23\n",
      "Iteration :   2100, Train reward: -160.11647556074067, Eval reward: -53.43300625429494, TD loss   : 77.7470494556427, Episode   :     25\n",
      "Iteration :   2200, Train reward: -160.11647556074067, Eval reward: -53.43300625429494, TD loss   : 78.61468085765839, Episode   :     25\n",
      "Iteration :   2300, Train reward: -166.63677164769499, Eval reward: -53.43300625429494, TD loss   : 82.02978910684585, Episode   :     26\n",
      "Iteration :   2400, Train reward: -164.45865303160332, Eval reward: -53.43300625429494, TD loss   : 71.03189578056336, Episode   :     27\n",
      "Iteration :   2500, Train reward: -150.63546597098616, Eval reward: -286.14028854518267, TD loss   : 61.16672653198242, Episode   :     28\n",
      "Iteration :   2600, Train reward: -154.40004771498147, Eval reward: -286.14028854518267, TD loss   : 69.80447169065475, Episode   :     29\n",
      "Iteration :   2700, Train reward: -155.0271302254022, Eval reward: -286.14028854518267, TD loss   : 53.41056600093842, Episode   :     30\n",
      "Iteration :   2800, Train reward: -153.85800678840968, Eval reward: -286.14028854518267, TD loss   : 52.02968965172768, Episode   :     31\n",
      "Iteration :   2900, Train reward: -157.2005622445763, Eval reward: -286.14028854518267, TD loss   : 52.315527037382125, Episode   :     32\n",
      "Iteration :   3000, Train reward: -149.89337380345293, Eval reward: -209.31597018604606, TD loss   : 61.89618029594421, Episode   :     33\n",
      "Iteration :   3100, Train reward: -149.6186478488029, Eval reward: -209.31597018604606, TD loss   : 56.962049260139466, Episode   :     34\n",
      "Iteration :   3200, Train reward: -149.6186478488029, Eval reward: -209.31597018604606, TD loss   : 57.2011997282505, Episode   :     34\n",
      "Iteration :   3300, Train reward: -145.27906429846976, Eval reward: -209.31597018604606, TD loss   : 44.3985145354271, Episode   :     35\n",
      "Iteration :   3400, Train reward: -146.40302585804218, Eval reward: -209.31597018604606, TD loss   : 61.30137861251831, Episode   :     36\n",
      "Iteration :   3500, Train reward: -149.58452570390688, Eval reward: -134.4804767592932, TD loss   : 35.2519005727768, Episode   :     37\n",
      "Iteration :   3600, Train reward: -146.6468549060091, Eval reward: -134.4804767592932, TD loss   : 58.90306783556938, Episode   :     39\n",
      "Iteration :   3700, Train reward: -146.6468549060091, Eval reward: -134.4804767592932, TD loss   : 51.771659054756164, Episode   :     39\n",
      "Iteration :   3800, Train reward: -160.6723191316847, Eval reward: -134.4804767592932, TD loss   : 66.31956148743629, Episode   :     40\n",
      "Iteration :   3900, Train reward: -155.29989311726783, Eval reward: -134.4804767592932, TD loss   : 72.27383925795556, Episode   :     41\n",
      "Iteration :   4000, Train reward: -164.86657428746759, Eval reward: 32.75180409649379, TD loss   : 74.3128542304039, Episode   :     42\n",
      "Iteration :   4100, Train reward: -155.092785635526, Eval reward: 32.75180409649379, TD loss   : 62.327067912817, Episode   :     43\n",
      "Iteration :   4200, Train reward: -163.6370129084512, Eval reward: 32.75180409649379, TD loss   : 69.35678528308868, Episode   :     44\n",
      "Iteration :   4300, Train reward: -152.45953413560466, Eval reward: 32.75180409649379, TD loss   : 55.71313400745392, Episode   :     45\n",
      "Iteration :   4400, Train reward: -145.83793826290562, Eval reward: 32.75180409649379, TD loss   : 55.55094385147095, Episode   :     46\n",
      "Iteration :   4500, Train reward: -144.50133796353924, Eval reward: -44.51515448871645, TD loss   : 54.223436864614484, Episode   :     47\n",
      "Iteration :   4600, Train reward: -146.8275707971552, Eval reward: -44.51515448871645, TD loss   : 51.503837699890134, Episode   :     48\n",
      "Iteration :   4700, Train reward: -140.70162488094016, Eval reward: -44.51515448871645, TD loss   : 61.18109398007393, Episode   :     50\n",
      "Iteration :   4800, Train reward: -154.83021115847123, Eval reward: -44.51515448871645, TD loss   : 62.63223569393158, Episode   :     51\n",
      "Iteration :   4900, Train reward: -153.1088911967094, Eval reward: -44.51515448871645, TD loss   : 59.420585968494414, Episode   :     52\n",
      "Iteration :   5000, Train reward: -155.57140357580687, Eval reward: -246.98619562657322, TD loss   : 68.74182058691979, Episode   :     53\n",
      "Iteration :   5100, Train reward: -159.09060834882206, Eval reward: -246.98619562657322, TD loss   : 67.8775177526474, Episode   :     55\n",
      "Iteration :   5200, Train reward: -166.85047059603727, Eval reward: -246.98619562657322, TD loss   : 56.25958876132965, Episode   :     56\n",
      "Iteration :   5300, Train reward: -161.31151053157984, Eval reward: -246.98619562657322, TD loss   : 58.479757302999495, Episode   :     57\n",
      "Iteration :   5400, Train reward: -163.6135324554014, Eval reward: -246.98619562657322, TD loss   : 47.88164327263832, Episode   :     58\n",
      "Iteration :   5500, Train reward: -166.41657454624684, Eval reward: -43.97849524625163, TD loss   : 53.737397528886795, Episode   :     59\n",
      "Iteration :   5600, Train reward: -158.35621522529652, Eval reward: -43.97849524625163, TD loss   : 57.658917223215106, Episode   :     61\n",
      "Iteration :   5700, Train reward: -152.76857419325137, Eval reward: -43.97849524625163, TD loss   : 73.43985206484794, Episode   :     62\n",
      "Iteration :   5800, Train reward: -152.76857419325137, Eval reward: -43.97849524625163, TD loss   : 61.16630621433258, Episode   :     62\n",
      "Iteration :   5900, Train reward: -160.7371089954831, Eval reward: -43.97849524625163, TD loss   : 61.41165733337402, Episode   :     63\n",
      "Iteration :   6000, Train reward: -145.2214950074155, Eval reward: -132.01898629463423, TD loss   : 65.33836931467056, Episode   :     64\n",
      "Iteration :   6100, Train reward: -144.15200865635217, Eval reward: -132.01898629463423, TD loss   : 54.41147304415703, Episode   :     65\n",
      "Iteration :   6200, Train reward: -147.5707140783776, Eval reward: -132.01898629463423, TD loss   : 43.16346125602722, Episode   :     67\n",
      "Iteration :   6300, Train reward: -145.28306780404148, Eval reward: -132.01898629463423, TD loss   : 58.22478164196014, Episode   :     68\n",
      "Iteration :   6400, Train reward: -145.28306780404148, Eval reward: -132.01898629463423, TD loss   : 49.41283481478691, Episode   :     68\n",
      "Iteration :   6500, Train reward: -143.42121174042916, Eval reward: -71.20883179151058, TD loss   : 52.76708458304405, Episode   :     69\n",
      "Iteration :   6600, Train reward: -141.02618736450248, Eval reward: -71.20883179151058, TD loss   : 60.66573298335075, Episode   :     70\n",
      "Iteration :   6700, Train reward: -129.5280260450203, Eval reward: -71.20883179151058, TD loss   : 50.85369630217552, Episode   :     71\n",
      "Iteration :   6800, Train reward: -126.14969158675831, Eval reward: -71.20883179151058, TD loss   : 55.08508894920349, Episode   :     72\n",
      "Iteration :   6900, Train reward: -121.8949429042647, Eval reward: -71.20883179151058, TD loss   : 50.307605534791946, Episode   :     73\n",
      "Iteration :   7000, Train reward: -122.76406659956733, Eval reward: -73.75250742324941, TD loss   : 53.73803811311722, Episode   :     74\n",
      "Iteration :   7100, Train reward: -116.65030218639359, Eval reward: -73.75250742324941, TD loss   : 52.71558126807213, Episode   :     75\n",
      "Iteration :   7200, Train reward: -112.90095019490744, Eval reward: -73.75250742324941, TD loss   : 44.40490813493729, Episode   :     76\n",
      "Iteration :   7300, Train reward: -115.39245974223331, Eval reward: -73.75250742324941, TD loss   : 52.24549092650413, Episode   :     77\n",
      "Iteration :   7400, Train reward: -120.54405772118484, Eval reward: -73.75250742324941, TD loss   : 50.48859855055809, Episode   :     78\n",
      "Iteration :   7500, Train reward: -110.63551177897212, Eval reward: -19.48463489196643, TD loss   : 50.29306262850761, Episode   :     79\n",
      "Iteration :   7600, Train reward: -103.36057556679592, Eval reward: -19.48463489196643, TD loss   : 36.43070873737335, Episode   :     80\n",
      "Iteration :   7700, Train reward: -97.12023587432944, Eval reward: -19.48463489196643, TD loss   : 44.14155965447426, Episode   :     81\n",
      "Iteration :   7800, Train reward: -96.70206651567554, Eval reward: -19.48463489196643, TD loss   : 36.941431605815886, Episode   :     82\n",
      "Iteration :   7900, Train reward: -88.46977308882256, Eval reward: -19.48463489196643, TD loss   : 41.03752933204174, Episode   :     83\n",
      "Iteration :   8000, Train reward: -96.3465605834353, Eval reward: -17.94914630211188, TD loss   : 32.738467121124266, Episode   :     84\n",
      "Iteration :   8100, Train reward: -91.09167563124937, Eval reward: -17.94914630211188, TD loss   : 69.7737528026104, Episode   :     85\n",
      "Iteration :   8200, Train reward: -85.64882599042416, Eval reward: -17.94914630211188, TD loss   : 47.50051647424698, Episode   :     86\n",
      "Iteration :   8300, Train reward: -83.48590273896323, Eval reward: -17.94914630211188, TD loss   : 36.48075203418732, Episode   :     87\n",
      "Iteration :   8400, Train reward: -85.35590289550755, Eval reward: -17.94914630211188, TD loss   : 42.41067285299301, Episode   :     88\n",
      "Iteration :   8500, Train reward: -93.55735179204204, Eval reward: -23.746963494009997, TD loss   : 43.45374724030495, Episode   :     89\n",
      "Iteration :   8600, Train reward: -92.47407353053876, Eval reward: -23.746963494009997, TD loss   : 52.40953212380409, Episode   :     90\n",
      "Iteration :   8700, Train reward: -93.40661698755329, Eval reward: -23.746963494009997, TD loss   : 35.469329105615614, Episode   :     91\n",
      "Iteration :   8800, Train reward: -94.02123402684128, Eval reward: -23.746963494009997, TD loss   : 39.960096147656444, Episode   :     92\n",
      "Iteration :   8900, Train reward: -94.73575103450831, Eval reward: -23.746963494009997, TD loss   : 36.626694377660755, Episode   :     93\n",
      "Iteration :   9000, Train reward: -91.66229946904197, Eval reward: 12.502339838539033, TD loss   : 39.30054599702358, Episode   :     94\n",
      "Iteration :   9100, Train reward: -88.69380506519124, Eval reward: 12.502339838539033, TD loss   : 43.589021669626234, Episode   :     96\n",
      "Iteration :   9200, Train reward: -85.53101808346841, Eval reward: 12.502339838539033, TD loss   : 47.34040942668915, Episode   :     97\n",
      "Iteration :   9300, Train reward: -95.700053252018, Eval reward: 12.502339838539033, TD loss   : 44.04471444249153, Episode   :     98\n",
      "Iteration :   9400, Train reward: -105.65886675311303, Eval reward: 12.502339838539033, TD loss   : 46.29326330780983, Episode   :     99\n",
      "Iteration :   9500, Train reward: -114.46168255869449, Eval reward: -24.61195536886375, TD loss   : 47.010229785442355, Episode   :    100\n",
      "Iteration :   9600, Train reward: -115.9286226491209, Eval reward: -24.61195536886375, TD loss   : 48.274757043123245, Episode   :    101\n",
      "Iteration :   9700, Train reward: -116.43156983787397, Eval reward: -24.61195536886375, TD loss   : 43.104960366487504, Episode   :    103\n",
      "Iteration :   9800, Train reward: -116.43156983787397, Eval reward: -24.61195536886375, TD loss   : 47.36203630328178, Episode   :    103\n",
      "Iteration :   9900, Train reward: -110.86647620609999, Eval reward: -24.61195536886375, TD loss   : 39.95044074296951, Episode   :    104\n",
      "Iteration :  10000, Train reward: -114.03841000341257, Eval reward: -25.943853419163947, TD loss   : 36.816964911222456, Episode   :    105\n",
      "Iteration :  10100, Train reward: -112.10225083521402, Eval reward: -25.943853419163947, TD loss   : 52.772702057361606, Episode   :    106\n",
      "Iteration :  10200, Train reward: -108.52125801074472, Eval reward: -25.943853419163947, TD loss   : 44.376859132051464, Episode   :    108\n",
      "Iteration :  10300, Train reward: -108.52125801074472, Eval reward: -25.943853419163947, TD loss   : 39.03310763955116, Episode   :    108\n",
      "Iteration :  10400, Train reward: -97.80281542673164, Eval reward: -25.943853419163947, TD loss   : 38.54310258746147, Episode   :    109\n",
      "Iteration :  10500, Train reward: -106.7724906140688, Eval reward: -11.723762459433368, TD loss   : 34.10029388308525, Episode   :    110\n",
      "Iteration :  10600, Train reward: -99.72172638712327, Eval reward: -11.723762459433368, TD loss   : 48.53382779657841, Episode   :    111\n",
      "Iteration :  10700, Train reward: -99.93965261025114, Eval reward: -11.723762459433368, TD loss   : 47.277280840873715, Episode   :    112\n",
      "Iteration :  10800, Train reward: -101.67978303144038, Eval reward: -11.723762459433368, TD loss   : 45.82040608048439, Episode   :    113\n",
      "Iteration :  10900, Train reward: -102.74659975460725, Eval reward: -11.723762459433368, TD loss   : 41.32230725288391, Episode   :    114\n",
      "Iteration :  11000, Train reward: -102.74659975460725, Eval reward: -24.412928379441603, TD loss   : 42.80983122110367, Episode   :    114\n",
      "Iteration :  11100, Train reward: -103.68896819258362, Eval reward: -24.412928379441603, TD loss   : 32.65747886419296, Episode   :    115\n",
      "Iteration :  11200, Train reward: -101.47087979059737, Eval reward: -24.412928379441603, TD loss   : 53.16389618039131, Episode   :    116\n",
      "Iteration :  11300, Train reward: -106.43152637080496, Eval reward: -24.412928379441603, TD loss   : 51.283875803947446, Episode   :    117\n",
      "Iteration :  11400, Train reward: -106.43152637080496, Eval reward: -24.412928379441603, TD loss   : 45.817051141262056, Episode   :    117\n",
      "Iteration :  11500, Train reward: -92.67993401672717, Eval reward: 20.88062136592847, TD loss   : 41.49922387123108, Episode   :    118\n",
      "Iteration :  11600, Train reward: -79.63556511381128, Eval reward: 20.88062136592847, TD loss   : 45.2439781999588, Episode   :    119\n",
      "Iteration :  11700, Train reward: -71.41969351345486, Eval reward: 20.88062136592847, TD loss   : 39.68820128560066, Episode   :    120\n",
      "Iteration :  11800, Train reward: -67.19561051494254, Eval reward: 20.88062136592847, TD loss   : 43.98104884386063, Episode   :    121\n",
      "Iteration :  11900, Train reward: -66.0413271127027, Eval reward: 20.88062136592847, TD loss   : 44.86911709427834, Episode   :    122\n",
      "Iteration :  12000, Train reward: -66.0413271127027, Eval reward: -10.713751549742573, TD loss   : 37.14452797293663, Episode   :    122\n",
      "Iteration :  12100, Train reward: -73.0532215082234, Eval reward: -10.713751549742573, TD loss   : 41.778564586639405, Episode   :    124\n",
      "Iteration :  12200, Train reward: -73.0532215082234, Eval reward: -10.713751549742573, TD loss   : 34.13095710754394, Episode   :    124\n",
      "Iteration :  12300, Train reward: -75.33952778021177, Eval reward: -10.713751549742573, TD loss   : 40.51697015523911, Episode   :    125\n",
      "Iteration :  12400, Train reward: -77.36251936726444, Eval reward: -10.713751549742573, TD loss   : 37.603392214775084, Episode   :    126\n",
      "Iteration :  12500, Train reward: -78.91836440364632, Eval reward: -16.39337247281879, TD loss   : 33.41734171509743, Episode   :    127\n",
      "Iteration :  12600, Train reward: -79.1437598545644, Eval reward: -16.39337247281879, TD loss   : 34.40499307870865, Episode   :    128\n",
      "Iteration :  12700, Train reward: -80.5711461989623, Eval reward: -16.39337247281879, TD loss   : 36.62312566637993, Episode   :    129\n",
      "Iteration :  12800, Train reward: -76.71930180603742, Eval reward: -16.39337247281879, TD loss   : 42.82222667217255, Episode   :    130\n",
      "Iteration :  12900, Train reward: -76.71930180603742, Eval reward: -16.39337247281879, TD loss   : 34.01489717125892, Episode   :    130\n",
      "Iteration :  13000, Train reward: -76.67533255143455, Eval reward: 9.84658274390988, TD loss   : 40.6596264564991, Episode   :    131\n",
      "Iteration :  13100, Train reward: -72.35655475067662, Eval reward: 9.84658274390988, TD loss   : 36.796574079990386, Episode   :    132\n",
      "Iteration :  13200, Train reward: -74.16528703339596, Eval reward: 9.84658274390988, TD loss   : 30.16898051261902, Episode   :    133\n",
      "Iteration :  13300, Train reward: -69.47691355429679, Eval reward: 9.84658274390988, TD loss   : 41.228875888586046, Episode   :    134\n",
      "Iteration :  13400, Train reward: -69.47691355429679, Eval reward: 9.84658274390988, TD loss   : 42.05588158965111, Episode   :    134\n",
      "Iteration :  13500, Train reward: -68.72537549715643, Eval reward: 34.918712248926894, TD loss   : 33.998364807367324, Episode   :    135\n",
      "Iteration :  13600, Train reward: -68.07727703363483, Eval reward: 34.918712248926894, TD loss   : 36.283124232292174, Episode   :    136\n",
      "Iteration :  13700, Train reward: -61.302218980910766, Eval reward: 34.918712248926894, TD loss   : 26.390112859010696, Episode   :    137\n",
      "Iteration :  13800, Train reward: -61.302218980910766, Eval reward: 34.918712248926894, TD loss   : 37.43287896037102, Episode   :    137\n",
      "Iteration :  13900, Train reward: -58.85736859797703, Eval reward: 34.918712248926894, TD loss   : 38.65912952899933, Episode   :    138\n",
      "Iteration :  14000, Train reward: -58.85736859797703, Eval reward: -18.935539150808665, TD loss   : 43.30511829614639, Episode   :    138\n",
      "Iteration :  14100, Train reward: -63.31821400833845, Eval reward: -18.935539150808665, TD loss   : 34.141527392864226, Episode   :    139\n",
      "Iteration :  14200, Train reward: -66.95903134877805, Eval reward: -18.935539150808665, TD loss   : 33.61965993762016, Episode   :    140\n",
      "Iteration :  14300, Train reward: -69.97533063421159, Eval reward: -18.935539150808665, TD loss   : 37.10770856499672, Episode   :    141\n",
      "Iteration :  14400, Train reward: -71.7223153761053, Eval reward: -18.935539150808665, TD loss   : 32.277282655239105, Episode   :    142\n",
      "Iteration :  14500, Train reward: -71.7223153761053, Eval reward: 4.061110016262195, TD loss   : 29.419646714925765, Episode   :    142\n",
      "Iteration :  14600, Train reward: -65.85849477713991, Eval reward: 4.061110016262195, TD loss   : 34.37953320980072, Episode   :    143\n",
      "Iteration :  14700, Train reward: -73.1876118932911, Eval reward: 4.061110016262195, TD loss   : 36.89722187876701, Episode   :    144\n",
      "Iteration :  14800, Train reward: -73.1876118932911, Eval reward: 4.061110016262195, TD loss   : 36.05251103043556, Episode   :    144\n",
      "Iteration :  14900, Train reward: -71.20068117118174, Eval reward: 4.061110016262195, TD loss   : 45.15465819716454, Episode   :    145\n",
      "Iteration :  15000, Train reward: -77.45279015798583, Eval reward: -7.537574760464802, TD loss   : 31.53742037177086, Episode   :    146\n",
      "Iteration :  15100, Train reward: -75.48419408989763, Eval reward: -7.537574760464802, TD loss   : 31.833360137939454, Episode   :    147\n",
      "Iteration :  15200, Train reward: -75.10154556845416, Eval reward: -7.537574760464802, TD loss   : 38.583934110403064, Episode   :    148\n",
      "Iteration :  15300, Train reward: -73.96276880477416, Eval reward: -7.537574760464802, TD loss   : 46.85349352777004, Episode   :    149\n",
      "Iteration :  15400, Train reward: -69.08721697364685, Eval reward: -7.537574760464802, TD loss   : 39.48550593852997, Episode   :    150\n",
      "Iteration :  15500, Train reward: -71.93549803733787, Eval reward: 51.27485183328415, TD loss   : 28.472770552635193, Episode   :    151\n",
      "Iteration :  15600, Train reward: -67.48519531302355, Eval reward: 51.27485183328415, TD loss   : 33.782893205881116, Episode   :    152\n",
      "Iteration :  15700, Train reward: -67.48519531302355, Eval reward: 51.27485183328415, TD loss   : 42.134586656093596, Episode   :    152\n",
      "Iteration :  15800, Train reward: -61.21463626982454, Eval reward: 51.27485183328415, TD loss   : 32.950829972028735, Episode   :    153\n",
      "Iteration :  15900, Train reward: -64.6488028286781, Eval reward: 51.27485183328415, TD loss   : 36.01505694150924, Episode   :    154\n",
      "Iteration :  16000, Train reward: -64.6488028286781, Eval reward: 17.046380757477085, TD loss   : 34.34490899562836, Episode   :    154\n",
      "Iteration :  16100, Train reward: -65.28914875389123, Eval reward: 17.046380757477085, TD loss   : 33.47719167709351, Episode   :    155\n",
      "Iteration :  16200, Train reward: -66.86482372787353, Eval reward: 17.046380757477085, TD loss   : 35.22720906972885, Episode   :    156\n",
      "Iteration :  16300, Train reward: -66.86482372787353, Eval reward: 17.046380757477085, TD loss   : 28.007712337970734, Episode   :    156\n",
      "Iteration :  16400, Train reward: -67.49577354618145, Eval reward: 17.046380757477085, TD loss   : 31.914424340724945, Episode   :    157\n",
      "Iteration :  16500, Train reward: -67.49577354618145, Eval reward: -52.50418275846306, TD loss   : 43.98444854974747, Episode   :    157\n",
      "Iteration :  16600, Train reward: -65.17709054531011, Eval reward: -52.50418275846306, TD loss   : 44.8223646569252, Episode   :    158\n",
      "Iteration :  16700, Train reward: -61.427200692529354, Eval reward: -52.50418275846306, TD loss   : 29.707128367424012, Episode   :    159\n",
      "Iteration :  16800, Train reward: -65.54116811154594, Eval reward: -52.50418275846306, TD loss   : 31.218329100608827, Episode   :    160\n",
      "Iteration :  16900, Train reward: -65.54116811154594, Eval reward: -52.50418275846306, TD loss   : 39.095268419981004, Episode   :    160\n",
      "Iteration :  17000, Train reward: -63.70236682100487, Eval reward: 105.1479734475619, TD loss   : 36.95423978209496, Episode   :    161\n",
      "Iteration :  17100, Train reward: -57.395195599936834, Eval reward: 105.1479734475619, TD loss   : 36.74674706459045, Episode   :    162\n",
      "Iteration :  17200, Train reward: -57.455033383416165, Eval reward: 105.1479734475619, TD loss   : 37.155658913850786, Episode   :    163\n",
      "Iteration :  17300, Train reward: -57.455033383416165, Eval reward: 105.1479734475619, TD loss   : 43.25720525741577, Episode   :    163\n",
      "Iteration :  17400, Train reward: -49.0907513968374, Eval reward: 105.1479734475619, TD loss   : 27.94869373679161, Episode   :    164\n",
      "Iteration :  17500, Train reward: -49.0907513968374, Eval reward: 41.17149021150473, TD loss   : 43.980693321228024, Episode   :    164\n",
      "Iteration :  17600, Train reward: -41.27351667277487, Eval reward: 41.17149021150473, TD loss   : 35.384122887849806, Episode   :    165\n",
      "Iteration :  17700, Train reward: -34.490763959741706, Eval reward: 41.17149021150473, TD loss   : 34.701015634536745, Episode   :    166\n",
      "Iteration :  17800, Train reward: -34.490763959741706, Eval reward: 41.17149021150473, TD loss   : 26.180534644126894, Episode   :    166\n",
      "Iteration :  17900, Train reward: -35.62789128282191, Eval reward: 41.17149021150473, TD loss   : 33.13297591567039, Episode   :    167\n",
      "Iteration :  18000, Train reward: -35.62789128282191, Eval reward: 8.805623890056022, TD loss   : 36.32368913531303, Episode   :    167\n",
      "Iteration :  18100, Train reward: -31.008807430806645, Eval reward: 8.805623890056022, TD loss   : 31.81455616593361, Episode   :    168\n",
      "Iteration :  18200, Train reward: -29.492436844222674, Eval reward: 8.805623890056022, TD loss   : 21.341097161769866, Episode   :    169\n",
      "Iteration :  18300, Train reward: -29.492436844222674, Eval reward: 8.805623890056022, TD loss   : 21.696108132600784, Episode   :    169\n",
      "Iteration :  18400, Train reward: -29.237046703749463, Eval reward: 8.805623890056022, TD loss   : 35.4422131896019, Episode   :    170\n",
      "Iteration :  18500, Train reward: -29.098823745844534, Eval reward: -21.561286305499102, TD loss   : 28.676267634630204, Episode   :    171\n",
      "Iteration :  18600, Train reward: -32.79888168988101, Eval reward: -21.561286305499102, TD loss   : 28.871942782402037, Episode   :    172\n",
      "Iteration :  18700, Train reward: -32.79888168988101, Eval reward: -21.561286305499102, TD loss   : 36.67948437929154, Episode   :    172\n",
      "Iteration :  18800, Train reward: -32.79888168988101, Eval reward: -21.561286305499102, TD loss   : 37.49004736185074, Episode   :    172\n",
      "Iteration :  18900, Train reward: -37.31662559927511, Eval reward: -21.561286305499102, TD loss   : 40.29533893346787, Episode   :    173\n",
      "Iteration :  19000, Train reward: -31.522743431885253, Eval reward: -0.9230526263573935, TD loss   : 33.591871846914295, Episode   :    174\n",
      "Iteration :  19100, Train reward: -31.397801693478243, Eval reward: -0.9230526263573935, TD loss   : 30.690217270851136, Episode   :    176\n",
      "Iteration :  19200, Train reward: -31.397801693478243, Eval reward: -0.9230526263573935, TD loss   : 30.411458449363707, Episode   :    176\n",
      "Iteration :  19300, Train reward: -32.016667120989716, Eval reward: -0.9230526263573935, TD loss   : 24.070670204162596, Episode   :    177\n",
      "Iteration :  19400, Train reward: -36.11557114162631, Eval reward: -0.9230526263573935, TD loss   : 34.8121520793438, Episode   :    178\n",
      "Iteration :  19500, Train reward: -36.11557114162631, Eval reward: -44.09573096602351, TD loss   : 26.511817625761033, Episode   :    178\n",
      "Iteration :  19600, Train reward: -35.170364271924676, Eval reward: -44.09573096602351, TD loss   : 26.94185649394989, Episode   :    180\n",
      "Iteration :  19700, Train reward: -35.170364271924676, Eval reward: -44.09573096602351, TD loss   : 23.68140596985817, Episode   :    180\n",
      "Iteration :  19800, Train reward: -35.170364271924676, Eval reward: -44.09573096602351, TD loss   : 24.300977489948274, Episode   :    180\n",
      "Iteration :  19900, Train reward: -32.48768352490761, Eval reward: -44.09573096602351, TD loss   : 22.74735234260559, Episode   :    181\n",
      "Iteration :  20000, Train reward: -35.42475796686729, Eval reward: 1.8048603212622552, TD loss   : 34.81403679132462, Episode   :    182\n",
      "Iteration :  20100, Train reward: -30.689274544426752, Eval reward: 1.8048603212622552, TD loss   : 27.983061833381655, Episode   :    183\n",
      "Iteration :  20200, Train reward: -29.050818715092124, Eval reward: 1.8048603212622552, TD loss   : 24.72502428531647, Episode   :    184\n",
      "Iteration :  20300, Train reward: -35.37670301227446, Eval reward: 1.8048603212622552, TD loss   : 31.78142864584923, Episode   :    185\n",
      "Iteration :  20400, Train reward: -35.37670301227446, Eval reward: 1.8048603212622552, TD loss   : 35.939286284446716, Episode   :    185\n",
      "Iteration :  20500, Train reward: -35.37670301227446, Eval reward: -6.745144357859621, TD loss   : 23.771951962709426, Episode   :    185\n",
      "Iteration :  20600, Train reward: -32.84994202576518, Eval reward: -6.745144357859621, TD loss   : 26.823120611906052, Episode   :    186\n",
      "Iteration :  20700, Train reward: -38.61043518028872, Eval reward: -6.745144357859621, TD loss   : 25.315525093078612, Episode   :    187\n",
      "Iteration :  20800, Train reward: -36.889953495709975, Eval reward: -6.745144357859621, TD loss   : 22.44332810997963, Episode   :    188\n",
      "Iteration :  20900, Train reward: -36.889953495709975, Eval reward: -6.745144357859621, TD loss   : 35.73369931340218, Episode   :    188\n",
      "Iteration :  21000, Train reward: -37.107214425255826, Eval reward: -12.852820831264712, TD loss   : 31.66116983294487, Episode   :    189\n",
      "Iteration :  21100, Train reward: -39.81401849072129, Eval reward: -12.852820831264712, TD loss   : 23.902525182962417, Episode   :    190\n",
      "Iteration :  21200, Train reward: -40.31428040111371, Eval reward: -12.852820831264712, TD loss   : 30.963790898323058, Episode   :    191\n",
      "Iteration :  21300, Train reward: -40.31428040111371, Eval reward: -12.852820831264712, TD loss   : 43.168871545791625, Episode   :    191\n",
      "Iteration :  21400, Train reward: -39.221895470861604, Eval reward: -12.852820831264712, TD loss   : 33.969265532493594, Episode   :    192\n",
      "Iteration :  21500, Train reward: -41.3534986542734, Eval reward: -6.727220689762295, TD loss   : 22.06525534272194, Episode   :    193\n",
      "Iteration :  21600, Train reward: -43.05196047317007, Eval reward: -6.727220689762295, TD loss   : 34.90098382234574, Episode   :    194\n",
      "Iteration :  21700, Train reward: -42.524079645309506, Eval reward: -6.727220689762295, TD loss   : 26.887847402095794, Episode   :    195\n",
      "Iteration :  21800, Train reward: -42.524079645309506, Eval reward: -6.727220689762295, TD loss   : 29.416893270015716, Episode   :    195\n",
      "Iteration :  21900, Train reward: -47.25644285955066, Eval reward: -6.727220689762295, TD loss   : 32.846706755161286, Episode   :    196\n",
      "Iteration :  22000, Train reward: -47.25644285955066, Eval reward: -38.30138102002709, TD loss   : 23.23946496129036, Episode   :    196\n",
      "Iteration :  22100, Train reward: -45.318456987560346, Eval reward: -38.30138102002709, TD loss   : 27.696698825359345, Episode   :    197\n",
      "Iteration :  22200, Train reward: -41.74982765208283, Eval reward: -38.30138102002709, TD loss   : 34.12557492494583, Episode   :    198\n",
      "Iteration :  22300, Train reward: -40.22289666307236, Eval reward: -38.30138102002709, TD loss   : 33.14710773825645, Episode   :    199\n",
      "Iteration :  22400, Train reward: -43.449606507962436, Eval reward: -38.30138102002709, TD loss   : 29.581340661048888, Episode   :    200\n",
      "Iteration :  22500, Train reward: -45.52600112016555, Eval reward: -5.7071349108631635, TD loss   : 24.14206593155861, Episode   :    201\n",
      "Iteration :  22600, Train reward: -41.901231272566925, Eval reward: -5.7071349108631635, TD loss   : 25.656904726028444, Episode   :    202\n",
      "Iteration :  22700, Train reward: -46.45673481359414, Eval reward: -5.7071349108631635, TD loss   : 27.133002605438232, Episode   :    203\n",
      "Iteration :  22800, Train reward: -46.45673481359414, Eval reward: -5.7071349108631635, TD loss   : 34.81293724536896, Episode   :    203\n",
      "Iteration :  22900, Train reward: -46.45673481359414, Eval reward: -5.7071349108631635, TD loss   : 33.248720906972885, Episode   :    203\n",
      "Iteration :  23000, Train reward: -46.71342901539252, Eval reward: -34.61846472386211, TD loss   : 33.313942481279376, Episode   :    204\n",
      "Iteration :  23100, Train reward: -43.76938034596055, Eval reward: -34.61846472386211, TD loss   : 29.723697344064714, Episode   :    205\n",
      "Iteration :  23200, Train reward: -43.76938034596055, Eval reward: -34.61846472386211, TD loss   : 38.885895547866824, Episode   :    205\n",
      "Iteration :  23300, Train reward: -59.247278840494644, Eval reward: -34.61846472386211, TD loss   : 23.728021392822267, Episode   :    206\n",
      "Iteration :  23400, Train reward: -50.3156127757744, Eval reward: -34.61846472386211, TD loss   : 30.605285292863847, Episode   :    207\n",
      "Iteration :  23500, Train reward: -54.06284509566986, Eval reward: -19.683374474507264, TD loss   : 27.538255237340927, Episode   :    208\n",
      "Iteration :  23600, Train reward: -51.54341086762709, Eval reward: -19.683374474507264, TD loss   : 28.95928175806999, Episode   :    209\n",
      "Iteration :  23700, Train reward: -49.329421699759834, Eval reward: -19.683374474507264, TD loss   : 40.74177726864815, Episode   :    210\n",
      "Iteration :  23800, Train reward: -49.329421699759834, Eval reward: -19.683374474507264, TD loss   : 39.06261526226997, Episode   :    210\n",
      "Iteration :  23900, Train reward: -63.04819435062325, Eval reward: -19.683374474507264, TD loss   : 20.091983025074004, Episode   :    211\n",
      "Iteration :  24000, Train reward: -63.04819435062325, Eval reward: -5.039747056488919, TD loss   : 30.446045449972154, Episode   :    211\n",
      "Iteration :  24100, Train reward: -68.80092144603844, Eval reward: -5.039747056488919, TD loss   : 27.18424313426018, Episode   :    212\n",
      "Iteration :  24200, Train reward: -68.80092144603844, Eval reward: -5.039747056488919, TD loss   : 40.731428084373476, Episode   :    212\n",
      "Iteration :  24300, Train reward: -60.116762305528084, Eval reward: -5.039747056488919, TD loss   : 36.0578851544857, Episode   :    213\n",
      "Iteration :  24400, Train reward: -63.664247775890864, Eval reward: -5.039747056488919, TD loss   : 29.88734661102295, Episode   :    214\n",
      "Iteration :  24500, Train reward: -63.664247775890864, Eval reward: -8.606880027031005, TD loss   : 30.68697723031044, Episode   :    214\n",
      "Iteration :  24600, Train reward: -65.72374810637794, Eval reward: -8.606880027031005, TD loss   : 20.97652302145958, Episode   :    215\n",
      "Iteration :  24700, Train reward: -65.72374810637794, Eval reward: -8.606880027031005, TD loss   : 30.96998251080513, Episode   :    215\n",
      "Iteration :  24800, Train reward: -67.017372952823, Eval reward: -8.606880027031005, TD loss   : 21.63130208015442, Episode   :    216\n",
      "Iteration :  24900, Train reward: -67.017372952823, Eval reward: -8.606880027031005, TD loss   : 32.35038744688034, Episode   :    216\n",
      "Iteration :  25000, Train reward: -67.017372952823, Eval reward: -13.21581176556025, TD loss   : 25.307995317578317, Episode   :    216\n",
      "Iteration :  25100, Train reward: -64.30730404368411, Eval reward: -13.21581176556025, TD loss   : 28.76513242483139, Episode   :    217\n",
      "Iteration :  25200, Train reward: -68.12159235707512, Eval reward: -13.21581176556025, TD loss   : 34.76001733064651, Episode   :    218\n",
      "Iteration :  25300, Train reward: -72.57009278742075, Eval reward: -13.21581176556025, TD loss   : 26.30514842391014, Episode   :    219\n",
      "Iteration :  25400, Train reward: -72.57009278742075, Eval reward: -13.21581176556025, TD loss   : 34.062152371406555, Episode   :    219\n",
      "Iteration :  25500, Train reward: -72.57009278742075, Eval reward: -30.46006953514227, TD loss   : 28.799357302188874, Episode   :    219\n",
      "Iteration :  25600, Train reward: -59.72313977936426, Eval reward: -30.46006953514227, TD loss   : 31.030117332935333, Episode   :    220\n",
      "Iteration :  25700, Train reward: -59.72313977936426, Eval reward: -30.46006953514227, TD loss   : 43.90837004184723, Episode   :    220\n",
      "Iteration :  25800, Train reward: -59.53655629524799, Eval reward: -30.46006953514227, TD loss   : 25.428835263252257, Episode   :    221\n",
      "Iteration :  25900, Train reward: -59.53655629524799, Eval reward: -30.46006953514227, TD loss   : 38.073401879072186, Episode   :    221\n",
      "Iteration :  26000, Train reward: -59.53655629524799, Eval reward: 19.464862841060366, TD loss   : 35.90357252597809, Episode   :    221\n",
      "Iteration :  26100, Train reward: -62.394834768078134, Eval reward: 19.464862841060366, TD loss   : 29.93638791680336, Episode   :    222\n",
      "Iteration :  26200, Train reward: -62.394834768078134, Eval reward: 19.464862841060366, TD loss   : 26.926633567810057, Episode   :    222\n",
      "Iteration :  26300, Train reward: -69.57522102482986, Eval reward: 19.464862841060366, TD loss   : 33.52601591348648, Episode   :    223\n",
      "Iteration :  26400, Train reward: -72.74419737538078, Eval reward: 19.464862841060366, TD loss   : 32.89364236116409, Episode   :    224\n",
      "Iteration :  26500, Train reward: -72.74419737538078, Eval reward: -96.38878134674351, TD loss   : 25.36581247448921, Episode   :    224\n",
      "Iteration :  26600, Train reward: -76.99324597885798, Eval reward: -96.38878134674351, TD loss   : 17.999074615240097, Episode   :    225\n",
      "Iteration :  26700, Train reward: -76.99324597885798, Eval reward: -96.38878134674351, TD loss   : 29.808490915298464, Episode   :    225\n",
      "Iteration :  26800, Train reward: -76.99324597885798, Eval reward: -96.38878134674351, TD loss   : 26.213849427700044, Episode   :    225\n",
      "Iteration :  26900, Train reward: -61.86445017795463, Eval reward: -96.38878134674351, TD loss   : 26.648982244729996, Episode   :    226\n",
      "Iteration :  27000, Train reward: -61.86445017795463, Eval reward: -7.737992869798627, TD loss   : 29.699709752798082, Episode   :    226\n",
      "Iteration :  27100, Train reward: -62.41576063941513, Eval reward: -7.737992869798627, TD loss   : 27.26653237581253, Episode   :    227\n",
      "Iteration :  27200, Train reward: -60.1899272294105, Eval reward: -7.737992869798627, TD loss   : 22.408622174263, Episode   :    228\n",
      "Iteration :  27300, Train reward: -64.01634755122078, Eval reward: -7.737992869798627, TD loss   : 24.538863279819488, Episode   :    229\n",
      "Iteration :  27400, Train reward: -64.01634755122078, Eval reward: -7.737992869798627, TD loss   : 28.72543831348419, Episode   :    229\n",
      "Iteration :  27500, Train reward: -63.38084402799556, Eval reward: -25.462188111201215, TD loss   : 24.735741102695464, Episode   :    230\n",
      "Iteration :  27600, Train reward: -47.20692214866769, Eval reward: -25.462188111201215, TD loss   : 29.99522493839264, Episode   :    231\n",
      "Iteration :  27700, Train reward: -47.20692214866769, Eval reward: -25.462188111201215, TD loss   : 29.674227528572082, Episode   :    231\n",
      "Iteration :  27800, Train reward: -53.50218154164721, Eval reward: -25.462188111201215, TD loss   : 25.141298558712005, Episode   :    232\n",
      "Iteration :  27900, Train reward: -53.50218154164721, Eval reward: -25.462188111201215, TD loss   : 32.740252450704574, Episode   :    232\n",
      "Iteration :  28000, Train reward: -53.50218154164721, Eval reward: 7.153430728640144, TD loss   : 27.40601791739464, Episode   :    232\n",
      "Iteration :  28100, Train reward: -53.71170359723219, Eval reward: 7.153430728640144, TD loss   : 29.409870312213897, Episode   :    233\n",
      "Iteration :  28200, Train reward: -53.64478531972369, Eval reward: 7.153430728640144, TD loss   : 31.586346316337586, Episode   :    234\n",
      "Iteration :  28300, Train reward: -53.64478531972369, Eval reward: 7.153430728640144, TD loss   : 35.883931171894076, Episode   :    234\n",
      "Iteration :  28400, Train reward: -52.36811554873348, Eval reward: 7.153430728640144, TD loss   : 24.002893726825715, Episode   :    235\n",
      "Iteration :  28500, Train reward: -41.75537856623707, Eval reward: -27.629694437420234, TD loss   : 29.70118440270424, Episode   :    236\n",
      "Iteration :  28600, Train reward: -42.08963012636048, Eval reward: -27.629694437420234, TD loss   : 28.346314178705214, Episode   :    237\n",
      "Iteration :  28700, Train reward: -42.08963012636048, Eval reward: -27.629694437420234, TD loss   : 20.42801653146744, Episode   :    237\n",
      "Iteration :  28800, Train reward: -42.08963012636048, Eval reward: -27.629694437420234, TD loss   : 27.98178085565567, Episode   :    237\n",
      "Iteration :  28900, Train reward: -31.268536465499757, Eval reward: -27.629694437420234, TD loss   : 27.21882440328598, Episode   :    238\n",
      "Iteration :  29000, Train reward: -31.268536465499757, Eval reward: -114.2320032962278, TD loss   : 33.283379342556, Episode   :    238\n",
      "Iteration :  29100, Train reward: -16.899807425898224, Eval reward: -114.2320032962278, TD loss   : 27.52288337945938, Episode   :    239\n",
      "Iteration :  29200, Train reward: -16.899807425898224, Eval reward: -114.2320032962278, TD loss   : 29.830166385173797, Episode   :    239\n",
      "Iteration :  29300, Train reward: -19.927492077145832, Eval reward: -114.2320032962278, TD loss   : 16.18162629365921, Episode   :    240\n",
      "Iteration :  29400, Train reward: -19.927492077145832, Eval reward: -114.2320032962278, TD loss   : 21.38444573879242, Episode   :    240\n",
      "Iteration :  29500, Train reward: -27.790196003969754, Eval reward: -123.14095766984678, TD loss   : 36.93152586340904, Episode   :    241\n",
      "Iteration :  29600, Train reward: -25.467727764633942, Eval reward: -123.14095766984678, TD loss   : 37.08248831272125, Episode   :    242\n",
      "Iteration :  29700, Train reward: -25.467727764633942, Eval reward: -123.14095766984678, TD loss   : 39.3344136428833, Episode   :    242\n",
      "Iteration :  29800, Train reward: -25.467727764633942, Eval reward: -123.14095766984678, TD loss   : 34.19537696123123, Episode   :    242\n",
      "Iteration :  29900, Train reward: -17.39362972603734, Eval reward: -123.14095766984678, TD loss   : 29.05210189461708, Episode   :    243\n",
      "Iteration :  30000, Train reward: -23.832648791260418, Eval reward: -32.19286678940561, TD loss   : 34.3482936167717, Episode   :    244\n",
      "Iteration :  30100, Train reward: -24.571092565217345, Eval reward: -32.19286678940561, TD loss   : 25.85274795293808, Episode   :    245\n",
      "Iteration :  30200, Train reward: -27.152999491745494, Eval reward: -32.19286678940561, TD loss   : 29.495266140699385, Episode   :    246\n",
      "Iteration :  30300, Train reward: -28.010868333229514, Eval reward: -32.19286678940561, TD loss   : 34.039181447029115, Episode   :    247\n",
      "Iteration :  30400, Train reward: -28.010868333229514, Eval reward: -32.19286678940561, TD loss   : 22.790430368185042, Episode   :    247\n",
      "Iteration :  30500, Train reward: -28.010868333229514, Eval reward: -70.5959636605821, TD loss   : 29.49927043914795, Episode   :    247\n",
      "Iteration :  30600, Train reward: -27.086573057688316, Eval reward: -70.5959636605821, TD loss   : 25.506577397584916, Episode   :    248\n",
      "Iteration :  30700, Train reward: -27.086573057688316, Eval reward: -70.5959636605821, TD loss   : 23.01000202178955, Episode   :    248\n",
      "Iteration :  30800, Train reward: -27.086573057688316, Eval reward: -70.5959636605821, TD loss   : 31.106211882829665, Episode   :    248\n",
      "Iteration :  30900, Train reward: -20.694643473606238, Eval reward: -70.5959636605821, TD loss   : 31.102057027816773, Episode   :    249\n",
      "Iteration :  31000, Train reward: -20.694643473606238, Eval reward: -89.40845488236343, TD loss   : 24.356609477996827, Episode   :    249\n",
      "Iteration :  31100, Train reward: -17.4376031286101, Eval reward: -89.40845488236343, TD loss   : 13.682733461856841, Episode   :    250\n",
      "Iteration :  31200, Train reward: -17.4376031286101, Eval reward: -89.40845488236343, TD loss   : 31.876907819509505, Episode   :    250\n",
      "Iteration :  31300, Train reward: -17.4376031286101, Eval reward: -89.40845488236343, TD loss   : 26.891812102794646, Episode   :    250\n",
      "Iteration :  31400, Train reward: -14.875837624191456, Eval reward: -89.40845488236343, TD loss   : 31.05318604230881, Episode   :    251\n",
      "Iteration :  31500, Train reward: -13.89297280586033, Eval reward: -28.167871054742154, TD loss   : 26.150632091760635, Episode   :    252\n",
      "Iteration :  31600, Train reward: -12.46829090444162, Eval reward: -28.167871054742154, TD loss   : 29.122646691799165, Episode   :    253\n",
      "Iteration :  31700, Train reward: -17.285493644195405, Eval reward: -28.167871054742154, TD loss   : 24.16209822297096, Episode   :    254\n",
      "Iteration :  31800, Train reward: -17.285493644195405, Eval reward: -28.167871054742154, TD loss   : 28.023363621234893, Episode   :    254\n",
      "Iteration :  31900, Train reward: -29.523537871062167, Eval reward: -28.167871054742154, TD loss   : 24.427213591337203, Episode   :    255\n",
      "Iteration :  32000, Train reward: -29.523537871062167, Eval reward: -125.02443085103616, TD loss   : 29.999960198402405, Episode   :    255\n",
      "Iteration :  32100, Train reward: -23.200796583742868, Eval reward: -125.02443085103616, TD loss   : 32.69750304937363, Episode   :    256\n",
      "Iteration :  32200, Train reward: -23.200796583742868, Eval reward: -125.02443085103616, TD loss   : 38.880348920822144, Episode   :    256\n",
      "Iteration :  32300, Train reward: -23.200796583742868, Eval reward: -125.02443085103616, TD loss   : 38.91414820432663, Episode   :    256\n",
      "Iteration :  32400, Train reward: -26.825010203453825, Eval reward: -125.02443085103616, TD loss   : 38.75974212646484, Episode   :    257\n",
      "Iteration :  32500, Train reward: -41.62922765071629, Eval reward: -72.64100654003383, TD loss   : 40.59730767011642, Episode   :    258\n",
      "Iteration :  32600, Train reward: -47.93803659556251, Eval reward: -72.64100654003383, TD loss   : 23.29279177904129, Episode   :    259\n",
      "Iteration :  32700, Train reward: -47.93803659556251, Eval reward: -72.64100654003383, TD loss   : 21.665680484771727, Episode   :    259\n",
      "Iteration :  32800, Train reward: -49.68720406480824, Eval reward: -72.64100654003383, TD loss   : 33.08380587100983, Episode   :    260\n",
      "Iteration :  32900, Train reward: -46.02613697427651, Eval reward: -72.64100654003383, TD loss   : 37.74006358385086, Episode   :    261\n",
      "Iteration :  33000, Train reward: -46.02613697427651, Eval reward: -63.16058334168473, TD loss   : 38.28343197584152, Episode   :    261\n",
      "Iteration :  33100, Train reward: -44.23434100021238, Eval reward: -63.16058334168473, TD loss   : 28.960854046344757, Episode   :    262\n",
      "Iteration :  33200, Train reward: -44.23434100021238, Eval reward: -63.16058334168473, TD loss   : 31.976038895845413, Episode   :    262\n",
      "Iteration :  33300, Train reward: -44.23434100021238, Eval reward: -63.16058334168473, TD loss   : 40.37766276359558, Episode   :    262\n",
      "Iteration :  33400, Train reward: -44.28586867242827, Eval reward: -63.16058334168473, TD loss   : 32.661828266382216, Episode   :    263\n",
      "Iteration :  33500, Train reward: -39.9310296479171, Eval reward: -98.2390388230574, TD loss   : 23.53289135813713, Episode   :    264\n",
      "Iteration :  33600, Train reward: -40.7590861799496, Eval reward: -98.2390388230574, TD loss   : 35.898869407176974, Episode   :    265\n",
      "Iteration :  33700, Train reward: -40.7590861799496, Eval reward: -98.2390388230574, TD loss   : 31.034959151744843, Episode   :    265\n",
      "Iteration :  33800, Train reward: -40.7590861799496, Eval reward: -98.2390388230574, TD loss   : 47.47979650497437, Episode   :    265\n",
      "Iteration :  33900, Train reward: -47.76180049044753, Eval reward: -98.2390388230574, TD loss   : 34.70888484716416, Episode   :    266\n",
      "Iteration :  34000, Train reward: -47.76180049044753, Eval reward: -67.41920985625786, TD loss   : 28.046950010061263, Episode   :    266\n",
      "Iteration :  34100, Train reward: -54.033783252466876, Eval reward: -67.41920985625786, TD loss   : 36.06372523188591, Episode   :    267\n",
      "Iteration :  34200, Train reward: -54.033783252466876, Eval reward: -67.41920985625786, TD loss   : 46.543260853290555, Episode   :    267\n",
      "Iteration :  34300, Train reward: -67.57948138221506, Eval reward: -67.41920985625786, TD loss   : 30.20178054332733, Episode   :    268\n",
      "Iteration :  34400, Train reward: -67.57948138221506, Eval reward: -67.41920985625786, TD loss   : 32.936086710691455, Episode   :    268\n",
      "Iteration :  34500, Train reward: -67.57948138221506, Eval reward: -168.22860328159587, TD loss   : 36.10220204114914, Episode   :    268\n",
      "Iteration :  34600, Train reward: -70.93355059697, Eval reward: -168.22860328159587, TD loss   : 46.10372982501983, Episode   :    269\n",
      "Iteration :  34700, Train reward: -70.93355059697, Eval reward: -168.22860328159587, TD loss   : 22.923068796396254, Episode   :    269\n",
      "Iteration :  34800, Train reward: -70.93355059697, Eval reward: -168.22860328159587, TD loss   : 28.86212526798248, Episode   :    269\n",
      "Iteration :  34900, Train reward: -69.39742657327864, Eval reward: -168.22860328159587, TD loss   : 34.76827935457229, Episode   :    270\n",
      "Iteration :  35000, Train reward: -69.39742657327864, Eval reward: -72.27883939861216, TD loss   : 40.708846213817594, Episode   :    270\n",
      "Iteration :  35100, Train reward: -62.96275011482709, Eval reward: -72.27883939861216, TD loss   : 26.999909155368805, Episode   :    272\n",
      "Iteration :  35200, Train reward: -62.96275011482709, Eval reward: -72.27883939861216, TD loss   : 41.051003241539, Episode   :    272\n",
      "Iteration :  35300, Train reward: -62.96275011482709, Eval reward: -72.27883939861216, TD loss   : 42.24887799263001, Episode   :    272\n",
      "Iteration :  35400, Train reward: -67.28648349547626, Eval reward: -72.27883939861216, TD loss   : 34.74679406881332, Episode   :    273\n",
      "Iteration :  35500, Train reward: -67.28648349547626, Eval reward: -25.911100704788804, TD loss   : 41.60974315881729, Episode   :    273\n",
      "Iteration :  35600, Train reward: -55.95852447150314, Eval reward: -25.911100704788804, TD loss   : 37.29264905691147, Episode   :    274\n",
      "Iteration :  35700, Train reward: -55.95852447150314, Eval reward: -25.911100704788804, TD loss   : 38.84802768111229, Episode   :    274\n",
      "Iteration :  35800, Train reward: -55.95852447150314, Eval reward: -25.911100704788804, TD loss   : 38.52258762836456, Episode   :    274\n",
      "Iteration :  35900, Train reward: -44.46862623392262, Eval reward: -25.911100704788804, TD loss   : 28.42614166855812, Episode   :    275\n",
      "Iteration :  36000, Train reward: -44.46862623392262, Eval reward: 46.26354761549494, TD loss   : 27.286484797000885, Episode   :    275\n",
      "Iteration :  36100, Train reward: -56.15656287090009, Eval reward: 46.26354761549494, TD loss   : 24.775343832969664, Episode   :    276\n",
      "Iteration :  36200, Train reward: -58.797297877408845, Eval reward: 46.26354761549494, TD loss   : 30.11476969599724, Episode   :    277\n",
      "Iteration :  36300, Train reward: -52.62751910456838, Eval reward: 46.26354761549494, TD loss   : 37.003246176242826, Episode   :    278\n",
      "Iteration :  36400, Train reward: -56.409266926149726, Eval reward: 46.26354761549494, TD loss   : 25.671515505313874, Episode   :    279\n",
      "Iteration :  36500, Train reward: -56.409266926149726, Eval reward: -45.217384256711455, TD loss   : 35.10625952839851, Episode   :    279\n",
      "Iteration :  36600, Train reward: -56.381418707967555, Eval reward: -45.217384256711455, TD loss   : 23.369150009155273, Episode   :    280\n",
      "Iteration :  36700, Train reward: -56.381418707967555, Eval reward: -45.217384256711455, TD loss   : 30.042094595432282, Episode   :    280\n",
      "Iteration :  36800, Train reward: -56.381418707967555, Eval reward: -45.217384256711455, TD loss   : 32.35244825601578, Episode   :    280\n",
      "Iteration :  36900, Train reward: -47.983648792996284, Eval reward: -45.217384256711455, TD loss   : 32.25334118127823, Episode   :    281\n",
      "Iteration :  37000, Train reward: -47.983648792996284, Eval reward: 27.099330634012016, TD loss   : 35.431014268398286, Episode   :    281\n",
      "Iteration :  37100, Train reward: -47.80321509221537, Eval reward: 27.099330634012016, TD loss   : 41.82856572508812, Episode   :    282\n",
      "Iteration :  37200, Train reward: -47.80321509221537, Eval reward: 27.099330634012016, TD loss   : 23.790861563682554, Episode   :    282\n",
      "Iteration :  37300, Train reward: -47.80321509221537, Eval reward: 27.099330634012016, TD loss   : 26.063944445848463, Episode   :    282\n",
      "Iteration :  37400, Train reward: -49.841159616908314, Eval reward: 27.099330634012016, TD loss   : 41.54320919394493, Episode   :    283\n",
      "Iteration :  37500, Train reward: -44.596329622706286, Eval reward: -99.53321241971368, TD loss   : 28.89339674115181, Episode   :    284\n",
      "Iteration :  37600, Train reward: -38.43506053183357, Eval reward: -99.53321241971368, TD loss   : 22.67945613503456, Episode   :    285\n",
      "Iteration :  37700, Train reward: -38.43506053183357, Eval reward: -99.53321241971368, TD loss   : 25.751783001422883, Episode   :    285\n",
      "Iteration :  37800, Train reward: -33.51190327349492, Eval reward: -99.53321241971368, TD loss   : 34.925444848537445, Episode   :    286\n",
      "Iteration :  37900, Train reward: -33.51190327349492, Eval reward: -99.53321241971368, TD loss   : 35.41388811826706, Episode   :    286\n",
      "Iteration :  38000, Train reward: -26.182441475258496, Eval reward: -18.003056451801054, TD loss   : 24.73278813481331, Episode   :    287\n",
      "Iteration :  38100, Train reward: -12.675082228991101, Eval reward: -18.003056451801054, TD loss   : 44.34387040495872, Episode   :    288\n",
      "Iteration :  38200, Train reward: -12.675082228991101, Eval reward: -18.003056451801054, TD loss   : 41.63583148598671, Episode   :    288\n",
      "Iteration :  38300, Train reward: -17.374807342979214, Eval reward: -18.003056451801054, TD loss   : 25.741386309862136, Episode   :    289\n",
      "Iteration :  38400, Train reward: -26.28603976918938, Eval reward: -18.003056451801054, TD loss   : 32.910667116641996, Episode   :    290\n",
      "Iteration :  38500, Train reward: -26.28603976918938, Eval reward: 14.818001509177913, TD loss   : 23.202717700004577, Episode   :    290\n",
      "Iteration :  38600, Train reward: -22.44010580886403, Eval reward: 14.818001509177913, TD loss   : 28.253299318552017, Episode   :    291\n",
      "Iteration :  38700, Train reward: -22.44010580886403, Eval reward: 14.818001509177913, TD loss   : 27.345635970830916, Episode   :    291\n",
      "Iteration :  38800, Train reward: -22.44010580886403, Eval reward: 14.818001509177913, TD loss   : 27.43476246714592, Episode   :    291\n",
      "Iteration :  38900, Train reward: -17.16997987893477, Eval reward: 14.818001509177913, TD loss   : 25.973188177347183, Episode   :    292\n",
      "Iteration :  39000, Train reward: -17.16997987893477, Eval reward: 44.29296387105559, TD loss   : 27.90019162893295, Episode   :    292\n",
      "Iteration :  39100, Train reward: -14.902229238915117, Eval reward: 44.29296387105559, TD loss   : 23.72677849292755, Episode   :    293\n",
      "Iteration :  39200, Train reward: -14.902229238915117, Eval reward: 44.29296387105559, TD loss   : 25.077939177751542, Episode   :    293\n",
      "Iteration :  39300, Train reward: -35.73577105573997, Eval reward: 44.29296387105559, TD loss   : 27.834723420143128, Episode   :    294\n",
      "Iteration :  39400, Train reward: -35.73577105573997, Eval reward: 44.29296387105559, TD loss   : 26.968061006069185, Episode   :    294\n",
      "Iteration :  39500, Train reward: -35.73577105573997, Eval reward: 35.05353635253442, TD loss   : 28.53964709043503, Episode   :    294\n",
      "Iteration :  39600, Train reward: -30.74845834048864, Eval reward: 35.05353635253442, TD loss   : 23.327233610153197, Episode   :    295\n",
      "Iteration :  39700, Train reward: -30.74845834048864, Eval reward: 35.05353635253442, TD loss   : 25.518854449987412, Episode   :    295\n",
      "Iteration :  39800, Train reward: -30.74845834048864, Eval reward: 35.05353635253442, TD loss   : 25.84037855386734, Episode   :    295\n",
      "Iteration :  39900, Train reward: -21.663475984853044, Eval reward: 35.05353635253442, TD loss   : 36.63559012770653, Episode   :    296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HasanErdin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\HasanErdin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4):\n",
    "    !python dqn/dqn/box2d.py --log_dir logs/vanilla-dqn-exp2 --target-update-period 1000 --buffer-capacity 100000 --render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"logs\", \"vanilla-dqn-exp2\")\n",
    "exp_2_dataframes = collect_training_logs(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Experiment DQN with exponential decaying epsilon strategy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :      0, Train reward:    nan, Eval reward: -107.93386384045334, TD loss   :    nan, Episode   :      0\n",
      "Iteration :    100, Train reward: -99.95509694651167, Eval reward: -107.93386384045334, TD loss   : 3.6269242763519287, Episode   :      1\n",
      "Iteration :    200, Train reward: -97.28718977872919, Eval reward: -107.93386384045334, TD loss   : 125.62463642001153, Episode   :      2\n",
      "Iteration :    300, Train reward: -109.5602052882535, Eval reward: -107.93386384045334, TD loss   : 134.27827560901642, Episode   :      3\n",
      "Iteration :    400, Train reward: -188.22863178871938, Eval reward: -107.93386384045334, TD loss   : 90.5856967639923, Episode   :      4\n",
      "Iteration :    500, Train reward: -197.3140376573501, Eval reward: -476.7164354503196, TD loss   : 51.48471210718155, Episode   :      5\n",
      "Iteration :    600, Train reward: -183.72785312599783, Eval reward: -476.7164354503196, TD loss   : 69.62909628629684, Episode   :      7\n",
      "Iteration :    700, Train reward: -170.03540415259158, Eval reward: -476.7164354503196, TD loss   : 84.79527848482132, Episode   :      8\n",
      "Iteration :    800, Train reward: -185.18594051479693, Eval reward: -476.7164354503196, TD loss   : 84.34182416677476, Episode   :      9\n",
      "Iteration :    900, Train reward: -183.2030623614639, Eval reward: -476.7164354503196, TD loss   : 83.88191521406173, Episode   :     10\n",
      "Iteration :   1000, Train reward: -176.28408030436134, Eval reward: -9.569259706657212, TD loss   : 80.95876477360726, Episode   :     11\n",
      "Iteration :   1100, Train reward: -174.0829478309848, Eval reward: -9.569259706657212, TD loss   : 89.69806127071381, Episode   :     12\n",
      "Iteration :   1200, Train reward: -167.45496577476663, Eval reward: -9.569259706657212, TD loss   : 80.42786375284194, Episode   :     13\n",
      "Iteration :   1300, Train reward: -164.7106938113939, Eval reward: -9.569259706657212, TD loss   : 93.56610854148865, Episode   :     14\n",
      "Iteration :   1400, Train reward: -156.2359382990161, Eval reward: -9.569259706657212, TD loss   : 68.23043218374252, Episode   :     15\n",
      "Iteration :   1500, Train reward: -153.79559423745985, Eval reward: -138.97708501286152, TD loss   : 68.5468523645401, Episode   :     16\n",
      "Iteration :   1600, Train reward: -147.3555002707264, Eval reward: -138.97708501286152, TD loss   : 60.19186769008636, Episode   :     18\n",
      "Iteration :   1700, Train reward: -150.64260977191054, Eval reward: -138.97708501286152, TD loss   : 74.95718563318252, Episode   :     19\n",
      "Iteration :   1800, Train reward: -150.64260977191054, Eval reward: -138.97708501286152, TD loss   : 64.27153996944428, Episode   :     19\n",
      "Iteration :   1900, Train reward: -167.15289531699844, Eval reward: -138.97708501286152, TD loss   : 69.73177208900452, Episode   :     20\n",
      "Iteration :   2000, Train reward: -166.1023633362565, Eval reward: -166.89234988230072, TD loss   : 56.39095559120178, Episode   :     21\n",
      "Iteration :   2100, Train reward: -170.5028822566562, Eval reward: -166.89234988230072, TD loss   : 67.12401134729386, Episode   :     23\n",
      "Iteration :   2200, Train reward: -170.5028822566562, Eval reward: -166.89234988230072, TD loss   : 78.3646439743042, Episode   :     23\n",
      "Iteration :   2300, Train reward: -157.0935107887674, Eval reward: -166.89234988230072, TD loss   : 56.83330176353454, Episode   :     24\n",
      "Iteration :   2400, Train reward: -151.85839433789374, Eval reward: -166.89234988230072, TD loss   : 78.56370024442673, Episode   :     25\n",
      "Iteration :   2500, Train reward: -148.94069691289184, Eval reward: -110.62527436124768, TD loss   : 73.9372639966011, Episode   :     26\n",
      "Iteration :   2600, Train reward: -142.4916905610689, Eval reward: -110.62527436124768, TD loss   : 55.26333999633789, Episode   :     27\n",
      "Iteration :   2700, Train reward: -144.35516882533545, Eval reward: -110.62527436124768, TD loss   : 68.77750542759895, Episode   :     28\n",
      "Iteration :   2800, Train reward: -131.06632327454574, Eval reward: -110.62527436124768, TD loss   : 70.58719196796417, Episode   :     29\n",
      "Iteration :   2900, Train reward: -133.736055421059, Eval reward: -110.62527436124768, TD loss   : 67.8082515001297, Episode   :     30\n",
      "Iteration :   3000, Train reward: -132.12498423488228, Eval reward: -45.38990485112444, TD loss   : 73.02592689275741, Episode   :     31\n",
      "Iteration :   3100, Train reward: -129.4605295363355, Eval reward: -45.38990485112444, TD loss   : 56.09532075643539, Episode   :     32\n",
      "Iteration :   3200, Train reward: -128.80050802773894, Eval reward: -45.38990485112444, TD loss   : 51.04644210338593, Episode   :     34\n",
      "Iteration :   3300, Train reward: -130.32977912305242, Eval reward: -45.38990485112444, TD loss   : 45.80723821520805, Episode   :     35\n",
      "Iteration :   3400, Train reward: -128.2147400540977, Eval reward: -45.38990485112444, TD loss   : 58.88215194225311, Episode   :     36\n",
      "Iteration :   3500, Train reward: -128.2147400540977, Eval reward: 6.190791814568732, TD loss   : 54.84865461111069, Episode   :     36\n",
      "Iteration :   3600, Train reward: -120.75612039377981, Eval reward: 6.190791814568732, TD loss   : 45.94679624199867, Episode   :     37\n",
      "Iteration :   3700, Train reward: -120.51100955764556, Eval reward: 6.190791814568732, TD loss   : 41.04607069015503, Episode   :     38\n",
      "Iteration :   3800, Train reward: -114.3125683775543, Eval reward: 6.190791814568732, TD loss   : 55.47029227495194, Episode   :     39\n",
      "Iteration :   3900, Train reward: -99.79708010864171, Eval reward: 6.190791814568732, TD loss   : 57.618783923387525, Episode   :     40\n",
      "Iteration :   4000, Train reward: -101.89632744859196, Eval reward: -142.28192769620475, TD loss   : 44.99888581752777, Episode   :     41\n",
      "Iteration :   4100, Train reward: -101.96294058028022, Eval reward: -142.28192769620475, TD loss   : 53.537450819015504, Episode   :     42\n",
      "Iteration :   4200, Train reward: -93.51887796992551, Eval reward: -142.28192769620475, TD loss   : 43.15998073816299, Episode   :     43\n",
      "Iteration :   4300, Train reward: -88.69552523180542, Eval reward: -142.28192769620475, TD loss   : 39.61180388569832, Episode   :     44\n",
      "Iteration :   4400, Train reward: -87.62467948439924, Eval reward: -142.28192769620475, TD loss   : 42.02415245294571, Episode   :     45\n",
      "Iteration :   4500, Train reward: -81.77867804317161, Eval reward: -104.92071381676143, TD loss   : 58.132925308942795, Episode   :     46\n",
      "Iteration :   4600, Train reward: -84.84643336030368, Eval reward: -104.92071381676143, TD loss   : 59.79460219979286, Episode   :     47\n",
      "Iteration :   4700, Train reward: -82.52155309239835, Eval reward: -104.92071381676143, TD loss   : 57.29201474905014, Episode   :     48\n",
      "Iteration :   4800, Train reward: -82.18534968042006, Eval reward: -104.92071381676143, TD loss   : 43.18946016073227, Episode   :     49\n",
      "Iteration :   4900, Train reward: -76.35112297236147, Eval reward: -104.92071381676143, TD loss   : 48.10977604866028, Episode   :     50\n",
      "Iteration :   5000, Train reward: -76.35112297236147, Eval reward: -57.24480332752139, TD loss   : 58.39383037686348, Episode   :     50\n",
      "Iteration :   5100, Train reward: -74.20888757848601, Eval reward: -57.24480332752139, TD loss   : 53.2316825568676, Episode   :     52\n",
      "Iteration :   5200, Train reward: -74.20888757848601, Eval reward: -57.24480332752139, TD loss   : 44.56159856319427, Episode   :     52\n",
      "Iteration :   5300, Train reward: -77.89438713448142, Eval reward: -57.24480332752139, TD loss   : 42.11723044395447, Episode   :     53\n",
      "Iteration :   5400, Train reward: -79.19380939059496, Eval reward: -57.24480332752139, TD loss   : 45.00362535715103, Episode   :     55\n",
      "Iteration :   5500, Train reward: -79.19380939059496, Eval reward: -80.11929329559673, TD loss   : 37.10587470293045, Episode   :     55\n",
      "Iteration :   5600, Train reward: -82.61878971261704, Eval reward: -80.11929329559673, TD loss   : 44.75473783731461, Episode   :     56\n",
      "Iteration :   5700, Train reward: -88.73616815628061, Eval reward: -80.11929329559673, TD loss   : 39.83231298089027, Episode   :     57\n",
      "Iteration :   5800, Train reward: -93.61135170422153, Eval reward: -80.11929329559673, TD loss   : 54.57650253534317, Episode   :     58\n",
      "Iteration :   5900, Train reward: -93.48368138035107, Eval reward: -80.11929329559673, TD loss   : 39.32492421030998, Episode   :     59\n",
      "Iteration :   6000, Train reward: -90.09455654388599, Eval reward: -4.947624742363304, TD loss   : 26.80288347363472, Episode   :     60\n",
      "Iteration :   6100, Train reward: -82.54285092724903, Eval reward: -4.947624742363304, TD loss   : 29.468271436691285, Episode   :     62\n",
      "Iteration :   6200, Train reward: -82.54285092724903, Eval reward: -4.947624742363304, TD loss   : 35.70755613207817, Episode   :     62\n",
      "Iteration :   6300, Train reward: -84.20457519588517, Eval reward: -4.947624742363304, TD loss   : 50.31234977006912, Episode   :     63\n",
      "Iteration :   6400, Train reward: -84.65244716568114, Eval reward: -4.947624742363304, TD loss   : 42.45479293346405, Episode   :     64\n",
      "Iteration :   6500, Train reward: -84.65244716568114, Eval reward: -8.394494953719175, TD loss   : 41.53031060457229, Episode   :     64\n",
      "Iteration :   6600, Train reward: -81.29472425188281, Eval reward: -8.394494953719175, TD loss   : 38.294760148525235, Episode   :     65\n",
      "Iteration :   6700, Train reward: -84.55436642916226, Eval reward: -8.394494953719175, TD loss   : 28.904938147068023, Episode   :     66\n",
      "Iteration :   6800, Train reward: -84.55436642916226, Eval reward: -8.394494953719175, TD loss   : 26.67015634059906, Episode   :     66\n",
      "Iteration :   6900, Train reward: -85.2182433981297, Eval reward: -8.394494953719175, TD loss   : 47.40100818037987, Episode   :     67\n",
      "Iteration :   7000, Train reward: -86.22995067191545, Eval reward: -14.240208653225366, TD loss   : 28.698186237812042, Episode   :     68\n",
      "Iteration :   7100, Train reward: -85.72948880177363, Eval reward: -14.240208653225366, TD loss   : 44.15372896194458, Episode   :     69\n",
      "Iteration :   7200, Train reward: -84.29752175677318, Eval reward: -14.240208653225366, TD loss   : 42.07762105941772, Episode   :     70\n",
      "Iteration :   7300, Train reward: -84.29752175677318, Eval reward: -14.240208653225366, TD loss   : 41.208001699447635, Episode   :     70\n",
      "Iteration :   7400, Train reward: -79.06547612190852, Eval reward: -14.240208653225366, TD loss   : 38.007430732250214, Episode   :     71\n",
      "Iteration :   7500, Train reward: -79.13369275410108, Eval reward: -16.88869411205231, TD loss   : 38.81129244208336, Episode   :     72\n",
      "Iteration :   7600, Train reward: -68.17998567563065, Eval reward: -16.88869411205231, TD loss   : 28.965350449085236, Episode   :     73\n",
      "Iteration :   7700, Train reward: -70.7833930764816, Eval reward: -16.88869411205231, TD loss   : 34.42126968920231, Episode   :     74\n",
      "Iteration :   7800, Train reward: -71.31830492711646, Eval reward: -16.88869411205231, TD loss   : 40.03913100600243, Episode   :     75\n",
      "Iteration :   7900, Train reward: -71.31830492711646, Eval reward: -16.88869411205231, TD loss   : 39.52170542597771, Episode   :     75\n",
      "Iteration :   8000, Train reward: -71.31830492711646, Eval reward: -65.70723279451259, TD loss   : 35.18602077484131, Episode   :     75\n",
      "Iteration :   8100, Train reward: -70.92609681727768, Eval reward: -65.70723279451259, TD loss   : 57.289035093784335, Episode   :     76\n",
      "Iteration :   8200, Train reward: -70.92609681727768, Eval reward: -65.70723279451259, TD loss   : 37.91974259376526, Episode   :     76\n",
      "Iteration :   8300, Train reward: -68.46681311477334, Eval reward: -65.70723279451259, TD loss   : 38.12715839505196, Episode   :     77\n",
      "Iteration :   8400, Train reward: -68.46681311477334, Eval reward: -65.70723279451259, TD loss   : 29.20703519821167, Episode   :     77\n",
      "Iteration :   8500, Train reward: -68.46681311477334, Eval reward: -5.641221295558977, TD loss   : 39.66599544525147, Episode   :     77\n",
      "Iteration :   8600, Train reward: -61.06078782308456, Eval reward: -5.641221295558977, TD loss   : 29.50406634092331, Episode   :     78\n",
      "Iteration :   8700, Train reward: -61.06078782308456, Eval reward: -5.641221295558977, TD loss   : 38.80557580709458, Episode   :     78\n",
      "Iteration :   8800, Train reward: -62.52478461777655, Eval reward: -5.641221295558977, TD loss   : 32.115915703773496, Episode   :     79\n",
      "Iteration :   8900, Train reward: -59.9596421130943, Eval reward: -5.641221295558977, TD loss   : 32.48693307638168, Episode   :     80\n",
      "Iteration :   9000, Train reward: -59.9596421130943, Eval reward: -206.68461914412268, TD loss   : 30.75126066684723, Episode   :     80\n",
      "Iteration :   9100, Train reward: -65.79153980256125, Eval reward: -206.68461914412268, TD loss   : 31.900475450754165, Episode   :     81\n",
      "Iteration :   9200, Train reward: -66.46292097758831, Eval reward: -206.68461914412268, TD loss   : 30.750472605228424, Episode   :     82\n",
      "Iteration :   9300, Train reward: -67.16928167766388, Eval reward: -206.68461914412268, TD loss   : 32.313421381115916, Episode   :     83\n",
      "Iteration :   9400, Train reward: -70.1927326151598, Eval reward: -206.68461914412268, TD loss   : 33.83844676375389, Episode   :     84\n",
      "Iteration :   9500, Train reward: -70.1927326151598, Eval reward: -14.890595914270659, TD loss   : 38.37772658705711, Episode   :     84\n",
      "Iteration :   9600, Train reward: -68.07873575805093, Eval reward: -14.890595914270659, TD loss   : 24.180996611714363, Episode   :     85\n",
      "Iteration :   9700, Train reward: -68.07873575805093, Eval reward: -14.890595914270659, TD loss   : 44.0803945183754, Episode   :     85\n",
      "Iteration :   9800, Train reward: -70.1496476209199, Eval reward: -14.890595914270659, TD loss   : 31.906323988437652, Episode   :     86\n",
      "Iteration :   9900, Train reward: -70.1496476209199, Eval reward: -14.890595914270659, TD loss   : 42.00177109003067, Episode   :     86\n",
      "Iteration :  10000, Train reward: -70.1496476209199, Eval reward: -31.491956900061286, TD loss   : 27.37259610772133, Episode   :     86\n",
      "Iteration :  10100, Train reward: -65.96149751244846, Eval reward: -31.491956900061286, TD loss   : 25.613263980150222, Episode   :     87\n",
      "Iteration :  10200, Train reward: -65.96149751244846, Eval reward: -31.491956900061286, TD loss   : 33.308656972646716, Episode   :     87\n",
      "Iteration :  10300, Train reward: -63.474150187064936, Eval reward: -31.491956900061286, TD loss   : 37.4567650437355, Episode   :     88\n",
      "Iteration :  10400, Train reward: -63.474150187064936, Eval reward: -31.491956900061286, TD loss   : 23.476014759540558, Episode   :     88\n",
      "Iteration :  10500, Train reward: -63.474150187064936, Eval reward: -44.33092196215607, TD loss   : 38.421537437438964, Episode   :     88\n",
      "Iteration :  10600, Train reward: -69.0507012797298, Eval reward: -44.33092196215607, TD loss   : 22.99065262198448, Episode   :     89\n",
      "Iteration :  10700, Train reward: -72.00693731470821, Eval reward: -44.33092196215607, TD loss   : 27.46093887448311, Episode   :     90\n",
      "Iteration :  10800, Train reward: -72.00693731470821, Eval reward: -44.33092196215607, TD loss   : 26.761151304244994, Episode   :     90\n",
      "Iteration :  10900, Train reward: -72.00693731470821, Eval reward: -44.33092196215607, TD loss   : 30.046215076446533, Episode   :     90\n",
      "Iteration :  11000, Train reward: -75.75326661259658, Eval reward: -56.19927812413747, TD loss   : 19.680110561847687, Episode   :     91\n",
      "Iteration :  11100, Train reward: -72.68818979145331, Eval reward: -56.19927812413747, TD loss   : 34.808927278518674, Episode   :     92\n",
      "Iteration :  11200, Train reward: -72.68818979145331, Eval reward: -56.19927812413747, TD loss   : 28.225750827789305, Episode   :     92\n",
      "Iteration :  11300, Train reward: -76.7980349162957, Eval reward: -56.19927812413747, TD loss   : 28.630449509620668, Episode   :     93\n",
      "Iteration :  11400, Train reward: -76.7980349162957, Eval reward: -56.19927812413747, TD loss   : 35.637613643407825, Episode   :     93\n",
      "Iteration :  11500, Train reward: -76.7980349162957, Eval reward: 5.710571276699278, TD loss   : 30.871474437713623, Episode   :     93\n",
      "Iteration :  11600, Train reward: -70.88129651003855, Eval reward: 5.710571276699278, TD loss   : 30.213048495054245, Episode   :     94\n",
      "Iteration :  11700, Train reward: -67.7853292237508, Eval reward: 5.710571276699278, TD loss   : 21.657996088266373, Episode   :     95\n",
      "Iteration :  11800, Train reward: -67.7853292237508, Eval reward: 5.710571276699278, TD loss   : 27.632963919639586, Episode   :     95\n",
      "Iteration :  11900, Train reward: -61.760626697797974, Eval reward: 5.710571276699278, TD loss   : 25.691853573322295, Episode   :     96\n",
      "Iteration :  12000, Train reward: -61.760626697797974, Eval reward: -59.28856407456167, TD loss   : 28.478261901140215, Episode   :     96\n",
      "Iteration :  12100, Train reward: -56.19497205967093, Eval reward: -59.28856407456167, TD loss   : 28.642551528215407, Episode   :     97\n",
      "Iteration :  12200, Train reward: -56.19497205967093, Eval reward: -59.28856407456167, TD loss   : 28.52453663825989, Episode   :     97\n",
      "Iteration :  12300, Train reward: -56.53711713716844, Eval reward: -59.28856407456167, TD loss   : 29.385723218917846, Episode   :     98\n",
      "Iteration :  12400, Train reward: -53.57363965385495, Eval reward: -59.28856407456167, TD loss   : 26.952121119499207, Episode   :     99\n",
      "Iteration :  12500, Train reward: -53.57363965385495, Eval reward: 10.392700502707466, TD loss   : 31.605430953502655, Episode   :     99\n",
      "Iteration :  12600, Train reward: -50.79467010258105, Eval reward: 10.392700502707466, TD loss   : 36.887335777282715, Episode   :    100\n",
      "Iteration :  12700, Train reward: -44.627631747533535, Eval reward: 10.392700502707466, TD loss   : 25.926788885593414, Episode   :    101\n",
      "Iteration :  12800, Train reward: -44.627631747533535, Eval reward: 10.392700502707466, TD loss   : 32.18274931788444, Episode   :    101\n",
      "Iteration :  12900, Train reward: -44.627631747533535, Eval reward: 10.392700502707466, TD loss   : 38.5957241153717, Episode   :    101\n",
      "Iteration :  13000, Train reward: -42.39448668143375, Eval reward: -146.12955109600188, TD loss   : 23.757898098230363, Episode   :    102\n",
      "Iteration :  13100, Train reward: -37.317124369368024, Eval reward: -146.12955109600188, TD loss   : 22.376501841545107, Episode   :    103\n",
      "Iteration :  13200, Train reward: -37.317124369368024, Eval reward: -146.12955109600188, TD loss   : 23.396265233755113, Episode   :    103\n",
      "Iteration :  13300, Train reward: -37.317124369368024, Eval reward: -146.12955109600188, TD loss   : 25.392605580091477, Episode   :    103\n",
      "Iteration :  13400, Train reward: -34.04143464139723, Eval reward: -146.12955109600188, TD loss   : 23.12054883480072, Episode   :    104\n",
      "Iteration :  13500, Train reward: -34.04143464139723, Eval reward: -71.98246666296014, TD loss   : 21.18245444178581, Episode   :    104\n",
      "Iteration :  13600, Train reward: -32.23918304642048, Eval reward: -71.98246666296014, TD loss   : 18.40007370352745, Episode   :    105\n",
      "Iteration :  13700, Train reward: -32.23918304642048, Eval reward: -71.98246666296014, TD loss   : 33.6319747620821, Episode   :    105\n",
      "Iteration :  13800, Train reward: -32.23918304642048, Eval reward: -71.98246666296014, TD loss   : 29.64686848759651, Episode   :    105\n",
      "Iteration :  13900, Train reward: -24.28342247812548, Eval reward: -71.98246666296014, TD loss   : 29.034383918046952, Episode   :    106\n",
      "Iteration :  14000, Train reward: -24.595017079921668, Eval reward: 40.135732643122445, TD loss   : 19.33458839893341, Episode   :    107\n",
      "Iteration :  14100, Train reward: -26.24577851952095, Eval reward: 40.135732643122445, TD loss   : 30.15982816696167, Episode   :    108\n",
      "Iteration :  14200, Train reward: -26.24577851952095, Eval reward: 40.135732643122445, TD loss   : 18.231838384866716, Episode   :    108\n",
      "Iteration :  14300, Train reward: -26.24577851952095, Eval reward: 40.135732643122445, TD loss   : 21.21340854525566, Episode   :    108\n",
      "Iteration :  14400, Train reward: -13.934411872151935, Eval reward: 40.135732643122445, TD loss   : 29.771886999607087, Episode   :    110\n",
      "Iteration :  14500, Train reward: -13.934411872151935, Eval reward: -49.04587912951871, TD loss   : 19.835657387375832, Episode   :    110\n",
      "Iteration :  14600, Train reward: -10.291637607750785, Eval reward: -49.04587912951871, TD loss   : 15.401145926117897, Episode   :    111\n",
      "Iteration :  14700, Train reward: -10.291637607750785, Eval reward: -49.04587912951871, TD loss   : 29.354845782518385, Episode   :    111\n",
      "Iteration :  14800, Train reward: -12.806066418319295, Eval reward: -49.04587912951871, TD loss   : 37.37513906896115, Episode   :    112\n",
      "Iteration :  14900, Train reward: -12.806066418319295, Eval reward: -49.04587912951871, TD loss   : 17.298873683810235, Episode   :    112\n",
      "Iteration :  15000, Train reward: -8.210594317625828, Eval reward: -12.233451528276017, TD loss   : 28.128992334604263, Episode   :    113\n",
      "Iteration :  15100, Train reward: -6.268442586896361, Eval reward: -12.233451528276017, TD loss   : 23.477862355709075, Episode   :    114\n",
      "Iteration :  15200, Train reward: -5.313539761880923, Eval reward: -12.233451528276017, TD loss   : 28.35832030594349, Episode   :    115\n",
      "Iteration :  15300, Train reward: -5.313539761880923, Eval reward: -12.233451528276017, TD loss   : 30.102032678127287, Episode   :    115\n",
      "Iteration :  15400, Train reward: -7.9917666422416405, Eval reward: -12.233451528276017, TD loss   : 36.243648409843445, Episode   :    116\n",
      "Iteration :  15500, Train reward: -7.9917666422416405, Eval reward: -4.626367158085244, TD loss   : 32.801255653500554, Episode   :    116\n",
      "Iteration :  15600, Train reward: -9.499421015480698, Eval reward: -4.626367158085244, TD loss   : 19.118703746795653, Episode   :    117\n",
      "Iteration :  15700, Train reward: -9.499421015480698, Eval reward: -4.626367158085244, TD loss   : 23.20429138839245, Episode   :    117\n",
      "Iteration :  15800, Train reward: -8.193264251190168, Eval reward: -4.626367158085244, TD loss   : 24.04376137495041, Episode   :    118\n",
      "Iteration :  15900, Train reward: -10.604682514976634, Eval reward: -4.626367158085244, TD loss   : 28.139201047420503, Episode   :    119\n",
      "Iteration :  16000, Train reward: -10.604682514976634, Eval reward: -61.25188827100957, TD loss   : 18.21332135617733, Episode   :    119\n",
      "Iteration :  16100, Train reward: -11.323898399041067, Eval reward: -61.25188827100957, TD loss   : 22.538325258493423, Episode   :    120\n",
      "Iteration :  16200, Train reward: -11.323898399041067, Eval reward: -61.25188827100957, TD loss   : 25.397557183504105, Episode   :    120\n",
      "Iteration :  16300, Train reward: -11.323898399041067, Eval reward: -61.25188827100957, TD loss   : 26.529474654197692, Episode   :    120\n",
      "Iteration :  16400, Train reward: -8.502288966106102, Eval reward: -61.25188827100957, TD loss   : 22.997372790575028, Episode   :    121\n",
      "Iteration :  16500, Train reward: -8.502288966106102, Eval reward: -101.09237863028363, TD loss   : 25.470760157108305, Episode   :    121\n",
      "Iteration :  16600, Train reward: -5.572092649397655, Eval reward: -101.09237863028363, TD loss   : 35.42442273497581, Episode   :    122\n",
      "Iteration :  16700, Train reward: -5.572092649397655, Eval reward: -101.09237863028363, TD loss   : 20.918420335650445, Episode   :    122\n",
      "Iteration :  16800, Train reward: -7.870650759274062, Eval reward: -101.09237863028363, TD loss   : 26.709313892126083, Episode   :    123\n",
      "Iteration :  16900, Train reward: -7.870650759274062, Eval reward: -101.09237863028363, TD loss   : 21.303065534830093, Episode   :    123\n",
      "Iteration :  17000, Train reward: -7.870650759274062, Eval reward: -53.431337118306644, TD loss   : 22.34812537789345, Episode   :    123\n",
      "Iteration :  17100, Train reward: -6.045994441335826, Eval reward: -53.431337118306644, TD loss   : 21.49906610965729, Episode   :    124\n",
      "Iteration :  17200, Train reward: -6.045994441335826, Eval reward: -53.431337118306644, TD loss   : 18.106512900590896, Episode   :    124\n",
      "Iteration :  17300, Train reward: -6.045994441335826, Eval reward: -53.431337118306644, TD loss   : 26.692881811857223, Episode   :    124\n",
      "Iteration :  17400, Train reward: -7.475234746815682, Eval reward: -53.431337118306644, TD loss   : 22.36364122390747, Episode   :    125\n",
      "Iteration :  17500, Train reward: -7.475234746815682, Eval reward: 9.839805417311846, TD loss   : 17.90856231570244, Episode   :    125\n",
      "Iteration :  17600, Train reward: -10.372900412897195, Eval reward: 9.839805417311846, TD loss   : 27.529866151809692, Episode   :    126\n",
      "Iteration :  17700, Train reward: -10.372900412897195, Eval reward: 9.839805417311846, TD loss   : 17.729824620485306, Episode   :    126\n",
      "Iteration :  17800, Train reward: -8.251503310111044, Eval reward: 9.839805417311846, TD loss   : 18.18839078903198, Episode   :    127\n",
      "Iteration :  17900, Train reward: -8.251503310111044, Eval reward: 9.839805417311846, TD loss   : 14.321159635782243, Episode   :    127\n",
      "Iteration :  18000, Train reward: -8.251503310111044, Eval reward: -16.926452438934714, TD loss   : 20.622308019399643, Episode   :    127\n",
      "Iteration :  18100, Train reward: 0.5866836182068269, Eval reward: -16.926452438934714, TD loss   : 23.324115641117096, Episode   :    128\n",
      "Iteration :  18200, Train reward: 0.5866836182068269, Eval reward: -16.926452438934714, TD loss   : 19.16207600593567, Episode   :    128\n",
      "Iteration :  18300, Train reward: 0.5866836182068269, Eval reward: -16.926452438934714, TD loss   : 24.391137903928758, Episode   :    128\n",
      "Iteration :  18400, Train reward: 0.4895103782727606, Eval reward: -16.926452438934714, TD loss   : 11.565194035768508, Episode   :    129\n",
      "Iteration :  18500, Train reward: 0.4895103782727606, Eval reward: 26.752056193895395, TD loss   : 17.479095109701156, Episode   :    129\n",
      "Iteration :  18600, Train reward: 3.813086988245704, Eval reward: 26.752056193895395, TD loss   : 15.05341863155365, Episode   :    130\n",
      "Iteration :  18700, Train reward: 3.813086988245704, Eval reward: 26.752056193895395, TD loss   : 16.204495616555214, Episode   :    130\n",
      "Iteration :  18800, Train reward: 3.813086988245704, Eval reward: 26.752056193895395, TD loss   : 22.748579454421996, Episode   :    130\n",
      "Iteration :  18900, Train reward: 2.8162105307002427, Eval reward: 26.752056193895395, TD loss   : 15.065207493305206, Episode   :    131\n",
      "Iteration :  19000, Train reward: 4.423000775279458, Eval reward: -155.84208367036928, TD loss   : 15.710459595918655, Episode   :    132\n",
      "Iteration :  19100, Train reward: 3.71806686346111, Eval reward: -155.84208367036928, TD loss   : 22.147673542499543, Episode   :    133\n",
      "Iteration :  19200, Train reward: 3.71806686346111, Eval reward: -155.84208367036928, TD loss   : 22.154356293678283, Episode   :    133\n",
      "Iteration :  19300, Train reward: 3.71806686346111, Eval reward: -155.84208367036928, TD loss   : 26.73375324368477, Episode   :    133\n",
      "Iteration :  19400, Train reward: 9.075623534181188, Eval reward: -155.84208367036928, TD loss   : 30.05108435988426, Episode   :    134\n",
      "Iteration :  19500, Train reward: 9.075623534181188, Eval reward: 70.13970637294999, TD loss   : 23.663058902025224, Episode   :    134\n",
      "Iteration :  19600, Train reward: 11.776987285463267, Eval reward: 70.13970637294999, TD loss   : 21.220566370487212, Episode   :    135\n",
      "Iteration :  19700, Train reward: 11.776987285463267, Eval reward: 70.13970637294999, TD loss   : 29.843774304389953, Episode   :    135\n",
      "Iteration :  19800, Train reward: 11.776987285463267, Eval reward: 70.13970637294999, TD loss   : 20.710597419738768, Episode   :    135\n",
      "Iteration :  19900, Train reward: 17.06461761796235, Eval reward: 70.13970637294999, TD loss   : 18.511584438085556, Episode   :    136\n",
      "Iteration :  20000, Train reward: 17.06461761796235, Eval reward: -74.39447672574917, TD loss   : 29.297150094509124, Episode   :    136\n",
      "Iteration :  20100, Train reward: 13.272615889499338, Eval reward: -74.39447672574917, TD loss   : 19.686196702718735, Episode   :    137\n",
      "Iteration :  20200, Train reward: 13.272615889499338, Eval reward: -74.39447672574917, TD loss   : 26.318982433080674, Episode   :    137\n",
      "Iteration :  20300, Train reward: 13.272615889499338, Eval reward: -74.39447672574917, TD loss   : 22.43203146934509, Episode   :    137\n",
      "Iteration :  20400, Train reward: 16.238638553614237, Eval reward: -74.39447672574917, TD loss   : 18.633988609313963, Episode   :    138\n",
      "Iteration :  20500, Train reward: 16.238638553614237, Eval reward: -12.887266573208143, TD loss   : 22.47291863203049, Episode   :    138\n",
      "Iteration :  20600, Train reward: 26.8762978937443, Eval reward: -12.887266573208143, TD loss   : 23.81297497689724, Episode   :    139\n",
      "Iteration :  20700, Train reward: 26.8762978937443, Eval reward: -12.887266573208143, TD loss   : 21.575708309412004, Episode   :    139\n",
      "Iteration :  20800, Train reward: 26.8762978937443, Eval reward: -12.887266573208143, TD loss   : 23.82414063692093, Episode   :    139\n",
      "Iteration :  20900, Train reward: 28.320378627109932, Eval reward: -12.887266573208143, TD loss   : 23.686342591047286, Episode   :    140\n",
      "Iteration :  21000, Train reward: 28.320378627109932, Eval reward: -70.58796271055529, TD loss   : 19.969232934713364, Episode   :    140\n",
      "Iteration :  21100, Train reward: 26.551028545531228, Eval reward: -70.58796271055529, TD loss   : 16.084259872436522, Episode   :    141\n",
      "Iteration :  21200, Train reward: 26.551028545531228, Eval reward: -70.58796271055529, TD loss   : 18.526421225070955, Episode   :    141\n",
      "Iteration :  21300, Train reward: 26.551028545531228, Eval reward: -70.58796271055529, TD loss   : 24.51455075740814, Episode   :    141\n",
      "Iteration :  21400, Train reward: 25.002060272059385, Eval reward: -70.58796271055529, TD loss   : 22.819908747673036, Episode   :    142\n",
      "Iteration :  21500, Train reward: 25.002060272059385, Eval reward: -27.34123054040374, TD loss   : 23.9138875412941, Episode   :    142\n",
      "Iteration :  21600, Train reward: 30.469251185133437, Eval reward: -27.34123054040374, TD loss   : 13.89596126794815, Episode   :    143\n",
      "Iteration :  21700, Train reward: 30.469251185133437, Eval reward: -27.34123054040374, TD loss   : 12.679471156597138, Episode   :    143\n",
      "Iteration :  21800, Train reward: 30.469251185133437, Eval reward: -27.34123054040374, TD loss   : 17.38942590236664, Episode   :    143\n",
      "Iteration :  21900, Train reward: 32.31092196147391, Eval reward: -27.34123054040374, TD loss   : 31.612903262376786, Episode   :    145\n",
      "Iteration :  22000, Train reward: 32.31092196147391, Eval reward: 11.664547353818874, TD loss   : 13.1457672560215, Episode   :    145\n",
      "Iteration :  22100, Train reward: 32.494766620103356, Eval reward: 11.664547353818874, TD loss   : 20.579805549383163, Episode   :    146\n",
      "Iteration :  22200, Train reward: 32.494766620103356, Eval reward: 11.664547353818874, TD loss   : 18.621913591623308, Episode   :    146\n",
      "Iteration :  22300, Train reward: 19.919273402642794, Eval reward: 11.664547353818874, TD loss   : 25.177760466337205, Episode   :    147\n",
      "Iteration :  22400, Train reward: 19.919273402642794, Eval reward: 11.664547353818874, TD loss   : 16.87486276268959, Episode   :    147\n",
      "Iteration :  22500, Train reward: 19.919273402642794, Eval reward: -82.98141064993652, TD loss   : 19.985685925483704, Episode   :    147\n",
      "Iteration :  22600, Train reward: 14.029479569536417, Eval reward: -82.98141064993652, TD loss   : 25.081184391975402, Episode   :    148\n",
      "Iteration :  22700, Train reward: 14.029479569536417, Eval reward: -82.98141064993652, TD loss   : 10.23934777855873, Episode   :    148\n",
      "Iteration :  22800, Train reward: 14.029479569536417, Eval reward: -82.98141064993652, TD loss   : 17.8054577088356, Episode   :    148\n",
      "Iteration :  22900, Train reward: 17.275642714834756, Eval reward: -82.98141064993652, TD loss   : 22.464679124355317, Episode   :    149\n",
      "Iteration :  23000, Train reward: 17.275642714834756, Eval reward: -87.13379661633068, TD loss   : 27.590204207897187, Episode   :    149\n",
      "Iteration :  23100, Train reward: 15.41613485429177, Eval reward: -87.13379661633068, TD loss   : 15.542808257341385, Episode   :    150\n",
      "Iteration :  23200, Train reward: 15.41613485429177, Eval reward: -87.13379661633068, TD loss   : 22.986909737586974, Episode   :    150\n",
      "Iteration :  23300, Train reward: 15.41613485429177, Eval reward: -87.13379661633068, TD loss   : 19.20287164926529, Episode   :    150\n",
      "Iteration :  23400, Train reward: 12.491021844711671, Eval reward: -87.13379661633068, TD loss   : 13.062280797958374, Episode   :    151\n",
      "Iteration :  23500, Train reward: 12.491021844711671, Eval reward: -76.41853125425828, TD loss   : 16.412429524660112, Episode   :    151\n",
      "Iteration :  23600, Train reward: 16.149552040431985, Eval reward: -76.41853125425828, TD loss   : 23.602010369300842, Episode   :    152\n",
      "Iteration :  23700, Train reward: 16.149552040431985, Eval reward: -76.41853125425828, TD loss   : 19.134166561365127, Episode   :    152\n",
      "Iteration :  23800, Train reward: 16.149552040431985, Eval reward: -76.41853125425828, TD loss   : 12.735815222263335, Episode   :    152\n",
      "Iteration :  23900, Train reward: 19.988215702027286, Eval reward: -76.41853125425828, TD loss   : 15.383464523553847, Episode   :    153\n",
      "Iteration :  24000, Train reward: 19.988215702027286, Eval reward: 30.531488162898473, TD loss   : 13.827371137142181, Episode   :    153\n",
      "Iteration :  24100, Train reward: 15.9917156204202, Eval reward: 30.531488162898473, TD loss   : 13.852261239290238, Episode   :    154\n",
      "Iteration :  24200, Train reward: 15.9917156204202, Eval reward: 30.531488162898473, TD loss   : 18.21969884753227, Episode   :    154\n",
      "Iteration :  24300, Train reward: 15.9917156204202, Eval reward: 30.531488162898473, TD loss   : 22.105861473083497, Episode   :    154\n",
      "Iteration :  24400, Train reward: 15.30023688676236, Eval reward: 30.531488162898473, TD loss   : 15.060182558894157, Episode   :    155\n",
      "Iteration :  24500, Train reward: 15.30023688676236, Eval reward: -70.39648486462528, TD loss   : 13.963844748735427, Episode   :    155\n",
      "Iteration :  24600, Train reward: 16.134904697215198, Eval reward: -70.39648486462528, TD loss   : 18.760671219825745, Episode   :    156\n",
      "Iteration :  24700, Train reward: 16.134904697215198, Eval reward: -70.39648486462528, TD loss   : 20.076434129476546, Episode   :    156\n",
      "Iteration :  24800, Train reward: 16.134904697215198, Eval reward: -70.39648486462528, TD loss   : 20.326108288764953, Episode   :    156\n",
      "Iteration :  24900, Train reward: 17.958306227628604, Eval reward: -70.39648486462528, TD loss   : 10.957910818457604, Episode   :    157\n",
      "Iteration :  25000, Train reward: 17.958306227628604, Eval reward: -28.41261142782317, TD loss   : 17.189907404184343, Episode   :    157\n",
      "Iteration :  25100, Train reward: 16.905175465759225, Eval reward: -28.41261142782317, TD loss   : 15.527927697896958, Episode   :    158\n",
      "Iteration :  25200, Train reward: 16.905175465759225, Eval reward: -28.41261142782317, TD loss   : 11.218687057495117, Episode   :    158\n",
      "Iteration :  25300, Train reward: 16.905175465759225, Eval reward: -28.41261142782317, TD loss   : 15.739968178272248, Episode   :    158\n",
      "Iteration :  25400, Train reward: 11.98979716121505, Eval reward: -28.41261142782317, TD loss   : 14.098287276029588, Episode   :    159\n",
      "Iteration :  25500, Train reward: 11.98979716121505, Eval reward: -11.237257599528817, TD loss   : 14.465156420469285, Episode   :    159\n",
      "Iteration :  25600, Train reward: 13.966982520376964, Eval reward: -11.237257599528817, TD loss   : 21.802385966777802, Episode   :    160\n",
      "Iteration :  25700, Train reward: 13.966982520376964, Eval reward: -11.237257599528817, TD loss   : 13.728829208612442, Episode   :    160\n",
      "Iteration :  25800, Train reward: 13.966982520376964, Eval reward: -11.237257599528817, TD loss   : 21.440108548402787, Episode   :    160\n",
      "Iteration :  25900, Train reward: 15.24260547531629, Eval reward: -11.237257599528817, TD loss   : 9.739873907566071, Episode   :    161\n",
      "Iteration :  26000, Train reward: 15.24260547531629, Eval reward: 3.167180429624898, TD loss   : 17.49765655040741, Episode   :    161\n",
      "Iteration :  26100, Train reward: 15.67010878326341, Eval reward: 3.167180429624898, TD loss   : 8.354153690338135, Episode   :    162\n",
      "Iteration :  26200, Train reward: 15.67010878326341, Eval reward: 3.167180429624898, TD loss   : 11.982156723737717, Episode   :    162\n",
      "Iteration :  26300, Train reward: 15.67010878326341, Eval reward: 3.167180429624898, TD loss   : 11.833313076496124, Episode   :    162\n",
      "Iteration :  26400, Train reward: 11.977500659051682, Eval reward: 3.167180429624898, TD loss   : 17.412218376994133, Episode   :    164\n",
      "Iteration :  26500, Train reward: 11.977500659051682, Eval reward: 41.87238785728537, TD loss   : 16.07885157585144, Episode   :    164\n",
      "Iteration :  26600, Train reward: 14.315515163938986, Eval reward: 41.87238785728537, TD loss   : 17.00528718829155, Episode   :    165\n",
      "Iteration :  26700, Train reward: 14.315515163938986, Eval reward: 41.87238785728537, TD loss   : 12.31638045310974, Episode   :    165\n",
      "Iteration :  26800, Train reward: 14.315515163938986, Eval reward: 41.87238785728537, TD loss   : 21.994630290269853, Episode   :    165\n",
      "Iteration :  26900, Train reward: 13.886226068962646, Eval reward: 41.87238785728537, TD loss   : 17.719437083005904, Episode   :    166\n",
      "Iteration :  27000, Train reward: 13.886226068962646, Eval reward: 57.035265366057764, TD loss   : 8.933442106246948, Episode   :    166\n",
      "Iteration :  27100, Train reward: 25.211923275200398, Eval reward: 57.035265366057764, TD loss   : 17.90193406701088, Episode   :    167\n",
      "Iteration :  27200, Train reward: 25.211923275200398, Eval reward: 57.035265366057764, TD loss   : 21.985624319314958, Episode   :    167\n",
      "Iteration :  27300, Train reward: 25.211923275200398, Eval reward: 57.035265366057764, TD loss   : 13.146778662204742, Episode   :    167\n",
      "Iteration :  27400, Train reward: 26.365314042203998, Eval reward: 57.035265366057764, TD loss   : 16.71881629228592, Episode   :    168\n",
      "Iteration :  27500, Train reward: 26.365314042203998, Eval reward: 64.91478442754858, TD loss   : 12.616818178892135, Episode   :    168\n",
      "Iteration :  27600, Train reward: 24.604700474776735, Eval reward: 64.91478442754858, TD loss   : 13.923506380319596, Episode   :    169\n",
      "Iteration :  27700, Train reward: 24.604700474776735, Eval reward: 64.91478442754858, TD loss   : 13.10938243508339, Episode   :    169\n",
      "Iteration :  27800, Train reward: 24.604700474776735, Eval reward: 64.91478442754858, TD loss   : 15.889047881364823, Episode   :    169\n",
      "Iteration :  27900, Train reward: 26.95024716379205, Eval reward: 64.91478442754858, TD loss   : 18.32656016588211, Episode   :    170\n",
      "Iteration :  28000, Train reward: 26.95024716379205, Eval reward: 5.618365531247582, TD loss   : 19.722204138040542, Episode   :    170\n",
      "Iteration :  28100, Train reward: 30.76109945419259, Eval reward: 5.618365531247582, TD loss   : 14.042021750211715, Episode   :    171\n",
      "Iteration :  28200, Train reward: 30.76109945419259, Eval reward: 5.618365531247582, TD loss   : 15.347203513383866, Episode   :    171\n",
      "Iteration :  28300, Train reward: 30.76109945419259, Eval reward: 5.618365531247582, TD loss   : 13.030635775327683, Episode   :    171\n",
      "Iteration :  28400, Train reward: 29.913033816783546, Eval reward: 5.618365531247582, TD loss   : 11.522683044672013, Episode   :    172\n",
      "Iteration :  28500, Train reward: 29.913033816783546, Eval reward: -28.03386980410894, TD loss   : 30.150038818120958, Episode   :    172\n",
      "Iteration :  28600, Train reward: 24.406926778694192, Eval reward: -28.03386980410894, TD loss   : 16.737993963956832, Episode   :    173\n",
      "Iteration :  28700, Train reward: 24.406926778694192, Eval reward: -28.03386980410894, TD loss   : 21.926523278951645, Episode   :    173\n",
      "Iteration :  28800, Train reward: 24.406926778694192, Eval reward: -28.03386980410894, TD loss   : 17.381153790950776, Episode   :    173\n",
      "Iteration :  28900, Train reward: 22.23321046844526, Eval reward: -28.03386980410894, TD loss   : 24.532382563352584, Episode   :    174\n",
      "Iteration :  29000, Train reward: 22.23321046844526, Eval reward: -6.666734862533422, TD loss   : 10.140431996583938, Episode   :    174\n",
      "Iteration :  29100, Train reward: 23.37239321107545, Eval reward: -6.666734862533422, TD loss   : 15.802174192667007, Episode   :    175\n",
      "Iteration :  29200, Train reward: 23.37239321107545, Eval reward: -6.666734862533422, TD loss   : 9.734529255628585, Episode   :    175\n",
      "Iteration :  29300, Train reward: 23.37239321107545, Eval reward: -6.666734862533422, TD loss   : 10.422324206829071, Episode   :    175\n",
      "Iteration :  29400, Train reward: 23.096942848087462, Eval reward: -6.666734862533422, TD loss   : 18.552177159786226, Episode   :    176\n",
      "Iteration :  29500, Train reward: 23.096942848087462, Eval reward: -25.82832806700237, TD loss   : 13.965101076364517, Episode   :    176\n",
      "Iteration :  29600, Train reward: 24.968929901325023, Eval reward: -25.82832806700237, TD loss   : 8.133151160478592, Episode   :    177\n",
      "Iteration :  29700, Train reward: 24.968929901325023, Eval reward: -25.82832806700237, TD loss   : 15.792068889141083, Episode   :    177\n",
      "Iteration :  29800, Train reward: 24.968929901325023, Eval reward: -25.82832806700237, TD loss   : 17.56670163631439, Episode   :    177\n",
      "Iteration :  29900, Train reward: 24.231392672749188, Eval reward: -25.82832806700237, TD loss   : 18.89687563419342, Episode   :    179\n",
      "Iteration :  30000, Train reward: 24.231392672749188, Eval reward: 25.568996873897895, TD loss   : 15.143210806846618, Episode   :    179\n",
      "Iteration :  30100, Train reward: 26.411935653201574, Eval reward: 25.568996873897895, TD loss   : 16.385915845632553, Episode   :    180\n",
      "Iteration :  30200, Train reward: 26.411935653201574, Eval reward: 25.568996873897895, TD loss   : 14.287496101856231, Episode   :    180\n",
      "Iteration :  30300, Train reward: 26.411935653201574, Eval reward: 25.568996873897895, TD loss   : 17.141787313222885, Episode   :    180\n",
      "Iteration :  30400, Train reward: 17.88541995763892, Eval reward: 25.568996873897895, TD loss   : 13.627405453920364, Episode   :    181\n",
      "Iteration :  30500, Train reward: 17.88541995763892, Eval reward: -25.864538659497747, TD loss   : 21.47474083542824, Episode   :    181\n",
      "Iteration :  30600, Train reward: 19.23959372994249, Eval reward: -25.864538659497747, TD loss   : 14.963195683956146, Episode   :    182\n",
      "Iteration :  30700, Train reward: 19.23959372994249, Eval reward: -25.864538659497747, TD loss   : 25.62133060336113, Episode   :    182\n",
      "Iteration :  30800, Train reward: 19.23959372994249, Eval reward: -25.864538659497747, TD loss   : 21.93444721698761, Episode   :    182\n",
      "Iteration :  30900, Train reward: 20.00317354187972, Eval reward: -25.864538659497747, TD loss   : 16.45378040909767, Episode   :    183\n",
      "Iteration :  31000, Train reward: 20.00317354187972, Eval reward: 39.8483963094573, TD loss   : 12.230068335533142, Episode   :    183\n",
      "Iteration :  31100, Train reward: 21.758117088435966, Eval reward: 39.8483963094573, TD loss   : 16.740108926296234, Episode   :    184\n",
      "Iteration :  31200, Train reward: 21.758117088435966, Eval reward: 39.8483963094573, TD loss   : 10.017846841216087, Episode   :    184\n",
      "Iteration :  31300, Train reward: 21.758117088435966, Eval reward: 39.8483963094573, TD loss   : 19.70283164858818, Episode   :    184\n",
      "Iteration :  31400, Train reward: 20.84185626858715, Eval reward: 39.8483963094573, TD loss   : 12.85126920580864, Episode   :    185\n",
      "Iteration :  31500, Train reward: 20.84185626858715, Eval reward: 9.653914231290367, TD loss   : 10.312549726963043, Episode   :    185\n",
      "Iteration :  31600, Train reward: 21.978608683519333, Eval reward: 9.653914231290367, TD loss   : 20.78917079091072, Episode   :    186\n",
      "Iteration :  31700, Train reward: 21.978608683519333, Eval reward: 9.653914231290367, TD loss   : 19.36579499959946, Episode   :    186\n",
      "Iteration :  31800, Train reward: 21.978608683519333, Eval reward: 9.653914231290367, TD loss   : 13.764888847470283, Episode   :    186\n",
      "Iteration :  31900, Train reward: 23.57154029219522, Eval reward: 9.653914231290367, TD loss   : 17.68086249947548, Episode   :    187\n",
      "Iteration :  32000, Train reward: 23.57154029219522, Eval reward: 35.812277771381844, TD loss   : 14.787391802072525, Episode   :    187\n",
      "Iteration :  32100, Train reward: 27.326996332746916, Eval reward: 35.812277771381844, TD loss   : 18.60394434094429, Episode   :    188\n",
      "Iteration :  32200, Train reward: 27.326996332746916, Eval reward: 35.812277771381844, TD loss   : 22.572289024591445, Episode   :    188\n",
      "Iteration :  32300, Train reward: 27.326996332746916, Eval reward: 35.812277771381844, TD loss   : 13.57030036687851, Episode   :    188\n",
      "Iteration :  32400, Train reward: 27.057296678282086, Eval reward: 35.812277771381844, TD loss   : 15.961531938314439, Episode   :    189\n",
      "Iteration :  32500, Train reward: 27.057296678282086, Eval reward: 81.5588433745337, TD loss   : 17.870362766981124, Episode   :    189\n",
      "Iteration :  32600, Train reward: 28.049770138515772, Eval reward: 81.5588433745337, TD loss   : 19.033497301340102, Episode   :    190\n",
      "Iteration :  32700, Train reward: 28.049770138515772, Eval reward: 81.5588433745337, TD loss   : 14.644951577186584, Episode   :    190\n",
      "Iteration :  32800, Train reward: 28.049770138515772, Eval reward: 81.5588433745337, TD loss   : 13.054206018447877, Episode   :    190\n",
      "Iteration :  32900, Train reward: 28.915175128525004, Eval reward: 81.5588433745337, TD loss   : 16.72085577368736, Episode   :    191\n",
      "Iteration :  33000, Train reward: 28.915175128525004, Eval reward: 59.86989668283078, TD loss   : 14.707752474546432, Episode   :    191\n",
      "Iteration :  33100, Train reward: 29.71719013164622, Eval reward: 59.86989668283078, TD loss   : 13.329570742249489, Episode   :    192\n",
      "Iteration :  33200, Train reward: 29.71719013164622, Eval reward: 59.86989668283078, TD loss   : 15.52767120361328, Episode   :    192\n",
      "Iteration :  33300, Train reward: 29.71719013164622, Eval reward: 59.86989668283078, TD loss   : 17.98331621527672, Episode   :    192\n",
      "Iteration :  33400, Train reward: 29.890624997683137, Eval reward: 59.86989668283078, TD loss   : 20.5501058280468, Episode   :    193\n",
      "Iteration :  33500, Train reward: 29.890624997683137, Eval reward: 25.270444038929988, TD loss   : 15.132920192480087, Episode   :    193\n",
      "Iteration :  33600, Train reward: 32.06250354909165, Eval reward: 25.270444038929988, TD loss   : 13.849404653310776, Episode   :    194\n",
      "Iteration :  33700, Train reward: 32.06250354909165, Eval reward: 25.270444038929988, TD loss   : 15.446159310340882, Episode   :    194\n",
      "Iteration :  33800, Train reward: 32.06250354909165, Eval reward: 25.270444038929988, TD loss   : 12.003369209766388, Episode   :    194\n",
      "Iteration :  33900, Train reward: 29.909860511279145, Eval reward: 25.270444038929988, TD loss   : 9.542521710395812, Episode   :    195\n",
      "Iteration :  34000, Train reward: 29.909860511279145, Eval reward: -63.42895060779269, TD loss   : 20.134820413589477, Episode   :    195\n",
      "Iteration :  34100, Train reward: 25.445161878931387, Eval reward: -63.42895060779269, TD loss   : 19.978878734111785, Episode   :    196\n",
      "Iteration :  34200, Train reward: 17.11419709943928, Eval reward: -63.42895060779269, TD loss   : 27.68409868121147, Episode   :    197\n",
      "Iteration :  34300, Train reward: 17.11419709943928, Eval reward: -63.42895060779269, TD loss   : 14.57930167913437, Episode   :    197\n",
      "Iteration :  34400, Train reward: 17.11419709943928, Eval reward: -63.42895060779269, TD loss   : 15.878146200180053, Episode   :    197\n",
      "Iteration :  34500, Train reward: 17.8131723364529, Eval reward: 17.962282921563176, TD loss   : 18.80310805439949, Episode   :    198\n",
      "Iteration :  34600, Train reward: 16.21244567421674, Eval reward: 17.962282921563176, TD loss   : 18.626985913515092, Episode   :    199\n",
      "Iteration :  34700, Train reward: 16.21244567421674, Eval reward: 17.962282921563176, TD loss   : 15.649746930599212, Episode   :    199\n",
      "Iteration :  34800, Train reward: 16.21244567421674, Eval reward: 17.962282921563176, TD loss   : 12.352406703233719, Episode   :    199\n",
      "Iteration :  34900, Train reward: 16.24177947731246, Eval reward: 17.962282921563176, TD loss   : 11.95000285744667, Episode   :    200\n",
      "Iteration :  35000, Train reward: 16.24177947731246, Eval reward: 55.42517465199633, TD loss   : 18.890436825752257, Episode   :    200\n",
      "Iteration :  35100, Train reward: 24.69315983540997, Eval reward: 55.42517465199633, TD loss   : 19.475747224092483, Episode   :    201\n",
      "Iteration :  35200, Train reward: 24.69315983540997, Eval reward: 55.42517465199633, TD loss   : 16.126289277076722, Episode   :    201\n",
      "Iteration :  35300, Train reward: 24.69315983540997, Eval reward: 55.42517465199633, TD loss   : 16.316152173280717, Episode   :    201\n",
      "Iteration :  35400, Train reward: 25.39632772800098, Eval reward: 55.42517465199633, TD loss   : 15.242204530239105, Episode   :    202\n",
      "Iteration :  35500, Train reward: 25.39632772800098, Eval reward: 27.620762883120506, TD loss   : 21.283338372707366, Episode   :    202\n",
      "Iteration :  35600, Train reward: 24.830281243912843, Eval reward: 27.620762883120506, TD loss   : 11.78204236626625, Episode   :    203\n",
      "Iteration :  35700, Train reward: 24.830281243912843, Eval reward: 27.620762883120506, TD loss   : 19.507894839048387, Episode   :    203\n",
      "Iteration :  35800, Train reward: 24.830281243912843, Eval reward: 27.620762883120506, TD loss   : 6.811722941398621, Episode   :    203\n",
      "Iteration :  35900, Train reward: 23.57258336104413, Eval reward: 27.620762883120506, TD loss   : 24.710993622541427, Episode   :    204\n",
      "Iteration :  36000, Train reward: 23.57258336104413, Eval reward: 24.131310886846798, TD loss   : 16.345276291370393, Episode   :    204\n",
      "Iteration :  36100, Train reward: 23.851005023696224, Eval reward: 24.131310886846798, TD loss   : 19.253854557275773, Episode   :    205\n",
      "Iteration :  36200, Train reward: 23.851005023696224, Eval reward: 24.131310886846798, TD loss   : 24.91010887503624, Episode   :    205\n",
      "Iteration :  36300, Train reward: 23.851005023696224, Eval reward: 24.131310886846798, TD loss   : 15.99696090579033, Episode   :    205\n",
      "Iteration :  36400, Train reward: 22.66000585077622, Eval reward: 24.131310886846798, TD loss   : 17.959520931243897, Episode   :    206\n",
      "Iteration :  36500, Train reward: 22.66000585077622, Eval reward: 37.26414175120571, TD loss   : 11.805525145530702, Episode   :    206\n",
      "Iteration :  36600, Train reward: 24.196025123494945, Eval reward: 37.26414175120571, TD loss   : 15.986430032253265, Episode   :    207\n",
      "Iteration :  36700, Train reward: 24.196025123494945, Eval reward: 37.26414175120571, TD loss   : 11.660416892766953, Episode   :    207\n",
      "Iteration :  36800, Train reward: 24.196025123494945, Eval reward: 37.26414175120571, TD loss   : 12.315492029190063, Episode   :    207\n",
      "Iteration :  36900, Train reward: 19.850142312233412, Eval reward: 37.26414175120571, TD loss   : 7.6636833399534225, Episode   :    208\n",
      "Iteration :  37000, Train reward: 19.850142312233412, Eval reward: 22.235488913364158, TD loss   : 15.021664966344833, Episode   :    208\n",
      "Iteration :  37100, Train reward: 19.38520372757833, Eval reward: 22.235488913364158, TD loss   : 15.251063467264176, Episode   :    209\n",
      "Iteration :  37200, Train reward: 19.38520372757833, Eval reward: 22.235488913364158, TD loss   : 16.827203903198242, Episode   :    209\n",
      "Iteration :  37300, Train reward: 19.38520372757833, Eval reward: 22.235488913364158, TD loss   : 22.32946001768112, Episode   :    209\n",
      "Iteration :  37400, Train reward: 19.423361341832408, Eval reward: 22.235488913364158, TD loss   : 13.406095494031906, Episode   :    210\n",
      "Iteration :  37500, Train reward: 19.423361341832408, Eval reward: 45.25770155053557, TD loss   : 12.330621889829636, Episode   :    210\n",
      "Iteration :  37600, Train reward: 17.188226054500465, Eval reward: 45.25770155053557, TD loss   : 24.733800568580627, Episode   :    211\n",
      "Iteration :  37700, Train reward: 17.015780050963308, Eval reward: 45.25770155053557, TD loss   : 13.094449359178544, Episode   :    212\n",
      "Iteration :  37800, Train reward: 11.354482171249508, Eval reward: 45.25770155053557, TD loss   : 19.574004145860673, Episode   :    213\n",
      "Iteration :  37900, Train reward: 11.354482171249508, Eval reward: 45.25770155053557, TD loss   : 19.73054717183113, Episode   :    213\n",
      "Iteration :  38000, Train reward: 11.354482171249508, Eval reward: 36.81389894500996, TD loss   : 13.987796511650085, Episode   :    213\n",
      "Iteration :  38100, Train reward: 11.154955239505547, Eval reward: 36.81389894500996, TD loss   : 24.002644869089128, Episode   :    214\n",
      "Iteration :  38200, Train reward: 11.154955239505547, Eval reward: 36.81389894500996, TD loss   : 12.7596584379673, Episode   :    214\n",
      "Iteration :  38300, Train reward: 11.154955239505547, Eval reward: 36.81389894500996, TD loss   : 18.799113725423812, Episode   :    214\n",
      "Iteration :  38400, Train reward: 11.611172804576954, Eval reward: 36.81389894500996, TD loss   : 12.31125510931015, Episode   :    215\n",
      "Iteration :  38500, Train reward: 11.611172804576954, Eval reward: 19.99363311322551, TD loss   : 26.75108397603035, Episode   :    215\n",
      "Iteration :  38600, Train reward: 17.856872184893454, Eval reward: 19.99363311322551, TD loss   : 19.2598273396492, Episode   :    216\n",
      "Iteration :  38700, Train reward: 17.856872184893454, Eval reward: 19.99363311322551, TD loss   : 16.816239458322524, Episode   :    216\n",
      "Iteration :  38800, Train reward: 17.856872184893454, Eval reward: 19.99363311322551, TD loss   : 17.788165290355682, Episode   :    216\n",
      "Iteration :  38900, Train reward: 24.208685745610413, Eval reward: 19.99363311322551, TD loss   : 17.379924976825713, Episode   :    217\n",
      "Iteration :  39000, Train reward: 24.208685745610413, Eval reward: 19.588058347169984, TD loss   : 12.523972831964493, Episode   :    217\n",
      "Iteration :  39100, Train reward: 26.75509217527206, Eval reward: 19.588058347169984, TD loss   : 19.993926080465318, Episode   :    218\n",
      "Iteration :  39200, Train reward: 26.75509217527206, Eval reward: 19.588058347169984, TD loss   : 20.723318018913268, Episode   :    218\n",
      "Iteration :  39300, Train reward: 26.75509217527206, Eval reward: 19.588058347169984, TD loss   : 10.753810412883759, Episode   :    218\n",
      "Iteration :  39400, Train reward: 29.83559508685812, Eval reward: 19.588058347169984, TD loss   : 20.914332473278044, Episode   :    219\n",
      "Iteration :  39500, Train reward: 29.83559508685812, Eval reward: 11.958634996588486, TD loss   : 18.427006273269654, Episode   :    219\n",
      "Iteration :  39600, Train reward: 27.183236486418018, Eval reward: 11.958634996588486, TD loss   : 19.03757980465889, Episode   :    220\n",
      "Iteration :  39700, Train reward: 27.183236486418018, Eval reward: 11.958634996588486, TD loss   : 15.498211646080017, Episode   :    220\n",
      "Iteration :  39800, Train reward: 27.183236486418018, Eval reward: 11.958634996588486, TD loss   : 23.279051653146745, Episode   :    220\n",
      "Iteration :  39900, Train reward: 28.671644372380275, Eval reward: 11.958634996588486, TD loss   : 21.50384161233902, Episode   :    221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HasanErdin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\HasanErdin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :      0, Train reward:    nan, Eval reward: -476.9872449886163, TD loss   :    nan, Episode   :      0\n",
      "Iteration :    100, Train reward: -101.1357097007237, Eval reward: -476.9872449886163, TD loss   : 314.96502685546875, Episode   :      1\n",
      "Iteration :    200, Train reward: -183.3455130171931, Eval reward: -476.9872449886163, TD loss   : 92.52947586059571, Episode   :      2\n",
      "Iteration :    300, Train reward: -225.31569111885298, Eval reward: -476.9872449886163, TD loss   : 83.29349723339081, Episode   :      3\n",
      "Iteration :    400, Train reward: -250.84169004542267, Eval reward: -476.9872449886163, TD loss   : 71.45591916322708, Episode   :      4\n",
      "Iteration :    500, Train reward: -226.78798856440275, Eval reward: -102.16369197698023, TD loss   : 77.66810770988464, Episode   :      5\n",
      "Iteration :    600, Train reward: -208.25397653374114, Eval reward: -102.16369197698023, TD loss   : 85.61731551885605, Episode   :      6\n",
      "Iteration :    700, Train reward: -215.00420474494584, Eval reward: -102.16369197698023, TD loss   : 93.04127799034119, Episode   :      7\n",
      "Iteration :    800, Train reward: -181.3366687858913, Eval reward: -102.16369197698023, TD loss   : 92.89846500396729, Episode   :      9\n",
      "Iteration :    900, Train reward: -181.3366687858913, Eval reward: -102.16369197698023, TD loss   : 86.61199021100998, Episode   :      9\n",
      "Iteration :   1000, Train reward: -182.27833419876043, Eval reward: -139.14386687501278, TD loss   : 95.25259689211845, Episode   :     10\n",
      "Iteration :   1100, Train reward: -188.8466479063932, Eval reward: -139.14386687501278, TD loss   : 82.96128896474838, Episode   :     11\n",
      "Iteration :   1200, Train reward: -172.8394612764907, Eval reward: -139.14386687501278, TD loss   : 71.61660469770432, Episode   :     13\n",
      "Iteration :   1300, Train reward: -181.33484481476117, Eval reward: -139.14386687501278, TD loss   : 80.80385890722275, Episode   :     14\n",
      "Iteration :   1400, Train reward: -173.97694155993756, Eval reward: -139.14386687501278, TD loss   : 60.10918405652046, Episode   :     15\n",
      "Iteration :   1500, Train reward: -173.5691316517398, Eval reward: -355.9570273630989, TD loss   : 67.0343399810791, Episode   :     16\n",
      "Iteration :   1600, Train reward: -173.23446784915853, Eval reward: -355.9570273630989, TD loss   : 71.85071236848832, Episode   :     17\n",
      "Iteration :   1700, Train reward: -169.46328899208618, Eval reward: -355.9570273630989, TD loss   : 69.9021260356903, Episode   :     18\n",
      "Iteration :   1800, Train reward: -165.52071527195872, Eval reward: -355.9570273630989, TD loss   : 81.6578815793991, Episode   :     20\n",
      "Iteration :   1900, Train reward: -177.20624139492833, Eval reward: -355.9570273630989, TD loss   : 65.16288744449615, Episode   :     21\n",
      "Iteration :   2000, Train reward: -168.67242511713, Eval reward: -398.21637289223435, TD loss   : 61.595272443294526, Episode   :     22\n",
      "Iteration :   2100, Train reward: -154.1610892517815, Eval reward: -398.21637289223435, TD loss   : 63.22750634431839, Episode   :     24\n",
      "Iteration :   2200, Train reward: -155.94020797632973, Eval reward: -398.21637289223435, TD loss   : 64.98932294130326, Episode   :     25\n",
      "Iteration :   2300, Train reward: -155.25197547546767, Eval reward: -398.21637289223435, TD loss   : 76.44324631214141, Episode   :     26\n",
      "Iteration :   2400, Train reward: -141.92355049503007, Eval reward: -398.21637289223435, TD loss   : 77.66498678922653, Episode   :     27\n",
      "Iteration :   2500, Train reward: -155.1515863237887, Eval reward: -241.6054162565947, TD loss   : 60.96065017700195, Episode   :     28\n",
      "Iteration :   2600, Train reward: -150.88690398738444, Eval reward: -241.6054162565947, TD loss   : 63.61303709864617, Episode   :     30\n",
      "Iteration :   2700, Train reward: -143.22782357096588, Eval reward: -241.6054162565947, TD loss   : 70.55721954107284, Episode   :     31\n",
      "Iteration :   2800, Train reward: -151.61675787280814, Eval reward: -241.6054162565947, TD loss   : 84.16514288425445, Episode   :     32\n",
      "Iteration :   2900, Train reward: -151.61675787280814, Eval reward: -241.6054162565947, TD loss   : 67.2859509909153, Episode   :     32\n",
      "Iteration :   3000, Train reward: -153.56030078301038, Eval reward: -189.55706576069596, TD loss   : 55.305566425323484, Episode   :     33\n",
      "Iteration :   3100, Train reward: -151.5021968539612, Eval reward: -189.55706576069596, TD loss   : 75.30164483904838, Episode   :     34\n",
      "Iteration :   3200, Train reward: -165.5104245025699, Eval reward: -189.55706576069596, TD loss   : 84.92394788742065, Episode   :     35\n",
      "Iteration :   3300, Train reward: -169.61495902332373, Eval reward: -189.55706576069596, TD loss   : 72.55699074745178, Episode   :     36\n",
      "Iteration :   3400, Train reward: -162.50013303126042, Eval reward: -189.55706576069596, TD loss   : 64.00902426242828, Episode   :     37\n",
      "Iteration :   3500, Train reward: -158.3638628273347, Eval reward: -197.21436826272273, TD loss   : 67.52593185186386, Episode   :     38\n",
      "Iteration :   3600, Train reward: -153.63466708448985, Eval reward: -197.21436826272273, TD loss   : 89.40344145536423, Episode   :     39\n",
      "Iteration :   3700, Train reward: -156.14964709549008, Eval reward: -197.21436826272273, TD loss   : 73.58779822707176, Episode   :     40\n",
      "Iteration :   3800, Train reward: -144.6027640655819, Eval reward: -197.21436826272273, TD loss   : 97.3931618475914, Episode   :     41\n",
      "Iteration :   3900, Train reward: -157.14118788491797, Eval reward: -197.21436826272273, TD loss   : 54.64528642654419, Episode   :     42\n",
      "Iteration :   4000, Train reward: -160.7393083363477, Eval reward: -258.53448128482006, TD loss   : 87.71559338450432, Episode   :     43\n",
      "Iteration :   4100, Train reward: -160.20538185707517, Eval reward: -258.53448128482006, TD loss   : 86.23715135335922, Episode   :     44\n",
      "Iteration :   4200, Train reward: -156.88534720523836, Eval reward: -258.53448128482006, TD loss   : 67.31505409955979, Episode   :     45\n",
      "Iteration :   4300, Train reward: -170.16646520462854, Eval reward: -258.53448128482006, TD loss   : 59.07122390508652, Episode   :     46\n",
      "Iteration :   4400, Train reward: -174.08380176957934, Eval reward: -258.53448128482006, TD loss   : 62.16192391633987, Episode   :     47\n",
      "Iteration :   4500, Train reward: -165.42901208246602, Eval reward: -285.6361520632539, TD loss   : 83.83154983520508, Episode   :     48\n",
      "Iteration :   4600, Train reward: -172.741527798217, Eval reward: -285.6361520632539, TD loss   : 77.43918830394745, Episode   :     49\n",
      "Iteration :   4700, Train reward: -184.86289087505472, Eval reward: -285.6361520632539, TD loss   : 77.26912590742111, Episode   :     50\n",
      "Iteration :   4800, Train reward: -183.13536116888952, Eval reward: -285.6361520632539, TD loss   : 51.765438162088394, Episode   :     51\n",
      "Iteration :   4900, Train reward: -183.13536116888952, Eval reward: -285.6361520632539, TD loss   : 58.98881796121597, Episode   :     51\n",
      "Iteration :   5000, Train reward: -173.47394874504147, Eval reward: -270.90839059925315, TD loss   : 57.35379233956337, Episode   :     52\n",
      "Iteration :   5100, Train reward: -173.55227540690097, Eval reward: -270.90839059925315, TD loss   : 77.06649048805237, Episode   :     54\n",
      "Iteration :   5200, Train reward: -163.38922029736327, Eval reward: -270.90839059925315, TD loss   : 62.323158473968505, Episode   :     55\n",
      "Iteration :   5300, Train reward: -163.38922029736327, Eval reward: -270.90839059925315, TD loss   : 60.639424002170564, Episode   :     55\n",
      "Iteration :   5400, Train reward: -150.63766080686713, Eval reward: -270.90839059925315, TD loss   : 46.833002562522886, Episode   :     56\n",
      "Iteration :   5500, Train reward: -150.6175423350159, Eval reward: -272.1594535079795, TD loss   : 70.09215118885041, Episode   :     57\n",
      "Iteration :   5600, Train reward: -156.6855185986003, Eval reward: -272.1594535079795, TD loss   : 61.703504320383075, Episode   :     58\n",
      "Iteration :   5700, Train reward: -158.1306997112477, Eval reward: -272.1594535079795, TD loss   : 52.858568589687344, Episode   :     59\n",
      "Iteration :   5800, Train reward: -157.66997410781622, Eval reward: -272.1594535079795, TD loss   : 53.96227775216103, Episode   :     60\n",
      "Iteration :   5900, Train reward: -157.66997410781622, Eval reward: -272.1594535079795, TD loss   : 60.53613379836082, Episode   :     60\n",
      "Iteration :   6000, Train reward: -157.66997410781622, Eval reward: -248.49165613257514, TD loss   : 78.36177153944969, Episode   :     60\n",
      "Iteration :   6100, Train reward: -161.06690517746844, Eval reward: -248.49165613257514, TD loss   : 59.93977601289749, Episode   :     61\n",
      "Iteration :   6200, Train reward: -148.94330982240464, Eval reward: -248.49165613257514, TD loss   : 68.77235730409622, Episode   :     63\n",
      "Iteration :   6300, Train reward: -148.94330982240464, Eval reward: -248.49165613257514, TD loss   : 51.20470817089081, Episode   :     63\n",
      "Iteration :   6400, Train reward: -143.79559154519228, Eval reward: -248.49165613257514, TD loss   : 60.397849504947665, Episode   :     64\n",
      "Iteration :   6500, Train reward: -148.67300610537964, Eval reward: -213.3222632400172, TD loss   : 56.05796921491623, Episode   :     65\n",
      "Iteration :   6600, Train reward: -135.920969952648, Eval reward: -213.3222632400172, TD loss   : 56.607143914699556, Episode   :     66\n",
      "Iteration :   6700, Train reward: -138.90082784398322, Eval reward: -213.3222632400172, TD loss   : 57.54409894585609, Episode   :     67\n",
      "Iteration :   6800, Train reward: -150.07399144172206, Eval reward: -213.3222632400172, TD loss   : 62.86615709900856, Episode   :     68\n",
      "Iteration :   6900, Train reward: -141.4478484926701, Eval reward: -213.3222632400172, TD loss   : 68.58715596914291, Episode   :     69\n",
      "Iteration :   7000, Train reward: -128.10562906347806, Eval reward: -305.81299149165136, TD loss   : 51.58502761244774, Episode   :     70\n",
      "Iteration :   7100, Train reward: -129.56961353215738, Eval reward: -305.81299149165136, TD loss   : 55.73652885913849, Episode   :     71\n",
      "Iteration :   7200, Train reward: -129.56961353215738, Eval reward: -305.81299149165136, TD loss   : 53.947705235481266, Episode   :     71\n",
      "Iteration :   7300, Train reward: -132.57851974913368, Eval reward: -305.81299149165136, TD loss   : 59.7975251853466, Episode   :     72\n",
      "Iteration :   7400, Train reward: -132.57851974913368, Eval reward: -305.81299149165136, TD loss   : 52.60988184213638, Episode   :     72\n",
      "Iteration :   7500, Train reward: -135.49891916913492, Eval reward: -294.22625898016395, TD loss   : 50.7057522892952, Episode   :     73\n",
      "Iteration :   7600, Train reward: -132.81758819812205, Eval reward: -294.22625898016395, TD loss   : 64.55510708332062, Episode   :     74\n",
      "Iteration :   7700, Train reward: -128.90881233296872, Eval reward: -294.22625898016395, TD loss   : 66.16370529651641, Episode   :     75\n",
      "Iteration :   7800, Train reward: -133.15719457510454, Eval reward: -294.22625898016395, TD loss   : 74.63148818731308, Episode   :     76\n",
      "Iteration :   7900, Train reward: -144.79369243442002, Eval reward: -294.22625898016395, TD loss   : 54.67972992539406, Episode   :     77\n",
      "Iteration :   8000, Train reward: -144.79369243442002, Eval reward: -190.7495636366558, TD loss   : 52.4431403541565, Episode   :     77\n",
      "Iteration :   8100, Train reward: -139.24542813262912, Eval reward: -190.7495636366558, TD loss   : 60.44283971786499, Episode   :     78\n",
      "Iteration :   8200, Train reward: -141.68855766635198, Eval reward: -190.7495636366558, TD loss   : 50.407562596797945, Episode   :     79\n",
      "Iteration :   8300, Train reward: -141.68855766635198, Eval reward: -190.7495636366558, TD loss   : 41.59817926049232, Episode   :     79\n",
      "Iteration :   8400, Train reward: -139.93291390525656, Eval reward: -190.7495636366558, TD loss   : 60.76887211084366, Episode   :     80\n",
      "Iteration :   8500, Train reward: -134.21358070180426, Eval reward: -153.23502880883794, TD loss   : 59.084789835214615, Episode   :     81\n",
      "Iteration :   8600, Train reward: -125.90767746411802, Eval reward: -153.23502880883794, TD loss   : 60.13301489114761, Episode   :     82\n",
      "Iteration :   8700, Train reward: -119.63139141079564, Eval reward: -153.23502880883794, TD loss   : 36.914049264192585, Episode   :     83\n",
      "Iteration :   8800, Train reward: -132.73264761587257, Eval reward: -153.23502880883794, TD loss   : 38.7908717572689, Episode   :     84\n",
      "Iteration :   8900, Train reward: -132.73264761587257, Eval reward: -153.23502880883794, TD loss   : 52.045054624080656, Episode   :     84\n",
      "Iteration :   9000, Train reward: -121.7945419339126, Eval reward: -121.7855500481932, TD loss   : 44.098759618997576, Episode   :     85\n",
      "Iteration :   9100, Train reward: -122.00281423521105, Eval reward: -121.7855500481932, TD loss   : 39.13171433568001, Episode   :     86\n",
      "Iteration :   9200, Train reward: -117.9456084268182, Eval reward: -121.7855500481932, TD loss   : 52.13034597039223, Episode   :     87\n",
      "Iteration :   9300, Train reward: -117.9456084268182, Eval reward: -121.7855500481932, TD loss   : 58.237196543216704, Episode   :     87\n",
      "Iteration :   9400, Train reward: -117.9456084268182, Eval reward: -121.7855500481932, TD loss   : 45.51821917176247, Episode   :     87\n",
      "Iteration :   9500, Train reward: -110.01656909044875, Eval reward: -135.45538740027033, TD loss   : 33.29608396530151, Episode   :     88\n",
      "Iteration :   9600, Train reward: -110.90341230864775, Eval reward: -135.45538740027033, TD loss   : 51.892126297950746, Episode   :     89\n",
      "Iteration :   9700, Train reward: -112.79731656855411, Eval reward: -135.45538740027033, TD loss   : 49.17775946617127, Episode   :     90\n",
      "Iteration :   9800, Train reward: -112.79731656855411, Eval reward: -135.45538740027033, TD loss   : 54.38370929121971, Episode   :     90\n",
      "Iteration :   9900, Train reward: -111.353497358414, Eval reward: -135.45538740027033, TD loss   : 57.995779707431794, Episode   :     91\n",
      "Iteration :  10000, Train reward: -109.76733624489184, Eval reward: -92.59296514807991, TD loss   : 37.44760323405266, Episode   :     92\n",
      "Iteration :  10100, Train reward: -106.41694075956381, Eval reward: -92.59296514807991, TD loss   : 43.726460189819335, Episode   :     93\n",
      "Iteration :  10200, Train reward: -106.06378779425943, Eval reward: -92.59296514807991, TD loss   : 57.16750268220901, Episode   :     94\n",
      "Iteration :  10300, Train reward: -109.70323143830925, Eval reward: -92.59296514807991, TD loss   : 47.09057662129402, Episode   :     95\n",
      "Iteration :  10400, Train reward: -109.70323143830925, Eval reward: -92.59296514807991, TD loss   : 37.21724024534225, Episode   :     95\n",
      "Iteration :  10500, Train reward: -109.70323143830925, Eval reward: -245.83030359350278, TD loss   : 29.193512427806855, Episode   :     95\n",
      "Iteration :  10600, Train reward: -108.4128258790565, Eval reward: -245.83030359350278, TD loss   : 43.6839938044548, Episode   :     96\n",
      "Iteration :  10700, Train reward: -104.08264483909682, Eval reward: -245.83030359350278, TD loss   : 52.74886519670486, Episode   :     97\n",
      "Iteration :  10800, Train reward: -104.08264483909682, Eval reward: -245.83030359350278, TD loss   : 54.30192948937416, Episode   :     97\n",
      "Iteration :  10900, Train reward: -104.58085157375123, Eval reward: -245.83030359350278, TD loss   : 46.908452697992324, Episode   :     98\n",
      "Iteration :  11000, Train reward: -104.58085157375123, Eval reward: -266.67978875080996, TD loss   : 45.585245515108106, Episode   :     98\n",
      "Iteration :  11100, Train reward: -100.8252536407359, Eval reward: -266.67978875080996, TD loss   : 48.68133821725846, Episode   :     99\n",
      "Iteration :  11200, Train reward: -101.31985768360656, Eval reward: -266.67978875080996, TD loss   : 59.304697993993756, Episode   :    100\n",
      "Iteration :  11300, Train reward: -101.76620775976942, Eval reward: -266.67978875080996, TD loss   : 49.605487747192385, Episode   :    101\n",
      "Iteration :  11400, Train reward: -101.76620775976942, Eval reward: -266.67978875080996, TD loss   : 33.624096726179125, Episode   :    101\n",
      "Iteration :  11500, Train reward: -102.51791855660538, Eval reward: -77.34788004025745, TD loss   : 42.200064375400544, Episode   :    102\n",
      "Iteration :  11600, Train reward: -104.08211017176798, Eval reward: -77.34788004025745, TD loss   : 43.69112954497337, Episode   :    103\n",
      "Iteration :  11700, Train reward: -104.08211017176798, Eval reward: -77.34788004025745, TD loss   : 45.16022020101547, Episode   :    103\n",
      "Iteration :  11800, Train reward: -90.91007391283881, Eval reward: -77.34788004025745, TD loss   : 47.70241154432297, Episode   :    104\n",
      "Iteration :  11900, Train reward: -90.91007391283881, Eval reward: -77.34788004025745, TD loss   : 45.36305869817734, Episode   :    104\n",
      "Iteration :  12000, Train reward: -90.91007391283881, Eval reward: -62.51358782838038, TD loss   : 44.05322076201439, Episode   :    104\n",
      "Iteration :  12100, Train reward: -93.69261344419365, Eval reward: -62.51358782838038, TD loss   : 52.01768550872803, Episode   :    105\n",
      "Iteration :  12200, Train reward: -93.69261344419365, Eval reward: -62.51358782838038, TD loss   : 43.683101451396944, Episode   :    105\n",
      "Iteration :  12300, Train reward: -93.67854761217608, Eval reward: -62.51358782838038, TD loss   : 31.95750700354576, Episode   :    106\n",
      "Iteration :  12400, Train reward: -110.8103716885432, Eval reward: -62.51358782838038, TD loss   : 51.474058884382245, Episode   :    107\n",
      "Iteration :  12500, Train reward: -110.8103716885432, Eval reward: -99.47499573421108, TD loss   : 54.7191921889782, Episode   :    107\n",
      "Iteration :  12600, Train reward: -98.5588085866809, Eval reward: -99.47499573421108, TD loss   : 41.29504005432129, Episode   :    108\n",
      "Iteration :  12700, Train reward: -98.5588085866809, Eval reward: -99.47499573421108, TD loss   : 38.850461754798886, Episode   :    108\n",
      "Iteration :  12800, Train reward: -98.5588085866809, Eval reward: -99.47499573421108, TD loss   : 40.26092755317688, Episode   :    108\n",
      "Iteration :  12900, Train reward: -93.5903096513058, Eval reward: -99.47499573421108, TD loss   : 39.45068945169449, Episode   :    109\n",
      "Iteration :  13000, Train reward: -93.5903096513058, Eval reward: -28.15560239040163, TD loss   : 43.80974644303322, Episode   :    109\n",
      "Iteration :  13100, Train reward: -84.11578895498425, Eval reward: -28.15560239040163, TD loss   : 47.95787322759628, Episode   :    110\n",
      "Iteration :  13200, Train reward: -84.11578895498425, Eval reward: -28.15560239040163, TD loss   : 53.92427137374878, Episode   :    110\n",
      "Iteration :  13300, Train reward: -84.11578895498425, Eval reward: -28.15560239040163, TD loss   : 38.59153769731522, Episode   :    110\n",
      "Iteration :  13400, Train reward: -73.4631108860905, Eval reward: -28.15560239040163, TD loss   : 52.17534642934799, Episode   :    111\n",
      "Iteration :  13500, Train reward: -73.4631108860905, Eval reward: -70.78917779715908, TD loss   : 45.25354567527771, Episode   :    111\n",
      "Iteration :  13600, Train reward: -69.38109674162556, Eval reward: -70.78917779715908, TD loss   : 41.101031593084336, Episode   :    112\n",
      "Iteration :  13700, Train reward: -69.38109674162556, Eval reward: -70.78917779715908, TD loss   : 41.88590471506119, Episode   :    112\n",
      "Iteration :  13800, Train reward: -69.38109674162556, Eval reward: -70.78917779715908, TD loss   : 45.757984466552735, Episode   :    112\n",
      "Iteration :  13900, Train reward: -62.52183900921866, Eval reward: -70.78917779715908, TD loss   : 43.13014407753944, Episode   :    113\n",
      "Iteration :  14000, Train reward: -56.17681334619233, Eval reward: 4.2919920291623725, TD loss   : 35.886728177070616, Episode   :    114\n",
      "Iteration :  14100, Train reward: -48.19369694011637, Eval reward: 4.2919920291623725, TD loss   : 43.79877799272537, Episode   :    115\n",
      "Iteration :  14200, Train reward: -48.19369694011637, Eval reward: 4.2919920291623725, TD loss   : 46.159032638072965, Episode   :    115\n",
      "Iteration :  14300, Train reward: -48.19369694011637, Eval reward: 4.2919920291623725, TD loss   : 44.742795077562334, Episode   :    115\n",
      "Iteration :  14400, Train reward: -44.6289863566807, Eval reward: 4.2919920291623725, TD loss   : 37.37385034561157, Episode   :    116\n",
      "Iteration :  14500, Train reward: -37.38441072814589, Eval reward: -121.63177776852106, TD loss   : 40.60187981128693, Episode   :    117\n",
      "Iteration :  14600, Train reward: -34.201615075234045, Eval reward: -121.63177776852106, TD loss   : 36.990687004327775, Episode   :    118\n",
      "Iteration :  14700, Train reward: -34.201615075234045, Eval reward: -121.63177776852106, TD loss   : 40.11308061003685, Episode   :    118\n",
      "Iteration :  14800, Train reward: -29.704898475264496, Eval reward: -121.63177776852106, TD loss   : 34.15154124975204, Episode   :    119\n",
      "Iteration :  14900, Train reward: -29.704898475264496, Eval reward: -121.63177776852106, TD loss   : 33.41118305325508, Episode   :    119\n",
      "Iteration :  15000, Train reward: -29.606005693329205, Eval reward: -2.9560631846000285, TD loss   : 46.47041752099991, Episode   :    120\n",
      "Iteration :  15100, Train reward: -27.831801456519862, Eval reward: -2.9560631846000285, TD loss   : 40.66361079573631, Episode   :    121\n",
      "Iteration :  15200, Train reward: -27.831801456519862, Eval reward: -2.9560631846000285, TD loss   : 35.291273580789564, Episode   :    121\n",
      "Iteration :  15300, Train reward: -28.218190127132182, Eval reward: -2.9560631846000285, TD loss   : 44.79124608516693, Episode   :    122\n",
      "Iteration :  15400, Train reward: -28.218190127132182, Eval reward: -2.9560631846000285, TD loss   : 38.60700797200203, Episode   :    122\n",
      "Iteration :  15500, Train reward: -28.218190127132182, Eval reward: 29.006006939312204, TD loss   : 33.20083377122879, Episode   :    122\n",
      "Iteration :  15600, Train reward: -20.477989090623726, Eval reward: 29.006006939312204, TD loss   : 25.013798042535782, Episode   :    123\n",
      "Iteration :  15700, Train reward: -20.477989090623726, Eval reward: 29.006006939312204, TD loss   : 37.781916773319246, Episode   :    123\n",
      "Iteration :  15800, Train reward: -17.83757858551781, Eval reward: 29.006006939312204, TD loss   : 34.58372203469276, Episode   :    124\n",
      "Iteration :  15900, Train reward: -17.83757858551781, Eval reward: 29.006006939312204, TD loss   : 27.331155912876127, Episode   :    124\n",
      "Iteration :  16000, Train reward: -17.83757858551781, Eval reward: 20.024245192666477, TD loss   : 41.563780685663225, Episode   :    124\n",
      "Iteration :  16100, Train reward: -15.56044594898275, Eval reward: 20.024245192666477, TD loss   : 36.49166565895081, Episode   :    125\n",
      "Iteration :  16200, Train reward: -15.56044594898275, Eval reward: 20.024245192666477, TD loss   : 32.989130898714066, Episode   :    125\n",
      "Iteration :  16300, Train reward: -10.139646595354154, Eval reward: 20.024245192666477, TD loss   : 37.779046832323075, Episode   :    126\n",
      "Iteration :  16400, Train reward: -10.139646595354154, Eval reward: 20.024245192666477, TD loss   : 38.88932554721832, Episode   :    126\n",
      "Iteration :  16500, Train reward: -10.139646595354154, Eval reward: 16.104337965232993, TD loss   : 32.58604561209679, Episode   :    126\n",
      "Iteration :  16600, Train reward: 11.005217629319514, Eval reward: 16.104337965232993, TD loss   : 39.067450320720674, Episode   :    127\n",
      "Iteration :  16700, Train reward: 11.005217629319514, Eval reward: 16.104337965232993, TD loss   : 35.59076624155045, Episode   :    127\n",
      "Iteration :  16800, Train reward: 11.005217629319514, Eval reward: 16.104337965232993, TD loss   : 37.26279386401176, Episode   :    127\n",
      "Iteration :  16900, Train reward: 5.501932948526502, Eval reward: 16.104337965232993, TD loss   : 48.399500471353534, Episode   :    128\n",
      "Iteration :  17000, Train reward: 5.501932948526502, Eval reward: 2.1472617102450813, TD loss   : 28.825347291231154, Episode   :    128\n",
      "Iteration :  17100, Train reward: 5.1124574547863, Eval reward: 2.1472617102450813, TD loss   : 39.42793557167053, Episode   :    129\n",
      "Iteration :  17200, Train reward: -0.21891289329780933, Eval reward: 2.1472617102450813, TD loss   : 27.55065734028816, Episode   :    130\n",
      "Iteration :  17300, Train reward: -0.21891289329780933, Eval reward: 2.1472617102450813, TD loss   : 44.478490289449695, Episode   :    130\n",
      "Iteration :  17400, Train reward: -8.635555802635306, Eval reward: 2.1472617102450813, TD loss   : 38.670649919509884, Episode   :    131\n",
      "Iteration :  17500, Train reward: -8.635555802635306, Eval reward: 30.558340247376474, TD loss   : 34.36800563812256, Episode   :    131\n",
      "Iteration :  17600, Train reward: -3.1061386682626475, Eval reward: 30.558340247376474, TD loss   : 24.664617367982864, Episode   :    132\n",
      "Iteration :  17700, Train reward: -3.1061386682626475, Eval reward: 30.558340247376474, TD loss   : 31.673699487447738, Episode   :    132\n",
      "Iteration :  17800, Train reward: -3.1061386682626475, Eval reward: 30.558340247376474, TD loss   : 32.57885637402534, Episode   :    132\n",
      "Iteration :  17900, Train reward: -5.756708499562937, Eval reward: 30.558340247376474, TD loss   : 42.368359978199, Episode   :    133\n",
      "Iteration :  18000, Train reward: -5.756708499562937, Eval reward: -99.49247630078648, TD loss   : 30.974071815013886, Episode   :    133\n",
      "Iteration :  18100, Train reward: -7.719040584362342, Eval reward: -99.49247630078648, TD loss   : 29.26470532298088, Episode   :    134\n",
      "Iteration :  18200, Train reward: -7.719040584362342, Eval reward: -99.49247630078648, TD loss   : 40.08366421937942, Episode   :    134\n",
      "Iteration :  18300, Train reward: -7.719040584362342, Eval reward: -99.49247630078648, TD loss   : 37.10340867638588, Episode   :    134\n",
      "Iteration :  18400, Train reward: -4.38452153691695, Eval reward: -99.49247630078648, TD loss   : 28.696957523822785, Episode   :    135\n",
      "Iteration :  18500, Train reward: -4.38452153691695, Eval reward: -127.62308026482995, TD loss   : 27.782847502231597, Episode   :    135\n",
      "Iteration :  18600, Train reward: -10.984949210681659, Eval reward: -127.62308026482995, TD loss   : 24.8949813079834, Episode   :    136\n",
      "Iteration :  18700, Train reward: -10.984949210681659, Eval reward: -127.62308026482995, TD loss   : 28.80400182723999, Episode   :    136\n",
      "Iteration :  18800, Train reward: -7.708075104402174, Eval reward: -127.62308026482995, TD loss   : 32.82081885457039, Episode   :    137\n",
      "Iteration :  18900, Train reward: -7.708075104402174, Eval reward: -127.62308026482995, TD loss   : 28.49540251851082, Episode   :    137\n",
      "Iteration :  19000, Train reward: -7.708075104402174, Eval reward: 38.77531885318017, TD loss   : 21.52961579680443, Episode   :    137\n",
      "Iteration :  19100, Train reward: -3.0788671977971283, Eval reward: 38.77531885318017, TD loss   : 32.46743437170982, Episode   :    138\n",
      "Iteration :  19200, Train reward: -3.0788671977971283, Eval reward: 38.77531885318017, TD loss   : 31.829571897983552, Episode   :    138\n",
      "Iteration :  19300, Train reward: -3.0788671977971283, Eval reward: 38.77531885318017, TD loss   : 34.35632618427277, Episode   :    138\n",
      "Iteration :  19400, Train reward: 5.322761883514908, Eval reward: 38.77531885318017, TD loss   : 39.164655307531355, Episode   :    139\n",
      "Iteration :  19500, Train reward: 5.322761883514908, Eval reward: -21.4074326252441, TD loss   : 43.379029244184494, Episode   :    139\n",
      "Iteration :  19600, Train reward: 9.224525584127127, Eval reward: -21.4074326252441, TD loss   : 45.04116777062416, Episode   :    140\n",
      "Iteration :  19700, Train reward: 9.224525584127127, Eval reward: -21.4074326252441, TD loss   : 30.639528763890265, Episode   :    140\n",
      "Iteration :  19800, Train reward: 9.224525584127127, Eval reward: -21.4074326252441, TD loss   : 36.91240184307098, Episode   :    140\n",
      "Iteration :  19900, Train reward: 15.454737039907409, Eval reward: -21.4074326252441, TD loss   : 31.394098185300827, Episode   :    141\n",
      "Iteration :  20000, Train reward: 15.454737039907409, Eval reward: -61.75555514180047, TD loss   : 27.530760335922242, Episode   :    141\n",
      "Iteration :  20100, Train reward: 17.77241521453781, Eval reward: -61.75555514180047, TD loss   : 44.9283273267746, Episode   :    142\n",
      "Iteration :  20200, Train reward: 17.77241521453781, Eval reward: -61.75555514180047, TD loss   : 42.08651131033898, Episode   :    142\n",
      "Iteration :  20300, Train reward: 4.230325579183571, Eval reward: -61.75555514180047, TD loss   : 29.379488945007324, Episode   :    143\n",
      "Iteration :  20400, Train reward: 4.230325579183571, Eval reward: -61.75555514180047, TD loss   : 44.429477659463885, Episode   :    143\n",
      "Iteration :  20500, Train reward: 4.230325579183571, Eval reward: 23.221718646903287, TD loss   : 26.109655088186265, Episode   :    143\n",
      "Iteration :  20600, Train reward: 7.563057704067697, Eval reward: 23.221718646903287, TD loss   : 34.65874295592308, Episode   :    144\n",
      "Iteration :  20700, Train reward: 7.563057704067697, Eval reward: 23.221718646903287, TD loss   : 34.53181283593178, Episode   :    144\n",
      "Iteration :  20800, Train reward: 7.563057704067697, Eval reward: 23.221718646903287, TD loss   : 28.15501641869545, Episode   :    144\n",
      "Iteration :  20900, Train reward: 9.747988597742454, Eval reward: 23.221718646903287, TD loss   : 37.1275729739666, Episode   :    145\n",
      "Iteration :  21000, Train reward: 9.747988597742454, Eval reward: 32.316827392429545, TD loss   : 23.666670442819594, Episode   :    145\n",
      "Iteration :  21100, Train reward: 10.971915477252507, Eval reward: 32.316827392429545, TD loss   : 31.099155290126802, Episode   :    146\n",
      "Iteration :  21200, Train reward: 10.971915477252507, Eval reward: 32.316827392429545, TD loss   : 35.64796403050423, Episode   :    146\n",
      "Iteration :  21300, Train reward: 10.971915477252507, Eval reward: 32.316827392429545, TD loss   : 30.31978875160217, Episode   :    146\n",
      "Iteration :  21400, Train reward: 11.741981295008111, Eval reward: 32.316827392429545, TD loss   : 35.4000991153717, Episode   :    147\n",
      "Iteration :  21500, Train reward: 11.741981295008111, Eval reward: 47.918680471128525, TD loss   : 28.962684729099273, Episode   :    147\n",
      "Iteration :  21600, Train reward: 10.450952050207096, Eval reward: 47.918680471128525, TD loss   : 23.49422553062439, Episode   :    148\n",
      "Iteration :  21700, Train reward: 10.450952050207096, Eval reward: 47.918680471128525, TD loss   : 20.880576498508454, Episode   :    148\n",
      "Iteration :  21800, Train reward: 10.450952050207096, Eval reward: 47.918680471128525, TD loss   : 28.95287211060524, Episode   :    148\n",
      "Iteration :  21900, Train reward: 16.45955976226505, Eval reward: 47.918680471128525, TD loss   : 24.934816101789476, Episode   :    149\n",
      "Iteration :  22000, Train reward: 19.55309513276626, Eval reward: -21.95814889336574, TD loss   : 29.20844872832298, Episode   :    150\n",
      "Iteration :  22100, Train reward: 21.073857026532135, Eval reward: -21.95814889336574, TD loss   : 27.506861442327498, Episode   :    151\n",
      "Iteration :  22200, Train reward: 21.073857026532135, Eval reward: -21.95814889336574, TD loss   : 34.7643041563034, Episode   :    151\n",
      "Iteration :  22300, Train reward: 21.073857026532135, Eval reward: -21.95814889336574, TD loss   : 24.970874503850936, Episode   :    151\n",
      "Iteration :  22400, Train reward: 18.904146563997873, Eval reward: -21.95814889336574, TD loss   : 21.383546674251555, Episode   :    152\n",
      "Iteration :  22500, Train reward: 18.37908879868534, Eval reward: -59.24690811217455, TD loss   : 29.54023872256279, Episode   :    153\n",
      "Iteration :  22600, Train reward: 17.810723958344433, Eval reward: -59.24690811217455, TD loss   : 30.268201540708542, Episode   :    154\n",
      "Iteration :  22700, Train reward: 17.810723958344433, Eval reward: -59.24690811217455, TD loss   : 27.592896052598952, Episode   :    154\n",
      "Iteration :  22800, Train reward: 17.810723958344433, Eval reward: -59.24690811217455, TD loss   : 24.4678130197525, Episode   :    154\n",
      "Iteration :  22900, Train reward: 14.538019758631426, Eval reward: -59.24690811217455, TD loss   : 24.492922921180725, Episode   :    155\n",
      "Iteration :  23000, Train reward: 14.538019758631426, Eval reward: 20.063948454720666, TD loss   : 22.30786422252655, Episode   :    155\n",
      "Iteration :  23100, Train reward: 19.95402913756534, Eval reward: 20.063948454720666, TD loss   : 14.04203142285347, Episode   :    156\n",
      "Iteration :  23200, Train reward: 19.95402913756534, Eval reward: 20.063948454720666, TD loss   : 21.91241548061371, Episode   :    156\n",
      "Iteration :  23300, Train reward: 19.95402913756534, Eval reward: 20.063948454720666, TD loss   : 23.974691413640976, Episode   :    156\n",
      "Iteration :  23400, Train reward: 20.942522287581458, Eval reward: 20.063948454720666, TD loss   : 29.896316608190535, Episode   :    157\n",
      "Iteration :  23500, Train reward: 20.942522287581458, Eval reward: 24.537080798744963, TD loss   : 36.941644295454026, Episode   :    157\n",
      "Iteration :  23600, Train reward: 19.117663431977665, Eval reward: 24.537080798744963, TD loss   : 33.57633848309517, Episode   :    158\n",
      "Iteration :  23700, Train reward: 19.117663431977665, Eval reward: 24.537080798744963, TD loss   : 29.162316262722015, Episode   :    158\n",
      "Iteration :  23800, Train reward: 19.117663431977665, Eval reward: 24.537080798744963, TD loss   : 19.2100211584568, Episode   :    158\n",
      "Iteration :  23900, Train reward: 13.44164234512887, Eval reward: 24.537080798744963, TD loss   : 22.253782424926758, Episode   :    159\n",
      "Iteration :  24000, Train reward: 13.44164234512887, Eval reward: 36.243448351805355, TD loss   : 37.61413317799568, Episode   :    159\n",
      "Iteration :  24100, Train reward: 15.208688077358236, Eval reward: 36.243448351805355, TD loss   : 33.487483953237536, Episode   :    160\n",
      "Iteration :  24200, Train reward: 15.208688077358236, Eval reward: 36.243448351805355, TD loss   : 30.66493774533272, Episode   :    160\n",
      "Iteration :  24300, Train reward: 15.208688077358236, Eval reward: 36.243448351805355, TD loss   : 22.60314426481724, Episode   :    160\n",
      "Iteration :  24400, Train reward: 13.839333989032758, Eval reward: 36.243448351805355, TD loss   : 31.90566144824028, Episode   :    161\n",
      "Iteration :  24500, Train reward: 11.600041233988785, Eval reward: 10.869872710606703, TD loss   : 32.30508064389229, Episode   :    162\n",
      "Iteration :  24600, Train reward: 23.603484093690835, Eval reward: 10.869872710606703, TD loss   : 24.4642713534832, Episode   :    163\n",
      "Iteration :  24700, Train reward: 23.603484093690835, Eval reward: 10.869872710606703, TD loss   : 36.1692790222168, Episode   :    163\n",
      "Iteration :  24800, Train reward: 23.603484093690835, Eval reward: 10.869872710606703, TD loss   : 25.871671075820924, Episode   :    163\n",
      "Iteration :  24900, Train reward: 20.797596451182894, Eval reward: 10.869872710606703, TD loss   : 40.275061638355254, Episode   :    164\n",
      "Iteration :  25000, Train reward: 20.797596451182894, Eval reward: 28.818965812141773, TD loss   : 41.779000923633575, Episode   :    164\n",
      "Iteration :  25100, Train reward: 16.827997759830005, Eval reward: 28.818965812141773, TD loss   : 34.25089670777321, Episode   :    165\n",
      "Iteration :  25200, Train reward: 16.827997759830005, Eval reward: 28.818965812141773, TD loss   : 30.034354256391524, Episode   :    165\n",
      "Iteration :  25300, Train reward: 16.827997759830005, Eval reward: 28.818965812141773, TD loss   : 30.340553345680238, Episode   :    165\n",
      "Iteration :  25400, Train reward: 22.38643828751889, Eval reward: 28.818965812141773, TD loss   : 20.65829458475113, Episode   :    166\n",
      "Iteration :  25500, Train reward: 22.38643828751889, Eval reward: 35.88627504870861, TD loss   : 30.224781965017318, Episode   :    166\n",
      "Iteration :  25600, Train reward: 26.683785354095903, Eval reward: 35.88627504870861, TD loss   : 34.93093090653419, Episode   :    168\n",
      "Iteration :  25700, Train reward: 26.683785354095903, Eval reward: 35.88627504870861, TD loss   : 24.400253659486772, Episode   :    168\n",
      "Iteration :  25800, Train reward: 26.683785354095903, Eval reward: 35.88627504870861, TD loss   : 22.549698730707167, Episode   :    168\n",
      "Iteration :  25900, Train reward: 28.784348998563058, Eval reward: 35.88627504870861, TD loss   : 37.71213758945465, Episode   :    169\n",
      "Iteration :  26000, Train reward: 28.784348998563058, Eval reward: 37.46418906703567, TD loss   : 22.436263738870622, Episode   :    169\n",
      "Iteration :  26100, Train reward: 28.67756658846161, Eval reward: 37.46418906703567, TD loss   : 24.477177946567537, Episode   :    170\n",
      "Iteration :  26200, Train reward: 28.67756658846161, Eval reward: 37.46418906703567, TD loss   : 27.859513028860093, Episode   :    170\n",
      "Iteration :  26300, Train reward: 28.67756658846161, Eval reward: 37.46418906703567, TD loss   : 31.622503881454467, Episode   :    170\n",
      "Iteration :  26400, Train reward: 30.252172255782522, Eval reward: 37.46418906703567, TD loss   : 24.13256041288376, Episode   :    171\n",
      "Iteration :  26500, Train reward: 30.29546070339511, Eval reward: 79.18581081350877, TD loss   : 20.432394943237306, Episode   :    172\n",
      "Iteration :  26600, Train reward: 33.463546050449075, Eval reward: 79.18581081350877, TD loss   : 17.222454607486725, Episode   :    173\n",
      "Iteration :  26700, Train reward: 33.463546050449075, Eval reward: 79.18581081350877, TD loss   : 38.95867401838303, Episode   :    173\n",
      "Iteration :  26800, Train reward: 33.463546050449075, Eval reward: 79.18581081350877, TD loss   : 28.327303852438927, Episode   :    173\n",
      "Iteration :  26900, Train reward: 39.15876558927807, Eval reward: 79.18581081350877, TD loss   : 24.983403387069703, Episode   :    174\n",
      "Iteration :  27000, Train reward: 39.15876558927807, Eval reward: 7.509620883855584, TD loss   : 27.26441009044647, Episode   :    174\n",
      "Iteration :  27100, Train reward: 37.013040697269226, Eval reward: 7.509620883855584, TD loss   : 34.49841534137726, Episode   :    175\n",
      "Iteration :  27200, Train reward: 37.013040697269226, Eval reward: 7.509620883855584, TD loss   : 30.387661768198015, Episode   :    175\n",
      "Iteration :  27300, Train reward: 37.013040697269226, Eval reward: 7.509620883855584, TD loss   : 24.394471068382263, Episode   :    175\n",
      "Iteration :  27400, Train reward: 39.087410104795026, Eval reward: 7.509620883855584, TD loss   : 24.834726538658142, Episode   :    176\n",
      "Iteration :  27500, Train reward: 39.087410104795026, Eval reward: 54.637117738029794, TD loss   : 30.913059254288672, Episode   :    176\n",
      "Iteration :  27600, Train reward: 37.92141446746525, Eval reward: 54.637117738029794, TD loss   : 26.62494699001312, Episode   :    177\n",
      "Iteration :  27700, Train reward: 37.92141446746525, Eval reward: 54.637117738029794, TD loss   : 33.715947779417036, Episode   :    177\n",
      "Iteration :  27800, Train reward: 37.92141446746525, Eval reward: 54.637117738029794, TD loss   : 29.23507519721985, Episode   :    177\n",
      "Iteration :  27900, Train reward: 27.95474688230139, Eval reward: 54.637117738029794, TD loss   : 45.43468843579292, Episode   :    178\n",
      "Iteration :  28000, Train reward: 27.95474688230139, Eval reward: -59.134599473978234, TD loss   : 23.428537678718566, Episode   :    178\n",
      "Iteration :  28100, Train reward: 20.04213294191495, Eval reward: -59.134599473978234, TD loss   : 30.38586796760559, Episode   :    179\n",
      "Iteration :  28200, Train reward: 20.04213294191495, Eval reward: -59.134599473978234, TD loss   : 22.04513637304306, Episode   :    179\n",
      "Iteration :  28300, Train reward: 9.29773918530291, Eval reward: -59.134599473978234, TD loss   : 28.41573205471039, Episode   :    180\n",
      "Iteration :  28400, Train reward: 9.29773918530291, Eval reward: -59.134599473978234, TD loss   : 23.83663926959038, Episode   :    180\n",
      "Iteration :  28500, Train reward: 9.29773918530291, Eval reward: 52.65417515278049, TD loss   : 20.796183836460113, Episode   :    180\n",
      "Iteration :  28600, Train reward: 11.340484655811384, Eval reward: 52.65417515278049, TD loss   : 27.31659996151924, Episode   :    181\n",
      "Iteration :  28700, Train reward: 11.340484655811384, Eval reward: 52.65417515278049, TD loss   : 27.562158815860748, Episode   :    181\n",
      "Iteration :  28800, Train reward: 11.340484655811384, Eval reward: 52.65417515278049, TD loss   : 32.31139032125473, Episode   :    181\n",
      "Iteration :  28900, Train reward: 5.999582532879741, Eval reward: 52.65417515278049, TD loss   : 20.140432324409485, Episode   :    182\n",
      "Iteration :  29000, Train reward: 5.999582532879741, Eval reward: 25.544311958450233, TD loss   : 48.524896515607836, Episode   :    182\n",
      "Iteration :  29100, Train reward: 7.871226684823048, Eval reward: 25.544311958450233, TD loss   : 27.320223039388658, Episode   :    183\n",
      "Iteration :  29200, Train reward: 7.871226684823048, Eval reward: 25.544311958450233, TD loss   : 29.326828330755234, Episode   :    183\n",
      "Iteration :  29300, Train reward: 7.871226684823048, Eval reward: 25.544311958450233, TD loss   : 29.320036675930023, Episode   :    183\n",
      "Iteration :  29400, Train reward: 9.836988557681446, Eval reward: 25.544311958450233, TD loss   : 21.97833583295345, Episode   :    184\n",
      "Iteration :  29500, Train reward: 9.836988557681446, Eval reward: 26.161414918644276, TD loss   : 27.616821786165236, Episode   :    184\n",
      "Iteration :  29600, Train reward: 13.136364609703142, Eval reward: 26.161414918644276, TD loss   : 31.45094664812088, Episode   :    185\n",
      "Iteration :  29700, Train reward: 13.136364609703142, Eval reward: 26.161414918644276, TD loss   : 30.312413851022722, Episode   :    185\n",
      "Iteration :  29800, Train reward: 13.136364609703142, Eval reward: 26.161414918644276, TD loss   : 24.296605466008188, Episode   :    185\n",
      "Iteration :  29900, Train reward: 6.900181539839091, Eval reward: 26.161414918644276, TD loss   : 31.873606972694397, Episode   :    186\n",
      "Iteration :  30000, Train reward: 6.900181539839091, Eval reward: 19.173427496540533, TD loss   : 23.092688286304472, Episode   :    186\n",
      "Iteration :  30100, Train reward: 9.129445122434976, Eval reward: 19.173427496540533, TD loss   : 27.26291424155235, Episode   :    187\n",
      "Iteration :  30200, Train reward: 9.129445122434976, Eval reward: 19.173427496540533, TD loss   : 22.638587168455125, Episode   :    187\n",
      "Iteration :  30300, Train reward: 9.129445122434976, Eval reward: 19.173427496540533, TD loss   : 26.614455655813217, Episode   :    187\n",
      "Iteration :  30400, Train reward: 10.63385802297837, Eval reward: 19.173427496540533, TD loss   : 23.04794899940491, Episode   :    188\n",
      "Iteration :  30500, Train reward: 10.63385802297837, Eval reward: 32.968835836634696, TD loss   : 23.145590118169785, Episode   :    188\n",
      "Iteration :  30600, Train reward: 4.615159160211822, Eval reward: 32.968835836634696, TD loss   : 19.98262251138687, Episode   :    189\n",
      "Iteration :  30700, Train reward: 4.615159160211822, Eval reward: 32.968835836634696, TD loss   : 29.892186367511748, Episode   :    189\n",
      "Iteration :  30800, Train reward: 4.615159160211822, Eval reward: 32.968835836634696, TD loss   : 21.35148313522339, Episode   :    189\n",
      "Iteration :  30900, Train reward: 4.921564798596955, Eval reward: 32.968835836634696, TD loss   : 26.351075986623766, Episode   :    190\n",
      "Iteration :  31000, Train reward: 4.921564798596955, Eval reward: 16.89320440132554, TD loss   : 44.36598384141922, Episode   :    190\n",
      "Iteration :  31100, Train reward: 7.508375962783444, Eval reward: 16.89320440132554, TD loss   : 28.07279568314552, Episode   :    191\n",
      "Iteration :  31200, Train reward: 4.365215658226578, Eval reward: 16.89320440132554, TD loss   : 27.15922012805939, Episode   :    192\n",
      "Iteration :  31300, Train reward: 4.365215658226578, Eval reward: 16.89320440132554, TD loss   : 23.782433871030808, Episode   :    192\n",
      "Iteration :  31400, Train reward: 4.365215658226578, Eval reward: 16.89320440132554, TD loss   : 25.019991124868394, Episode   :    192\n",
      "Iteration :  31500, Train reward: 0.708034949407514, Eval reward: -91.39087109742424, TD loss   : 20.823066610097886, Episode   :    193\n",
      "Iteration :  31600, Train reward: -0.8930673106656719, Eval reward: -91.39087109742424, TD loss   : 26.432887328863146, Episode   :    194\n",
      "Iteration :  31700, Train reward: -0.8930673106656719, Eval reward: -91.39087109742424, TD loss   : 25.556898146867752, Episode   :    194\n",
      "Iteration :  31800, Train reward: -0.8930673106656719, Eval reward: -91.39087109742424, TD loss   : 15.52255061507225, Episode   :    194\n",
      "Iteration :  31900, Train reward: 7.8173616852667065, Eval reward: -91.39087109742424, TD loss   : 28.8858132815361, Episode   :    195\n",
      "Iteration :  32000, Train reward: 7.003132126026117, Eval reward: 5.454598661876816, TD loss   : 27.697460689544677, Episode   :    196\n",
      "Iteration :  32100, Train reward: 8.966907188882107, Eval reward: 5.454598661876816, TD loss   : 33.894090546369554, Episode   :    197\n",
      "Iteration :  32200, Train reward: 8.966907188882107, Eval reward: 5.454598661876816, TD loss   : 25.653644338846206, Episode   :    197\n",
      "Iteration :  32300, Train reward: 8.966907188882107, Eval reward: 5.454598661876816, TD loss   : 22.451662834882736, Episode   :    197\n",
      "Iteration :  32400, Train reward: 13.165613249999387, Eval reward: 5.454598661876816, TD loss   : 34.09743225097656, Episode   :    198\n",
      "Iteration :  32500, Train reward: 19.64298047188271, Eval reward: 25.62785168662259, TD loss   : 22.88179927945137, Episode   :    199\n",
      "Iteration :  32600, Train reward: 30.516408942585777, Eval reward: 25.62785168662259, TD loss   : 22.49711354136467, Episode   :    200\n",
      "Iteration :  32700, Train reward: 30.516408942585777, Eval reward: 25.62785168662259, TD loss   : 36.320474548339845, Episode   :    200\n",
      "Iteration :  32800, Train reward: 30.516408942585777, Eval reward: 25.62785168662259, TD loss   : 33.39013345003128, Episode   :    200\n",
      "Iteration :  32900, Train reward: 25.93482984953941, Eval reward: 25.62785168662259, TD loss   : 35.227659435272216, Episode   :    201\n",
      "Iteration :  33000, Train reward: 25.93482984953941, Eval reward: 18.793598157294333, TD loss   : 21.648985109329224, Episode   :    201\n",
      "Iteration :  33100, Train reward: 31.90108388841091, Eval reward: 18.793598157294333, TD loss   : 31.6680908370018, Episode   :    202\n",
      "Iteration :  33200, Train reward: 31.90108388841091, Eval reward: 18.793598157294333, TD loss   : 24.673567888736724, Episode   :    202\n",
      "Iteration :  33300, Train reward: 27.315372179054215, Eval reward: 18.793598157294333, TD loss   : 22.330032156705855, Episode   :    203\n",
      "Iteration :  33400, Train reward: 27.315372179054215, Eval reward: 18.793598157294333, TD loss   : 28.286521161794663, Episode   :    203\n",
      "Iteration :  33500, Train reward: 19.933840179172197, Eval reward: -30.434788474858955, TD loss   : 33.1787876701355, Episode   :    204\n",
      "Iteration :  33600, Train reward: 18.923914905693596, Eval reward: -30.434788474858955, TD loss   : 25.362431738376618, Episode   :    205\n",
      "Iteration :  33700, Train reward: 11.919738581790602, Eval reward: -30.434788474858955, TD loss   : 22.417485011816026, Episode   :    206\n",
      "Iteration :  33800, Train reward: 6.230231165698236, Eval reward: -30.434788474858955, TD loss   : 24.01910010099411, Episode   :    207\n",
      "Iteration :  33900, Train reward: 6.230231165698236, Eval reward: -30.434788474858955, TD loss   : 17.398762041330336, Episode   :    207\n",
      "Iteration :  34000, Train reward: 6.230231165698236, Eval reward: -74.12827214270388, TD loss   : 28.567975646257402, Episode   :    207\n",
      "Iteration :  34100, Train reward: 9.285377090433318, Eval reward: -74.12827214270388, TD loss   : 25.671913430690765, Episode   :    208\n",
      "Iteration :  34200, Train reward: 9.285377090433318, Eval reward: -74.12827214270388, TD loss   : 26.574741641283037, Episode   :    208\n",
      "Iteration :  34300, Train reward: 9.285377090433318, Eval reward: -74.12827214270388, TD loss   : 32.58274047136307, Episode   :    208\n",
      "Iteration :  34400, Train reward: 10.073616274215093, Eval reward: -74.12827214270388, TD loss   : 30.377421041727064, Episode   :    209\n",
      "Iteration :  34500, Train reward: 7.615256068726749, Eval reward: -81.81921085678384, TD loss   : 23.630814793109895, Episode   :    210\n",
      "Iteration :  34600, Train reward: -2.3551612306534793, Eval reward: -81.81921085678384, TD loss   : 34.993367636203764, Episode   :    211\n",
      "Iteration :  34700, Train reward: -2.3551612306534793, Eval reward: -81.81921085678384, TD loss   : 26.36723077058792, Episode   :    211\n",
      "Iteration :  34800, Train reward: -2.3551612306534793, Eval reward: -81.81921085678384, TD loss   : 34.85320217728615, Episode   :    211\n",
      "Iteration :  34900, Train reward: -0.8295267436330238, Eval reward: -81.81921085678384, TD loss   : 25.205684690475465, Episode   :    212\n",
      "Iteration :  35000, Train reward: -0.8295267436330238, Eval reward: -53.99157110712191, TD loss   : 25.618823825120927, Episode   :    212\n",
      "Iteration :  35100, Train reward: -0.8142367831340749, Eval reward: -53.99157110712191, TD loss   : 27.72895563721657, Episode   :    213\n",
      "Iteration :  35200, Train reward: -0.8142367831340749, Eval reward: -53.99157110712191, TD loss   : 22.74298889040947, Episode   :    213\n",
      "Iteration :  35300, Train reward: -0.8142367831340749, Eval reward: -53.99157110712191, TD loss   : 36.26428899347782, Episode   :    213\n",
      "Iteration :  35400, Train reward: 0.6668778677238961, Eval reward: -53.99157110712191, TD loss   : 25.38378514647484, Episode   :    214\n",
      "Iteration :  35500, Train reward: 0.6668778677238961, Eval reward: 53.90634428801242, TD loss   : 21.401502861976624, Episode   :    214\n",
      "Iteration :  35600, Train reward: -5.147360376434223, Eval reward: 53.90634428801242, TD loss   : 24.14553106188774, Episode   :    215\n",
      "Iteration :  35700, Train reward: -5.147360376434223, Eval reward: 53.90634428801242, TD loss   : 23.359176760911943, Episode   :    215\n",
      "Iteration :  35800, Train reward: -13.495151482162163, Eval reward: 53.90634428801242, TD loss   : 17.21671100437641, Episode   :    216\n",
      "Iteration :  35900, Train reward: -13.495151482162163, Eval reward: 53.90634428801242, TD loss   : 18.501643629074096, Episode   :    216\n",
      "Iteration :  36000, Train reward: -13.495151482162163, Eval reward: -106.84621214886779, TD loss   : 34.20649370789528, Episode   :    216\n",
      "Iteration :  36100, Train reward: -13.391444169527034, Eval reward: -106.84621214886779, TD loss   : 30.297167117595674, Episode   :    217\n",
      "Iteration :  36200, Train reward: -13.391444169527034, Eval reward: -106.84621214886779, TD loss   : 19.661344050168992, Episode   :    217\n",
      "Iteration :  36300, Train reward: -13.391444169527034, Eval reward: -106.84621214886779, TD loss   : 24.570840426683425, Episode   :    217\n",
      "Iteration :  36400, Train reward: -9.970193142818307, Eval reward: -106.84621214886779, TD loss   : 37.7426245367527, Episode   :    218\n",
      "Iteration :  36500, Train reward: -9.970193142818307, Eval reward: -68.54498731664435, TD loss   : 31.648470841646194, Episode   :    218\n",
      "Iteration :  36600, Train reward: -12.693742219408042, Eval reward: -68.54498731664435, TD loss   : 26.175095418691637, Episode   :    219\n",
      "Iteration :  36700, Train reward: -12.693742219408042, Eval reward: -68.54498731664435, TD loss   : 23.120663019418718, Episode   :    219\n",
      "Iteration :  36800, Train reward: -12.693742219408042, Eval reward: -68.54498731664435, TD loss   : 25.763282145261766, Episode   :    219\n",
      "Iteration :  36900, Train reward: -11.7698979964449, Eval reward: -68.54498731664435, TD loss   : 20.8444646024704, Episode   :    220\n",
      "Iteration :  37000, Train reward: -10.12061415257667, Eval reward: -1.182750961895516, TD loss   : 30.401782404184342, Episode   :    221\n",
      "Iteration :  37100, Train reward: -10.28935764018504, Eval reward: -1.182750961895516, TD loss   : 33.60149320781231, Episode   :    222\n",
      "Iteration :  37200, Train reward: -10.28935764018504, Eval reward: -1.182750961895516, TD loss   : 25.023976442813872, Episode   :    222\n",
      "Iteration :  37300, Train reward: -10.28935764018504, Eval reward: -1.182750961895516, TD loss   : 43.50432063937187, Episode   :    222\n",
      "Iteration :  37400, Train reward: -3.60967752979343, Eval reward: -1.182750961895516, TD loss   : 24.205688773393632, Episode   :    224\n",
      "Iteration :  37500, Train reward: -3.60967752979343, Eval reward: 10.477438135216548, TD loss   : 28.998961403369904, Episode   :    224\n",
      "Iteration :  37600, Train reward: -0.6512472018046381, Eval reward: 10.477438135216548, TD loss   : 31.486547409296037, Episode   :    225\n",
      "Iteration :  37700, Train reward: -0.6512472018046381, Eval reward: 10.477438135216548, TD loss   : 24.042314101457595, Episode   :    225\n",
      "Iteration :  37800, Train reward: -0.6512472018046381, Eval reward: 10.477438135216548, TD loss   : 25.624385823011398, Episode   :    225\n",
      "Iteration :  37900, Train reward: 5.101778654558165, Eval reward: 10.477438135216548, TD loss   : 29.450799299478533, Episode   :    226\n",
      "Iteration :  38000, Train reward: 4.195041687236359, Eval reward: -64.2718277083493, TD loss   : 33.23829098463059, Episode   :    227\n",
      "Iteration :  38100, Train reward: -5.788811465470164, Eval reward: -64.2718277083493, TD loss   : 29.606474189758302, Episode   :    228\n",
      "Iteration :  38200, Train reward: -5.788811465470164, Eval reward: -64.2718277083493, TD loss   : 16.852797132730483, Episode   :    228\n",
      "Iteration :  38300, Train reward: -10.329615544151771, Eval reward: -64.2718277083493, TD loss   : 37.9746620285511, Episode   :    229\n",
      "Iteration :  38400, Train reward: -10.329615544151771, Eval reward: -64.2718277083493, TD loss   : 19.58569951415062, Episode   :    229\n",
      "Iteration :  38500, Train reward: -11.595999065966675, Eval reward: -2.4818316060615158, TD loss   : 22.1444317650795, Episode   :    230\n",
      "Iteration :  38600, Train reward: -5.387638559150255, Eval reward: -2.4818316060615158, TD loss   : 27.391670697927474, Episode   :    231\n",
      "Iteration :  38700, Train reward: -5.387638559150255, Eval reward: -2.4818316060615158, TD loss   : 32.178274540901185, Episode   :    231\n",
      "Iteration :  38800, Train reward: -5.387638559150255, Eval reward: -2.4818316060615158, TD loss   : 18.84633629322052, Episode   :    231\n",
      "Iteration :  38900, Train reward: -11.30075130363746, Eval reward: -2.4818316060615158, TD loss   : 27.451393873691558, Episode   :    232\n",
      "Iteration :  39000, Train reward: -9.702582557822243, Eval reward: 36.4336097036056, TD loss   : 33.956169234514235, Episode   :    233\n",
      "Iteration :  39100, Train reward: -10.70855536512656, Eval reward: 36.4336097036056, TD loss   : 35.92288757920265, Episode   :    234\n",
      "Iteration :  39200, Train reward: -10.70855536512656, Eval reward: 36.4336097036056, TD loss   : 22.048270683288575, Episode   :    234\n",
      "Iteration :  39300, Train reward: -12.006321791200659, Eval reward: 36.4336097036056, TD loss   : 28.942383918762207, Episode   :    235\n",
      "Iteration :  39400, Train reward: -12.006321791200659, Eval reward: 36.4336097036056, TD loss   : 21.89041053414345, Episode   :    235\n",
      "Iteration :  39500, Train reward: -12.006321791200659, Eval reward: 49.95910126280528, TD loss   : 20.185203119516373, Episode   :    235\n",
      "Iteration :  39600, Train reward: -7.818806842809264, Eval reward: 49.95910126280528, TD loss   : 13.819549299478531, Episode   :    236\n",
      "Iteration :  39700, Train reward: -7.818806842809264, Eval reward: 49.95910126280528, TD loss   : 33.64280420422554, Episode   :    236\n",
      "Iteration :  39800, Train reward: -7.818806842809264, Eval reward: 49.95910126280528, TD loss   : 20.31228272676468, Episode   :    236\n",
      "Iteration :  39900, Train reward: -5.44468378096869, Eval reward: 49.95910126280528, TD loss   : 29.330715390443803, Episode   :    237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HasanErdin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\HasanErdin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :      0, Train reward:    nan, Eval reward: -607.8032632244791, TD loss   :    nan, Episode   :      0\n",
      "Iteration :    100, Train reward: -140.2682454049526, Eval reward: -607.8032632244791, TD loss   : 2.2990565299987793, Episode   :      2\n",
      "Iteration :    200, Train reward: -239.10829488241882, Eval reward: -607.8032632244791, TD loss   : 144.1342082428932, Episode   :      3\n",
      "Iteration :    300, Train reward: -224.56102676055252, Eval reward: -607.8032632244791, TD loss   : 136.33198642253876, Episode   :      4\n",
      "Iteration :    400, Train reward: -236.0439316113082, Eval reward: -607.8032632244791, TD loss   : 112.7301567697525, Episode   :      5\n",
      "Iteration :    500, Train reward: -234.46445804416126, Eval reward: -517.4442887769052, TD loss   : 97.79673667669296, Episode   :      6\n",
      "Iteration :    600, Train reward: -217.70686372174472, Eval reward: -517.4442887769052, TD loss   : 96.55488087534904, Episode   :      7\n",
      "Iteration :    700, Train reward: -223.60542116277617, Eval reward: -517.4442887769052, TD loss   : 99.77819746494293, Episode   :      8\n",
      "Iteration :    800, Train reward: -223.4973996005792, Eval reward: -517.4442887769052, TD loss   : 81.05704012393952, Episode   :      9\n",
      "Iteration :    900, Train reward: -190.9116786880937, Eval reward: -517.4442887769052, TD loss   : 94.2295990562439, Episode   :     11\n",
      "Iteration :   1000, Train reward: -177.89255901622815, Eval reward: -10.946499876640154, TD loss   : 101.2407611989975, Episode   :     12\n",
      "Iteration :   1100, Train reward: -164.84304272815547, Eval reward: -10.946499876640154, TD loss   : 79.97671431303024, Episode   :     13\n",
      "Iteration :   1200, Train reward: -166.1357364991379, Eval reward: -10.946499876640154, TD loss   : 84.66325439929962, Episode   :     14\n",
      "Iteration :   1300, Train reward: -177.72396592679584, Eval reward: -10.946499876640154, TD loss   : 73.18145294427872, Episode   :     16\n",
      "Iteration :   1400, Train reward: -170.04148476893047, Eval reward: -10.946499876640154, TD loss   : 75.08688044548035, Episode   :     17\n",
      "Iteration :   1500, Train reward: -170.04148476893047, Eval reward: -30.6748981992325, TD loss   : 63.2726190674305, Episode   :     17\n",
      "Iteration :   1600, Train reward: -162.5974251703417, Eval reward: -30.6748981992325, TD loss   : 48.884448261260985, Episode   :     19\n",
      "Iteration :   1700, Train reward: -162.37979825112623, Eval reward: -30.6748981992325, TD loss   : 69.76304843306542, Episode   :     20\n",
      "Iteration :   1800, Train reward: -162.37979825112623, Eval reward: -30.6748981992325, TD loss   : 63.988586612939834, Episode   :     20\n",
      "Iteration :   1900, Train reward: -165.4434081819144, Eval reward: -30.6748981992325, TD loss   : 73.5204424071312, Episode   :     21\n",
      "Iteration :   2000, Train reward: -160.8073996484223, Eval reward: -260.309485925275, TD loss   : 63.23298250794411, Episode   :     22\n",
      "Iteration :   2100, Train reward: -139.76407468492602, Eval reward: -260.309485925275, TD loss   : 48.50763025760651, Episode   :     24\n",
      "Iteration :   2200, Train reward: -139.76407468492602, Eval reward: -260.309485925275, TD loss   : 64.66605553388595, Episode   :     24\n",
      "Iteration :   2300, Train reward: -130.23804007895654, Eval reward: -260.309485925275, TD loss   : 62.78239928126335, Episode   :     25\n",
      "Iteration :   2400, Train reward: -126.02143022091846, Eval reward: -260.309485925275, TD loss   : 63.861225649118424, Episode   :     27\n",
      "Iteration :   2500, Train reward: -117.66860033143053, Eval reward: -136.3882645677595, TD loss   : 60.35574919939041, Episode   :     28\n",
      "Iteration :   2600, Train reward: -110.16225927732944, Eval reward: -136.3882645677595, TD loss   : 49.49737974047661, Episode   :     30\n",
      "Iteration :   2700, Train reward: -107.26868282109066, Eval reward: -136.3882645677595, TD loss   : 55.62464971661568, Episode   :     31\n",
      "Iteration :   2800, Train reward: -116.68367190254214, Eval reward: -136.3882645677595, TD loss   : 60.18887081027031, Episode   :     32\n",
      "Iteration :   2900, Train reward: -121.26747897095875, Eval reward: -136.3882645677595, TD loss   : 62.74921208143234, Episode   :     33\n",
      "Iteration :   3000, Train reward: -115.98710584028959, Eval reward: -171.93125196400072, TD loss   : 66.96494428753853, Episode   :     34\n",
      "Iteration :   3100, Train reward: -100.17417043209883, Eval reward: -171.93125196400072, TD loss   : 52.33942889690399, Episode   :     36\n",
      "Iteration :   3200, Train reward: -109.57329897659145, Eval reward: -171.93125196400072, TD loss   : 46.83246297717094, Episode   :     37\n",
      "Iteration :   3300, Train reward: -111.66706156215396, Eval reward: -171.93125196400072, TD loss   : 55.27370695590973, Episode   :     38\n",
      "Iteration :   3400, Train reward: -110.94775947019453, Eval reward: -171.93125196400072, TD loss   : 69.98386091470718, Episode   :     39\n",
      "Iteration :   3500, Train reward: -108.78632776363705, Eval reward: -226.94556484663275, TD loss   : 60.172169349193574, Episode   :     40\n",
      "Iteration :   3600, Train reward: -106.0031048016541, Eval reward: -226.94556484663275, TD loss   : 69.62386299967766, Episode   :     41\n",
      "Iteration :   3700, Train reward: -105.55006455762404, Eval reward: -226.94556484663275, TD loss   : 60.05173801660538, Episode   :     42\n",
      "Iteration :   3800, Train reward: -105.55006455762404, Eval reward: -226.94556484663275, TD loss   : 57.41596986413002, Episode   :     42\n",
      "Iteration :   3900, Train reward: -99.3548470305322, Eval reward: -226.94556484663275, TD loss   : 67.7605070412159, Episode   :     43\n",
      "Iteration :   4000, Train reward: -99.51109480942957, Eval reward: -85.43052307761143, TD loss   : 62.683144516944886, Episode   :     45\n",
      "Iteration :   4100, Train reward: -91.1818134800989, Eval reward: -85.43052307761143, TD loss   : 58.76590343475342, Episode   :     46\n",
      "Iteration :   4200, Train reward: -90.33751231971314, Eval reward: -85.43052307761143, TD loss   : 51.17156419634819, Episode   :     47\n",
      "Iteration :   4300, Train reward: -89.72404494494685, Eval reward: -85.43052307761143, TD loss   : 38.46971925616264, Episode   :     48\n",
      "Iteration :   4400, Train reward: -95.17204061616732, Eval reward: -85.43052307761143, TD loss   : 52.23152599334717, Episode   :     49\n",
      "Iteration :   4500, Train reward: -95.17204061616732, Eval reward: -76.40071884479146, TD loss   : 49.00682843208313, Episode   :     49\n",
      "Iteration :   4600, Train reward: -99.58593496618508, Eval reward: -76.40071884479146, TD loss   : 38.47454713582992, Episode   :     50\n",
      "Iteration :   4700, Train reward: -105.90864000190125, Eval reward: -76.40071884479146, TD loss   : 51.65882540464401, Episode   :     51\n",
      "Iteration :   4800, Train reward: -104.47684004099335, Eval reward: -76.40071884479146, TD loss   : 40.73974342346192, Episode   :     52\n",
      "Iteration :   4900, Train reward: -104.47684004099335, Eval reward: -76.40071884479146, TD loss   : 57.694124367237094, Episode   :     52\n",
      "Iteration :   5000, Train reward: -102.79496204447055, Eval reward: -97.21388569915665, TD loss   : 51.6112125492096, Episode   :     53\n",
      "Iteration :   5100, Train reward: -99.20773715142798, Eval reward: -97.21388569915665, TD loss   : 48.54098638057709, Episode   :     54\n",
      "Iteration :   5200, Train reward: -95.80649550172879, Eval reward: -97.21388569915665, TD loss   : 37.63529065728188, Episode   :     55\n",
      "Iteration :   5300, Train reward: -93.27821704212319, Eval reward: -97.21388569915665, TD loss   : 54.771214740276335, Episode   :     56\n",
      "Iteration :   5400, Train reward: -86.84541989117291, Eval reward: -97.21388569915665, TD loss   : 48.00955417156219, Episode   :     57\n",
      "Iteration :   5500, Train reward: -86.84541989117291, Eval reward: -185.08926010038653, TD loss   : 61.23132014036179, Episode   :     57\n",
      "Iteration :   5600, Train reward: -81.95816979605875, Eval reward: -185.08926010038653, TD loss   : 37.47076687455177, Episode   :     58\n",
      "Iteration :   5700, Train reward: -75.22191175048562, Eval reward: -185.08926010038653, TD loss   : 45.62559621572495, Episode   :     59\n",
      "Iteration :   5800, Train reward: -83.63168912013043, Eval reward: -185.08926010038653, TD loss   : 46.80733070611954, Episode   :     60\n",
      "Iteration :   5900, Train reward: -83.63168912013043, Eval reward: -185.08926010038653, TD loss   : 49.36135726571083, Episode   :     60\n",
      "Iteration :   6000, Train reward: -83.8828572660772, Eval reward: -193.80241267160045, TD loss   : 43.20610672235489, Episode   :     61\n",
      "Iteration :   6100, Train reward: -79.41719801949617, Eval reward: -193.80241267160045, TD loss   : 45.82445767164231, Episode   :     62\n",
      "Iteration :   6200, Train reward: -83.53811846038523, Eval reward: -193.80241267160045, TD loss   : 47.298952419757846, Episode   :     63\n",
      "Iteration :   6300, Train reward: -88.31735169949762, Eval reward: -193.80241267160045, TD loss   : 48.40501233816147, Episode   :     64\n",
      "Iteration :   6400, Train reward: -87.86918054303263, Eval reward: -193.80241267160045, TD loss   : 48.353511443138125, Episode   :     65\n",
      "Iteration :   6500, Train reward: -92.53511526314522, Eval reward: -64.13428186383001, TD loss   : 41.77661585211754, Episode   :     66\n",
      "Iteration :   6600, Train reward: -88.23393090434038, Eval reward: -64.13428186383001, TD loss   : 41.919894992113115, Episode   :     68\n",
      "Iteration :   6700, Train reward: -88.23393090434038, Eval reward: -64.13428186383001, TD loss   : 45.30216912865639, Episode   :     68\n",
      "Iteration :   6800, Train reward: -94.1360149021977, Eval reward: -64.13428186383001, TD loss   : 37.85358738183975, Episode   :     69\n",
      "Iteration :   6900, Train reward: -91.2298308670862, Eval reward: -64.13428186383001, TD loss   : 43.04505481004715, Episode   :     70\n",
      "Iteration :   7000, Train reward: -91.2298308670862, Eval reward: -6.783850294761018, TD loss   : 59.50759570479393, Episode   :     70\n",
      "Iteration :   7100, Train reward: -88.37323170484247, Eval reward: -6.783850294761018, TD loss   : 36.513110003471375, Episode   :     71\n",
      "Iteration :   7200, Train reward: -83.58238640009819, Eval reward: -6.783850294761018, TD loss   : 36.7624284863472, Episode   :     72\n",
      "Iteration :   7300, Train reward: -81.7970481625052, Eval reward: -6.783850294761018, TD loss   : 38.79696405172348, Episode   :     73\n",
      "Iteration :   7400, Train reward: -81.7970481625052, Eval reward: -6.783850294761018, TD loss   : 35.248563538789746, Episode   :     73\n",
      "Iteration :   7500, Train reward: -82.21624729639082, Eval reward: -29.429427997979694, TD loss   : 44.46985015630722, Episode   :     74\n",
      "Iteration :   7600, Train reward: -83.13179853954398, Eval reward: -29.429427997979694, TD loss   : 41.5902108502388, Episode   :     75\n",
      "Iteration :   7700, Train reward: -93.68498591675284, Eval reward: -29.429427997979694, TD loss   : 38.98759384155274, Episode   :     76\n",
      "Iteration :   7800, Train reward: -93.06646607612733, Eval reward: -29.429427997979694, TD loss   : 34.57431110739708, Episode   :     77\n",
      "Iteration :   7900, Train reward: -93.06646607612733, Eval reward: -29.429427997979694, TD loss   : 35.82299741983414, Episode   :     77\n",
      "Iteration :   8000, Train reward: -101.01899285807784, Eval reward: -1.7884025938048027, TD loss   : 34.92312553405762, Episode   :     78\n",
      "Iteration :   8100, Train reward: -100.44091884052665, Eval reward: -1.7884025938048027, TD loss   : 33.13017869710922, Episode   :     79\n",
      "Iteration :   8200, Train reward: -100.44091884052665, Eval reward: -1.7884025938048027, TD loss   : 43.123277510404584, Episode   :     79\n",
      "Iteration :   8300, Train reward: -100.44091884052665, Eval reward: -1.7884025938048027, TD loss   : 33.547076147794726, Episode   :     79\n",
      "Iteration :   8400, Train reward: -85.67086932205834, Eval reward: -1.7884025938048027, TD loss   : 32.793801621198654, Episode   :     80\n",
      "Iteration :   8500, Train reward: -84.32305273627995, Eval reward: -42.978014721638814, TD loss   : 34.29442382335663, Episode   :     81\n",
      "Iteration :   8600, Train reward: -85.3619724388048, Eval reward: -42.978014721638814, TD loss   : 45.09306277632713, Episode   :     82\n",
      "Iteration :   8700, Train reward: -85.3619724388048, Eval reward: -42.978014721638814, TD loss   : 35.82005472779274, Episode   :     82\n",
      "Iteration :   8800, Train reward: -83.99510977378637, Eval reward: -42.978014721638814, TD loss   : 29.647181364297868, Episode   :     83\n",
      "Iteration :   8900, Train reward: -79.3361108022724, Eval reward: -42.978014721638814, TD loss   : 37.680314061641695, Episode   :     84\n",
      "Iteration :   9000, Train reward: -79.3361108022724, Eval reward: -65.1942517434849, TD loss   : 34.21718736767769, Episode   :     84\n",
      "Iteration :   9100, Train reward: -76.54414749637495, Eval reward: -65.1942517434849, TD loss   : 30.871303050518037, Episode   :     85\n",
      "Iteration :   9200, Train reward: -78.63854975593574, Eval reward: -65.1942517434849, TD loss   : 32.83572008132935, Episode   :     86\n",
      "Iteration :   9300, Train reward: -78.63854975593574, Eval reward: -65.1942517434849, TD loss   : 32.15988210558891, Episode   :     86\n",
      "Iteration :   9400, Train reward: -76.95195434810098, Eval reward: -65.1942517434849, TD loss   : 36.096167476177214, Episode   :     87\n",
      "Iteration :   9500, Train reward: -76.95195434810098, Eval reward: -90.22727946407926, TD loss   : 25.559287925958632, Episode   :     87\n",
      "Iteration :   9600, Train reward: -73.60319882539463, Eval reward: -90.22727946407926, TD loss   : 40.77347273468971, Episode   :     88\n",
      "Iteration :   9700, Train reward: -66.56398064473824, Eval reward: -90.22727946407926, TD loss   : 30.316977491378783, Episode   :     89\n",
      "Iteration :   9800, Train reward: -66.21170102716898, Eval reward: -90.22727946407926, TD loss   : 32.267660944461824, Episode   :     90\n",
      "Iteration :   9900, Train reward: -67.06422148707254, Eval reward: -90.22727946407926, TD loss   : 35.191430612802506, Episode   :     91\n",
      "Iteration :  10000, Train reward: -64.03152153133878, Eval reward: 0.5662133390761348, TD loss   : 38.41151872396469, Episode   :     92\n",
      "Iteration :  10100, Train reward: -62.69743743868436, Eval reward: 0.5662133390761348, TD loss   : 26.945379766225816, Episode   :     93\n",
      "Iteration :  10200, Train reward: -64.62732295296817, Eval reward: 0.5662133390761348, TD loss   : 38.160937492847445, Episode   :     94\n",
      "Iteration :  10300, Train reward: -64.62732295296817, Eval reward: 0.5662133390761348, TD loss   : 31.813210250139235, Episode   :     94\n",
      "Iteration :  10400, Train reward: -66.33547006346973, Eval reward: 0.5662133390761348, TD loss   : 22.733370203971862, Episode   :     95\n",
      "Iteration :  10500, Train reward: -53.947074191132046, Eval reward: -47.12767379451938, TD loss   : 30.673135386705397, Episode   :     96\n",
      "Iteration :  10600, Train reward: -49.22519851456988, Eval reward: -47.12767379451938, TD loss   : 33.253928512334824, Episode   :     97\n",
      "Iteration :  10700, Train reward: -49.22519851456988, Eval reward: -47.12767379451938, TD loss   : 28.496853659152986, Episode   :     97\n",
      "Iteration :  10800, Train reward: -61.3616089307713, Eval reward: -47.12767379451938, TD loss   : 25.78337277650833, Episode   :     99\n",
      "Iteration :  10900, Train reward: -61.3616089307713, Eval reward: -47.12767379451938, TD loss   : 27.847784073352813, Episode   :     99\n",
      "Iteration :  11000, Train reward: -62.78335394774145, Eval reward: -25.388724145989148, TD loss   : 32.3382448899746, Episode   :    100\n",
      "Iteration :  11100, Train reward: -58.4401132942214, Eval reward: -25.388724145989148, TD loss   : 34.116303861141205, Episode   :    101\n",
      "Iteration :  11200, Train reward: -58.4401132942214, Eval reward: -25.388724145989148, TD loss   : 24.707083287239076, Episode   :    101\n",
      "Iteration :  11300, Train reward: -75.9786176669414, Eval reward: -25.388724145989148, TD loss   : 24.47561861038208, Episode   :    102\n",
      "Iteration :  11400, Train reward: -75.9786176669414, Eval reward: -25.388724145989148, TD loss   : 29.596625756025315, Episode   :    102\n",
      "Iteration :  11500, Train reward: -71.49846948137919, Eval reward: 6.587921785983411, TD loss   : 23.92190656542778, Episode   :    103\n",
      "Iteration :  11600, Train reward: -63.2404906398791, Eval reward: 6.587921785983411, TD loss   : 36.00756594777107, Episode   :    104\n",
      "Iteration :  11700, Train reward: -63.2404906398791, Eval reward: 6.587921785983411, TD loss   : 28.801441078186034, Episode   :    104\n",
      "Iteration :  11800, Train reward: -73.75617076649642, Eval reward: 6.587921785983411, TD loss   : 27.108855805397035, Episode   :    105\n",
      "Iteration :  11900, Train reward: -66.62952270666696, Eval reward: 6.587921785983411, TD loss   : 30.821158390045166, Episode   :    106\n",
      "Iteration :  12000, Train reward: -66.62952270666696, Eval reward: 39.96628279841932, TD loss   : 26.284019774198534, Episode   :    106\n",
      "Iteration :  12100, Train reward: -70.88798380746948, Eval reward: 39.96628279841932, TD loss   : 27.38307189822197, Episode   :    108\n",
      "Iteration :  12200, Train reward: -70.88798380746948, Eval reward: 39.96628279841932, TD loss   : 26.114907670021058, Episode   :    108\n",
      "Iteration :  12300, Train reward: -70.88798380746948, Eval reward: 39.96628279841932, TD loss   : 30.273713940382002, Episode   :    108\n",
      "Iteration :  12400, Train reward: -69.30409682826813, Eval reward: 39.96628279841932, TD loss   : 22.453568317890166, Episode   :    109\n",
      "Iteration :  12500, Train reward: -66.17879333053267, Eval reward: -18.459361634392458, TD loss   : 31.422803385257723, Episode   :    110\n",
      "Iteration :  12600, Train reward: -60.406005093150426, Eval reward: -18.459361634392458, TD loss   : 27.44566539645195, Episode   :    111\n",
      "Iteration :  12700, Train reward: -59.888601218686446, Eval reward: -18.459361634392458, TD loss   : 19.878633028268816, Episode   :    112\n",
      "Iteration :  12800, Train reward: -62.902526483997846, Eval reward: -18.459361634392458, TD loss   : 24.871671143770218, Episode   :    113\n",
      "Iteration :  12900, Train reward: -62.902526483997846, Eval reward: -18.459361634392458, TD loss   : 27.48092302441597, Episode   :    113\n",
      "Iteration :  13000, Train reward: -63.49674053639684, Eval reward: -103.35744126123555, TD loss   : 27.471058245897293, Episode   :    114\n",
      "Iteration :  13100, Train reward: -61.233183288492285, Eval reward: -103.35744126123555, TD loss   : 29.874960837364195, Episode   :    115\n",
      "Iteration :  13200, Train reward: -59.48653873516247, Eval reward: -103.35744126123555, TD loss   : 26.353617762327193, Episode   :    116\n",
      "Iteration :  13300, Train reward: -59.48653873516247, Eval reward: -103.35744126123555, TD loss   : 20.868634339571, Episode   :    116\n",
      "Iteration :  13400, Train reward: -63.372006720060725, Eval reward: -103.35744126123555, TD loss   : 24.30257239818573, Episode   :    117\n",
      "Iteration :  13500, Train reward: -63.372006720060725, Eval reward: -31.2903004599749, TD loss   : 19.30392617702484, Episode   :    117\n",
      "Iteration :  13600, Train reward: -46.69874878410671, Eval reward: -31.2903004599749, TD loss   : 17.091873054504394, Episode   :    118\n",
      "Iteration :  13700, Train reward: -46.69874878410671, Eval reward: -31.2903004599749, TD loss   : 22.370924723148345, Episode   :    118\n",
      "Iteration :  13800, Train reward: -46.69874878410671, Eval reward: -31.2903004599749, TD loss   : 22.12839189171791, Episode   :    118\n",
      "Iteration :  13900, Train reward: -41.84387965099601, Eval reward: -31.2903004599749, TD loss   : 23.667258429527283, Episode   :    119\n",
      "Iteration :  14000, Train reward: -41.84387965099601, Eval reward: -31.550924364314977, TD loss   : 18.846918202638626, Episode   :    119\n",
      "Iteration :  14100, Train reward: -35.206224783300435, Eval reward: -31.550924364314977, TD loss   : 25.927779281139372, Episode   :    120\n",
      "Iteration :  14200, Train reward: -36.90855632769148, Eval reward: -31.550924364314977, TD loss   : 22.262617775201797, Episode   :    121\n",
      "Iteration :  14300, Train reward: -36.90855632769148, Eval reward: -31.550924364314977, TD loss   : 38.626177965402604, Episode   :    121\n",
      "Iteration :  14400, Train reward: -24.82835991845223, Eval reward: -31.550924364314977, TD loss   : 19.13755828499794, Episode   :    122\n",
      "Iteration :  14500, Train reward: -24.82835991845223, Eval reward: -8.315493703606839, TD loss   : 21.923723236322402, Episode   :    122\n",
      "Iteration :  14600, Train reward: -22.621966034955825, Eval reward: -8.315493703606839, TD loss   : 20.654054347872734, Episode   :    123\n",
      "Iteration :  14700, Train reward: -25.440686244976302, Eval reward: -8.315493703606839, TD loss   : 29.725541564226152, Episode   :    124\n",
      "Iteration :  14800, Train reward: -18.727492828674936, Eval reward: -8.315493703606839, TD loss   : 23.15344159603119, Episode   :    125\n",
      "Iteration :  14900, Train reward: -17.221637826756258, Eval reward: -8.315493703606839, TD loss   : 20.730266497135162, Episode   :    126\n",
      "Iteration :  15000, Train reward: -17.221637826756258, Eval reward: -15.252083758177923, TD loss   : 20.528755295276643, Episode   :    126\n",
      "Iteration :  15100, Train reward: -11.314471840543487, Eval reward: -15.252083758177923, TD loss   : 22.236270900964737, Episode   :    127\n",
      "Iteration :  15200, Train reward: -11.314471840543487, Eval reward: -15.252083758177923, TD loss   : 18.013844114542007, Episode   :    127\n",
      "Iteration :  15300, Train reward: -8.714426384086394, Eval reward: -15.252083758177923, TD loss   : 18.708619035482407, Episode   :    128\n",
      "Iteration :  15400, Train reward: -5.022087921843669, Eval reward: -15.252083758177923, TD loss   : 23.01916848421097, Episode   :    129\n",
      "Iteration :  15500, Train reward: -5.022087921843669, Eval reward: -2.9784902175608066, TD loss   : 20.963024113178253, Episode   :    129\n",
      "Iteration :  15600, Train reward: -4.495125238452573, Eval reward: -2.9784902175608066, TD loss   : 24.259234305620193, Episode   :    130\n",
      "Iteration :  15700, Train reward: -4.495125238452573, Eval reward: -2.9784902175608066, TD loss   : 22.001424621343613, Episode   :    130\n",
      "Iteration :  15800, Train reward: -8.12340043823235, Eval reward: -2.9784902175608066, TD loss   : 29.41675749182701, Episode   :    131\n",
      "Iteration :  15900, Train reward: -8.12340043823235, Eval reward: -2.9784902175608066, TD loss   : 21.970040290355684, Episode   :    131\n",
      "Iteration :  16000, Train reward: -7.9450972263600335, Eval reward: -6.396779779540006, TD loss   : 20.846900029182436, Episode   :    132\n",
      "Iteration :  16100, Train reward: -5.616322287471009, Eval reward: -6.396779779540006, TD loss   : 19.164430137872696, Episode   :    133\n",
      "Iteration :  16200, Train reward: -5.133381583229767, Eval reward: -6.396779779540006, TD loss   : 20.350595155954363, Episode   :    134\n",
      "Iteration :  16300, Train reward: -5.133381583229767, Eval reward: -6.396779779540006, TD loss   : 21.346124366521835, Episode   :    134\n",
      "Iteration :  16400, Train reward: -5.133381583229767, Eval reward: -6.396779779540006, TD loss   : 29.919016591310502, Episode   :    134\n",
      "Iteration :  16500, Train reward: -3.5365994002765326, Eval reward: -36.75108273429459, TD loss   : 23.662665774822234, Episode   :    135\n",
      "Iteration :  16600, Train reward: -7.165651626725586, Eval reward: -36.75108273429459, TD loss   : 12.173439149856568, Episode   :    136\n",
      "Iteration :  16700, Train reward: -7.165651626725586, Eval reward: -36.75108273429459, TD loss   : 18.157468414306642, Episode   :    136\n",
      "Iteration :  16800, Train reward: -7.165651626725586, Eval reward: -36.75108273429459, TD loss   : 23.568201055526732, Episode   :    136\n",
      "Iteration :  16900, Train reward: -1.3790387000310838, Eval reward: -36.75108273429459, TD loss   : 18.56061100125313, Episode   :    137\n",
      "Iteration :  17000, Train reward: -1.3790387000310838, Eval reward: -10.70369428971512, TD loss   : 21.808061960935593, Episode   :    137\n",
      "Iteration :  17100, Train reward: -1.5847812607240228, Eval reward: -10.70369428971512, TD loss   : 25.42297919154167, Episode   :    138\n",
      "Iteration :  17200, Train reward: -1.5847812607240228, Eval reward: -10.70369428971512, TD loss   : 15.181045334339142, Episode   :    138\n",
      "Iteration :  17300, Train reward: -1.5847812607240228, Eval reward: -10.70369428971512, TD loss   : 14.634563274383545, Episode   :    138\n",
      "Iteration :  17400, Train reward: 6.2672959160566455, Eval reward: -10.70369428971512, TD loss   : 18.140161460638048, Episode   :    139\n",
      "Iteration :  17500, Train reward: 1.3074932775755967, Eval reward: 17.581785035599374, TD loss   : 19.146978942155837, Episode   :    140\n",
      "Iteration :  17600, Train reward: 4.340507746596069, Eval reward: 17.581785035599374, TD loss   : 16.424828815460206, Episode   :    141\n",
      "Iteration :  17700, Train reward: 4.340507746596069, Eval reward: 17.581785035599374, TD loss   : 23.093055958747865, Episode   :    141\n",
      "Iteration :  17800, Train reward: 4.340507746596069, Eval reward: 17.581785035599374, TD loss   : 14.537099540233612, Episode   :    141\n",
      "Iteration :  17900, Train reward: 9.955925579834638, Eval reward: 17.581785035599374, TD loss   : 16.625090456008913, Episode   :    142\n",
      "Iteration :  18000, Train reward: 9.955925579834638, Eval reward: -40.12763592447696, TD loss   : 18.771883996725084, Episode   :    142\n",
      "Iteration :  18100, Train reward: 10.928427300123317, Eval reward: -40.12763592447696, TD loss   : 33.1572291123867, Episode   :    143\n",
      "Iteration :  18200, Train reward: 10.928427300123317, Eval reward: -40.12763592447696, TD loss   : 23.37023577570915, Episode   :    143\n",
      "Iteration :  18300, Train reward: 10.928427300123317, Eval reward: -40.12763592447696, TD loss   : 21.802821229696274, Episode   :    143\n",
      "Iteration :  18400, Train reward: 13.727859527217115, Eval reward: -40.12763592447696, TD loss   : 22.335311503410338, Episode   :    144\n",
      "Iteration :  18500, Train reward: 13.727859527217115, Eval reward: -37.45215320917733, TD loss   : 22.578463672399522, Episode   :    144\n",
      "Iteration :  18600, Train reward: 17.388998876483008, Eval reward: -37.45215320917733, TD loss   : 18.01579021215439, Episode   :    145\n",
      "Iteration :  18700, Train reward: 17.388998876483008, Eval reward: -37.45215320917733, TD loss   : 21.39781767964363, Episode   :    145\n",
      "Iteration :  18800, Train reward: 17.388998876483008, Eval reward: -37.45215320917733, TD loss   : 18.078364293575287, Episode   :    145\n",
      "Iteration :  18900, Train reward: 15.678184676052108, Eval reward: -37.45215320917733, TD loss   : 18.521897205114364, Episode   :    146\n",
      "Iteration :  19000, Train reward: 15.678184676052108, Eval reward: -11.872278952032081, TD loss   : 21.254942422509192, Episode   :    146\n",
      "Iteration :  19100, Train reward: 9.969507115365667, Eval reward: -11.872278952032081, TD loss   : 22.896526402235033, Episode   :    147\n",
      "Iteration :  19200, Train reward: 9.969507115365667, Eval reward: -11.872278952032081, TD loss   : 16.01553939640522, Episode   :    147\n",
      "Iteration :  19300, Train reward: 9.969507115365667, Eval reward: -11.872278952032081, TD loss   : 21.00308300256729, Episode   :    147\n",
      "Iteration :  19400, Train reward: 7.385658901796359, Eval reward: -11.872278952032081, TD loss   : 18.21913991689682, Episode   :    148\n",
      "Iteration :  19500, Train reward: 7.385658901796359, Eval reward: -27.207182976193234, TD loss   : 20.832722413539887, Episode   :    148\n",
      "Iteration :  19600, Train reward: 8.421220526517102, Eval reward: -27.207182976193234, TD loss   : 12.476678554415702, Episode   :    149\n",
      "Iteration :  19700, Train reward: 8.421220526517102, Eval reward: -27.207182976193234, TD loss   : 15.221884670257568, Episode   :    149\n",
      "Iteration :  19800, Train reward: 8.421220526517102, Eval reward: -27.207182976193234, TD loss   : 22.854575811624528, Episode   :    149\n",
      "Iteration :  19900, Train reward: 9.712174073999108, Eval reward: -27.207182976193234, TD loss   : 24.495756766796113, Episode   :    150\n",
      "Iteration :  20000, Train reward: 9.712174073999108, Eval reward: 0.5334920608313908, TD loss   : 16.71391739487648, Episode   :    150\n",
      "Iteration :  20100, Train reward: 10.187654036921883, Eval reward: 0.5334920608313908, TD loss   : 24.77279547929764, Episode   :    151\n",
      "Iteration :  20200, Train reward: 10.187654036921883, Eval reward: 0.5334920608313908, TD loss   : 17.184222930669783, Episode   :    151\n",
      "Iteration :  20300, Train reward: 10.187654036921883, Eval reward: 0.5334920608313908, TD loss   : 16.833385426998138, Episode   :    151\n",
      "Iteration :  20400, Train reward: 13.188357715870746, Eval reward: 0.5334920608313908, TD loss   : 19.244268523454664, Episode   :    152\n",
      "Iteration :  20500, Train reward: 13.188357715870746, Eval reward: 17.99838381439982, TD loss   : 14.95089939236641, Episode   :    152\n",
      "Iteration :  20600, Train reward: 14.251682109470204, Eval reward: 17.99838381439982, TD loss   : 19.5566577231884, Episode   :    153\n",
      "Iteration :  20700, Train reward: 14.251682109470204, Eval reward: 17.99838381439982, TD loss   : 19.87405226111412, Episode   :    153\n",
      "Iteration :  20800, Train reward: 14.251682109470204, Eval reward: 17.99838381439982, TD loss   : 16.614858388900757, Episode   :    153\n",
      "Iteration :  20900, Train reward: 15.633512723269899, Eval reward: 17.99838381439982, TD loss   : 17.581350474357606, Episode   :    154\n",
      "Iteration :  21000, Train reward: 15.633512723269899, Eval reward: -30.3635420457994, TD loss   : 15.742323578596116, Episode   :    154\n",
      "Iteration :  21100, Train reward: 16.541172741609735, Eval reward: -30.3635420457994, TD loss   : 21.500510568618775, Episode   :    155\n",
      "Iteration :  21200, Train reward: 16.541172741609735, Eval reward: -30.3635420457994, TD loss   : 21.42417829155922, Episode   :    155\n",
      "Iteration :  21300, Train reward: 16.541172741609735, Eval reward: -30.3635420457994, TD loss   : 19.943958463668825, Episode   :    155\n",
      "Iteration :  21400, Train reward: 18.683964652181267, Eval reward: -30.3635420457994, TD loss   : 21.811281424760818, Episode   :    156\n",
      "Iteration :  21500, Train reward: 18.683964652181267, Eval reward: -65.54630514469436, TD loss   : 21.704048217535018, Episode   :    156\n",
      "Iteration :  21600, Train reward: 17.512943942398447, Eval reward: -65.54630514469436, TD loss   : 20.019060972929, Episode   :    157\n",
      "Iteration :  21700, Train reward: 17.280867954979545, Eval reward: -65.54630514469436, TD loss   : 12.217964115142822, Episode   :    158\n",
      "Iteration :  21800, Train reward: 17.280867954979545, Eval reward: -65.54630514469436, TD loss   : 13.920324866771699, Episode   :    158\n",
      "Iteration :  21900, Train reward: 17.280867954979545, Eval reward: -65.54630514469436, TD loss   : 14.242662533521653, Episode   :    158\n",
      "Iteration :  22000, Train reward: 8.91060599879875, Eval reward: -48.967116680103715, TD loss   : 13.928077543973922, Episode   :    159\n",
      "Iteration :  22100, Train reward: 2.8646011249535652, Eval reward: -48.967116680103715, TD loss   : 19.26416027069092, Episode   :    160\n",
      "Iteration :  22200, Train reward: 1.2489890173945724, Eval reward: -48.967116680103715, TD loss   : 17.478001166582107, Episode   :    161\n",
      "Iteration :  22300, Train reward: -0.7885760323729428, Eval reward: -48.967116680103715, TD loss   : 17.52453831076622, Episode   :    162\n",
      "Iteration :  22400, Train reward: -0.7885760323729428, Eval reward: -48.967116680103715, TD loss   : 17.968265780210494, Episode   :    162\n",
      "Iteration :  22500, Train reward: -17.977030784493984, Eval reward: 29.67706836597519, TD loss   : 17.688564974069596, Episode   :    163\n",
      "Iteration :  22600, Train reward: -19.22059562656188, Eval reward: 29.67706836597519, TD loss   : 17.937144906520842, Episode   :    164\n",
      "Iteration :  22700, Train reward: -19.22059562656188, Eval reward: 29.67706836597519, TD loss   : 20.846771595478057, Episode   :    164\n",
      "Iteration :  22800, Train reward: -19.22059562656188, Eval reward: 29.67706836597519, TD loss   : 16.21615163207054, Episode   :    164\n",
      "Iteration :  22900, Train reward: -18.2587824888032, Eval reward: 29.67706836597519, TD loss   : 20.649781286120415, Episode   :    165\n",
      "Iteration :  23000, Train reward: -18.2587824888032, Eval reward: -18.543036725036377, TD loss   : 15.567190794944763, Episode   :    165\n",
      "Iteration :  23100, Train reward: -17.377735811061605, Eval reward: -18.543036725036377, TD loss   : 21.036755845546722, Episode   :    166\n",
      "Iteration :  23200, Train reward: -17.377735811061605, Eval reward: -18.543036725036377, TD loss   : 16.215790216326713, Episode   :    166\n",
      "Iteration :  23300, Train reward: -25.045959267415714, Eval reward: -18.543036725036377, TD loss   : 22.16589760184288, Episode   :    167\n",
      "Iteration :  23400, Train reward: -25.045959267415714, Eval reward: -18.543036725036377, TD loss   : 23.541621881723405, Episode   :    167\n",
      "Iteration :  23500, Train reward: -25.045959267415714, Eval reward: -28.29066210693557, TD loss   : 20.419659975767136, Episode   :    167\n",
      "Iteration :  23600, Train reward: -19.797438008894137, Eval reward: -28.29066210693557, TD loss   : 24.46552801132202, Episode   :    168\n",
      "Iteration :  23700, Train reward: -19.797438008894137, Eval reward: -28.29066210693557, TD loss   : 18.27631708264351, Episode   :    168\n",
      "Iteration :  23800, Train reward: -19.797438008894137, Eval reward: -28.29066210693557, TD loss   : 12.48765962123871, Episode   :    168\n",
      "Iteration :  23900, Train reward: -22.099755732362574, Eval reward: -28.29066210693557, TD loss   : 20.35388536334038, Episode   :    169\n",
      "Iteration :  24000, Train reward: -22.099755732362574, Eval reward: -105.52902692397728, TD loss   : 19.03690315425396, Episode   :    169\n",
      "Iteration :  24100, Train reward: -21.338606254031994, Eval reward: -105.52902692397728, TD loss   : 14.05321609377861, Episode   :    170\n",
      "Iteration :  24200, Train reward: -21.338606254031994, Eval reward: -105.52902692397728, TD loss   : 23.74714550793171, Episode   :    170\n",
      "Iteration :  24300, Train reward: -21.338606254031994, Eval reward: -105.52902692397728, TD loss   : 11.924234541654586, Episode   :    170\n",
      "Iteration :  24400, Train reward: -17.698123842759163, Eval reward: -105.52902692397728, TD loss   : 18.835927003622054, Episode   :    171\n",
      "Iteration :  24500, Train reward: -17.698123842759163, Eval reward: -12.71947338817947, TD loss   : 20.651420841217043, Episode   :    171\n",
      "Iteration :  24600, Train reward: -18.83042298645347, Eval reward: -12.71947338817947, TD loss   : 19.755295715332032, Episode   :    172\n",
      "Iteration :  24700, Train reward: -18.83042298645347, Eval reward: -12.71947338817947, TD loss   : 20.724033942222594, Episode   :    172\n",
      "Iteration :  24800, Train reward: -18.83042298645347, Eval reward: -12.71947338817947, TD loss   : 17.37780252337456, Episode   :    172\n",
      "Iteration :  24900, Train reward: -17.212357968573237, Eval reward: -12.71947338817947, TD loss   : 22.122867320775985, Episode   :    173\n",
      "Iteration :  25000, Train reward: -14.489692675870282, Eval reward: -37.14808824106791, TD loss   : 21.42929074048996, Episode   :    174\n",
      "Iteration :  25100, Train reward: -11.241923303039496, Eval reward: -37.14808824106791, TD loss   : 15.57703962445259, Episode   :    176\n",
      "Iteration :  25200, Train reward: -11.241923303039496, Eval reward: -37.14808824106791, TD loss   : 24.43918329715729, Episode   :    176\n",
      "Iteration :  25300, Train reward: -11.241923303039496, Eval reward: -37.14808824106791, TD loss   : 22.121589401960374, Episode   :    176\n",
      "Iteration :  25400, Train reward: -16.813360453304938, Eval reward: -37.14808824106791, TD loss   : 12.987328156232834, Episode   :    177\n",
      "Iteration :  25500, Train reward: -16.813360453304938, Eval reward: -46.5725966297161, TD loss   : 16.12460235476494, Episode   :    177\n",
      "Iteration :  25600, Train reward: -14.34923959436037, Eval reward: -46.5725966297161, TD loss   : 21.39700127720833, Episode   :    178\n",
      "Iteration :  25700, Train reward: -14.34923959436037, Eval reward: -46.5725966297161, TD loss   : 20.406573700904847, Episode   :    178\n",
      "Iteration :  25800, Train reward: -14.34923959436037, Eval reward: -46.5725966297161, TD loss   : 20.923407192230226, Episode   :    178\n",
      "Iteration :  25900, Train reward: -16.134984384048153, Eval reward: -46.5725966297161, TD loss   : 19.8818890273571, Episode   :    179\n",
      "Iteration :  26000, Train reward: -16.134984384048153, Eval reward: -37.902186313059836, TD loss   : 18.630904594659807, Episode   :    179\n",
      "Iteration :  26100, Train reward: -14.015075139451033, Eval reward: -37.902186313059836, TD loss   : 20.38898581147194, Episode   :    180\n",
      "Iteration :  26200, Train reward: -14.015075139451033, Eval reward: -37.902186313059836, TD loss   : 24.11141150712967, Episode   :    180\n",
      "Iteration :  26300, Train reward: -14.015075139451033, Eval reward: -37.902186313059836, TD loss   : 18.495191736221315, Episode   :    180\n",
      "Iteration :  26400, Train reward: -11.398521831999465, Eval reward: -37.902186313059836, TD loss   : 17.390712915658952, Episode   :    181\n",
      "Iteration :  26500, Train reward: -11.398521831999465, Eval reward: 18.621986675884376, TD loss   : 16.725400079488754, Episode   :    181\n",
      "Iteration :  26600, Train reward: -11.391272669839095, Eval reward: 18.621986675884376, TD loss   : 13.173703172206878, Episode   :    182\n",
      "Iteration :  26700, Train reward: -11.391272669839095, Eval reward: 18.621986675884376, TD loss   : 15.663640849590301, Episode   :    182\n",
      "Iteration :  26800, Train reward: -2.1140524700444807, Eval reward: 18.621986675884376, TD loss   : 16.27456636428833, Episode   :    183\n",
      "Iteration :  26900, Train reward: -2.1140524700444807, Eval reward: 18.621986675884376, TD loss   : 17.49322745203972, Episode   :    183\n",
      "Iteration :  27000, Train reward: -2.1140524700444807, Eval reward: -24.79036606218239, TD loss   : 19.111406121253967, Episode   :    183\n",
      "Iteration :  27100, Train reward: 0.8745828038351583, Eval reward: -24.79036606218239, TD loss   : 18.216218889951705, Episode   :    185\n",
      "Iteration :  27200, Train reward: 0.8745828038351583, Eval reward: -24.79036606218239, TD loss   : 15.108663550615312, Episode   :    185\n",
      "Iteration :  27300, Train reward: 0.8745828038351583, Eval reward: -24.79036606218239, TD loss   : 18.326404800415037, Episode   :    185\n",
      "Iteration :  27400, Train reward: 0.6908613516340208, Eval reward: -24.79036606218239, TD loss   : 16.902784273028374, Episode   :    186\n",
      "Iteration :  27500, Train reward: 0.6908613516340208, Eval reward: 45.28605909288605, TD loss   : 12.766738787293434, Episode   :    186\n",
      "Iteration :  27600, Train reward: 9.569397256757473, Eval reward: 45.28605909288605, TD loss   : 13.40413139462471, Episode   :    187\n",
      "Iteration :  27700, Train reward: 9.569397256757473, Eval reward: 45.28605909288605, TD loss   : 11.925745068192482, Episode   :    187\n",
      "Iteration :  27800, Train reward: 9.569397256757473, Eval reward: 45.28605909288605, TD loss   : 16.85829393863678, Episode   :    187\n",
      "Iteration :  27900, Train reward: 11.289241099974866, Eval reward: 45.28605909288605, TD loss   : 15.915497723817825, Episode   :    188\n",
      "Iteration :  28000, Train reward: 13.722399663945415, Eval reward: -10.353034271987728, TD loss   : 14.560206551551818, Episode   :    189\n",
      "Iteration :  28100, Train reward: 15.65314335243842, Eval reward: -10.353034271987728, TD loss   : 14.567085856199265, Episode   :    190\n",
      "Iteration :  28200, Train reward: 15.65314335243842, Eval reward: -10.353034271987728, TD loss   : 11.286032429933549, Episode   :    190\n",
      "Iteration :  28300, Train reward: 15.65314335243842, Eval reward: -10.353034271987728, TD loss   : 27.771497445106505, Episode   :    190\n",
      "Iteration :  28400, Train reward: 16.787902531304564, Eval reward: -10.353034271987728, TD loss   : 25.78689444541931, Episode   :    191\n",
      "Iteration :  28500, Train reward: 16.787902531304564, Eval reward: -62.06517986853767, TD loss   : 15.78712661743164, Episode   :    191\n",
      "Iteration :  28600, Train reward: 15.981590606735555, Eval reward: -62.06517986853767, TD loss   : 19.408205252885818, Episode   :    192\n",
      "Iteration :  28700, Train reward: 15.981590606735555, Eval reward: -62.06517986853767, TD loss   : 13.582875320911407, Episode   :    192\n",
      "Iteration :  28800, Train reward: 15.981590606735555, Eval reward: -62.06517986853767, TD loss   : 20.36031742811203, Episode   :    192\n",
      "Iteration :  28900, Train reward: 13.804772595450023, Eval reward: -62.06517986853767, TD loss   : 17.794586638212206, Episode   :    193\n",
      "Iteration :  29000, Train reward: 6.420912535122795, Eval reward: -11.079098502180784, TD loss   : 16.663978694677354, Episode   :    194\n",
      "Iteration :  29100, Train reward: 4.1686001801292045, Eval reward: -11.079098502180784, TD loss   : 14.829332110881806, Episode   :    195\n",
      "Iteration :  29200, Train reward: 4.1686001801292045, Eval reward: -11.079098502180784, TD loss   : 12.483292837142944, Episode   :    195\n",
      "Iteration :  29300, Train reward: -16.84868062930638, Eval reward: -11.079098502180784, TD loss   : 16.237934681773186, Episode   :    196\n",
      "Iteration :  29400, Train reward: -16.84868062930638, Eval reward: -11.079098502180784, TD loss   : 23.28503282546997, Episode   :    196\n",
      "Iteration :  29500, Train reward: -16.84868062930638, Eval reward: -2.0442417524741643, TD loss   : 10.722516814470291, Episode   :    196\n",
      "Iteration :  29600, Train reward: -15.982392527614062, Eval reward: -2.0442417524741643, TD loss   : 19.233907742500307, Episode   :    197\n",
      "Iteration :  29700, Train reward: -15.982392527614062, Eval reward: -2.0442417524741643, TD loss   : 24.288416475653648, Episode   :    197\n",
      "Iteration :  29800, Train reward: -15.982392527614062, Eval reward: -2.0442417524741643, TD loss   : 20.33009915113449, Episode   :    197\n",
      "Iteration :  29900, Train reward: -21.35377299089455, Eval reward: -2.0442417524741643, TD loss   : 14.06582621395588, Episode   :    198\n",
      "Iteration :  30000, Train reward: -21.35377299089455, Eval reward: -48.66075379919424, TD loss   : 14.715774913430215, Episode   :    198\n",
      "Iteration :  30100, Train reward: -19.75338320127228, Eval reward: -48.66075379919424, TD loss   : 12.327479526996612, Episode   :    199\n",
      "Iteration :  30200, Train reward: -19.75338320127228, Eval reward: -48.66075379919424, TD loss   : 20.5967094039917, Episode   :    199\n",
      "Iteration :  30300, Train reward: -19.75338320127228, Eval reward: -48.66075379919424, TD loss   : 14.196078456640244, Episode   :    199\n",
      "Iteration :  30400, Train reward: -13.98702735594594, Eval reward: -48.66075379919424, TD loss   : 14.271123307943345, Episode   :    200\n",
      "Iteration :  30500, Train reward: -13.98702735594594, Eval reward: -1.8785406365069348, TD loss   : 11.847358599901199, Episode   :    200\n",
      "Iteration :  30600, Train reward: -14.05854377864668, Eval reward: -1.8785406365069348, TD loss   : 16.748321232795714, Episode   :    201\n",
      "Iteration :  30700, Train reward: -14.05854377864668, Eval reward: -1.8785406365069348, TD loss   : 12.43540710568428, Episode   :    201\n",
      "Iteration :  30800, Train reward: -14.05854377864668, Eval reward: -1.8785406365069348, TD loss   : 23.09506098508835, Episode   :    201\n",
      "Iteration :  30900, Train reward: -11.303052287026564, Eval reward: -1.8785406365069348, TD loss   : 28.731338196992873, Episode   :    202\n",
      "Iteration :  31000, Train reward: -11.303052287026564, Eval reward: -14.066351347106039, TD loss   : 13.317746850252151, Episode   :    202\n",
      "Iteration :  31100, Train reward: -8.88160817716565, Eval reward: -14.066351347106039, TD loss   : 25.715797144174577, Episode   :    203\n",
      "Iteration :  31200, Train reward: -17.468174855815484, Eval reward: -14.066351347106039, TD loss   : 12.796745284795762, Episode   :    204\n",
      "Iteration :  31300, Train reward: -17.468174855815484, Eval reward: -14.066351347106039, TD loss   : 18.00458405971527, Episode   :    204\n",
      "Iteration :  31400, Train reward: -17.468174855815484, Eval reward: -14.066351347106039, TD loss   : 12.024362004995346, Episode   :    204\n",
      "Iteration :  31500, Train reward: -17.689137912471928, Eval reward: 44.65139891828282, TD loss   : 12.145230084657669, Episode   :    205\n",
      "Iteration :  31600, Train reward: -19.717933181448224, Eval reward: 44.65139891828282, TD loss   : 11.898119502663612, Episode   :    206\n",
      "Iteration :  31700, Train reward: -19.717933181448224, Eval reward: 44.65139891828282, TD loss   : 20.93443073153496, Episode   :    206\n",
      "Iteration :  31800, Train reward: -19.717933181448224, Eval reward: 44.65139891828282, TD loss   : 19.959362194538116, Episode   :    206\n",
      "Iteration :  31900, Train reward: -15.363438197787099, Eval reward: 44.65139891828282, TD loss   : 17.714949419498442, Episode   :    207\n",
      "Iteration :  32000, Train reward: -15.363438197787099, Eval reward: 33.689156484893466, TD loss   : 23.177741994857787, Episode   :    207\n",
      "Iteration :  32100, Train reward: -17.081413903237046, Eval reward: 33.689156484893466, TD loss   : 16.470332292318343, Episode   :    208\n",
      "Iteration :  32200, Train reward: -17.081413903237046, Eval reward: 33.689156484893466, TD loss   : 12.790219355821609, Episode   :    208\n",
      "Iteration :  32300, Train reward: -25.36826247677983, Eval reward: 33.689156484893466, TD loss   : 19.450729181170463, Episode   :    209\n",
      "Iteration :  32400, Train reward: -26.189556137901718, Eval reward: 33.689156484893466, TD loss   : 12.739832787513732, Episode   :    210\n",
      "Iteration :  32500, Train reward: -26.189556137901718, Eval reward: 42.97769578025854, TD loss   : 19.02215366244316, Episode   :    210\n",
      "Iteration :  32600, Train reward: -25.66385746818876, Eval reward: 42.97769578025854, TD loss   : 14.712644671201707, Episode   :    211\n",
      "Iteration :  32700, Train reward: -25.66385746818876, Eval reward: 42.97769578025854, TD loss   : 19.260861287117006, Episode   :    211\n",
      "Iteration :  32800, Train reward: -25.66385746818876, Eval reward: 42.97769578025854, TD loss   : 18.187641180753708, Episode   :    211\n",
      "Iteration :  32900, Train reward: -23.130986271410556, Eval reward: 42.97769578025854, TD loss   : 21.126408642530443, Episode   :    212\n",
      "Iteration :  33000, Train reward: -26.16350161447998, Eval reward: 34.202491954089005, TD loss   : 15.05179682135582, Episode   :    213\n",
      "Iteration :  33100, Train reward: -17.352139523841295, Eval reward: 34.202491954089005, TD loss   : 16.302078646421432, Episode   :    214\n",
      "Iteration :  33200, Train reward: -17.352139523841295, Eval reward: 34.202491954089005, TD loss   : 16.86776067018509, Episode   :    214\n",
      "Iteration :  33300, Train reward: -17.352139523841295, Eval reward: 34.202491954089005, TD loss   : 15.669640545845033, Episode   :    214\n",
      "Iteration :  33400, Train reward: -32.23282159287921, Eval reward: 34.202491954089005, TD loss   : 16.620159199237822, Episode   :    215\n",
      "Iteration :  33500, Train reward: -32.23282159287921, Eval reward: 33.730689585747015, TD loss   : 15.606475496292115, Episode   :    215\n",
      "Iteration :  33600, Train reward: -10.54746153972763, Eval reward: 33.730689585747015, TD loss   : 17.650997759103774, Episode   :    216\n",
      "Iteration :  33700, Train reward: -10.54746153972763, Eval reward: 33.730689585747015, TD loss   : 20.07754102945328, Episode   :    216\n",
      "Iteration :  33800, Train reward: -10.54746153972763, Eval reward: 33.730689585747015, TD loss   : 16.762120159864427, Episode   :    216\n",
      "Iteration :  33900, Train reward: -2.8181341237411424, Eval reward: 33.730689585747015, TD loss   : 18.63576911687851, Episode   :    217\n",
      "Iteration :  34000, Train reward: -2.8181341237411424, Eval reward: -30.10922049405974, TD loss   : 16.632594965696335, Episode   :    217\n",
      "Iteration :  34100, Train reward: 4.640563858072826, Eval reward: -30.10922049405974, TD loss   : 18.758489937782286, Episode   :    218\n",
      "Iteration :  34200, Train reward: 4.640563858072826, Eval reward: -30.10922049405974, TD loss   : 27.099029902219772, Episode   :    218\n",
      "Iteration :  34300, Train reward: 4.640563858072826, Eval reward: -30.10922049405974, TD loss   : 17.290016738176345, Episode   :    218\n",
      "Iteration :  34400, Train reward: 4.615975825820547, Eval reward: -30.10922049405974, TD loss   : 11.0780004799366, Episode   :    219\n",
      "Iteration :  34500, Train reward: 4.615975825820547, Eval reward: 30.8749731135851, TD loss   : 11.993494840860366, Episode   :    219\n",
      "Iteration :  34600, Train reward: 5.613189582735077, Eval reward: 30.8749731135851, TD loss   : 20.701472376585006, Episode   :    220\n",
      "Iteration :  34700, Train reward: 5.613189582735077, Eval reward: 30.8749731135851, TD loss   : 17.659771316051483, Episode   :    220\n",
      "Iteration :  34800, Train reward: 5.613189582735077, Eval reward: 30.8749731135851, TD loss   : 12.16082020163536, Episode   :    220\n",
      "Iteration :  34900, Train reward: 6.6624127833266495, Eval reward: 30.8749731135851, TD loss   : 13.974052166938781, Episode   :    221\n",
      "Iteration :  35000, Train reward: 6.6624127833266495, Eval reward: 47.95576103911649, TD loss   : 14.196490795612336, Episode   :    221\n",
      "Iteration :  35100, Train reward: 9.833442056949522, Eval reward: 47.95576103911649, TD loss   : 16.22130484700203, Episode   :    222\n",
      "Iteration :  35200, Train reward: 9.833442056949522, Eval reward: 47.95576103911649, TD loss   : 15.108042280673981, Episode   :    222\n",
      "Iteration :  35300, Train reward: 9.833442056949522, Eval reward: 47.95576103911649, TD loss   : 21.628283668756485, Episode   :    222\n",
      "Iteration :  35400, Train reward: 13.214093618949823, Eval reward: 47.95576103911649, TD loss   : 18.313909281492233, Episode   :    223\n",
      "Iteration :  35500, Train reward: 13.214093618949823, Eval reward: 26.732972974658793, TD loss   : 17.475848729610444, Episode   :    223\n",
      "Iteration :  35600, Train reward: 19.131424305235534, Eval reward: 26.732972974658793, TD loss   : 12.443871396780015, Episode   :    225\n",
      "Iteration :  35700, Train reward: 19.131424305235534, Eval reward: 26.732972974658793, TD loss   : 22.199126269817352, Episode   :    225\n",
      "Iteration :  35800, Train reward: 19.131424305235534, Eval reward: 26.732972974658793, TD loss   : 16.90013931155205, Episode   :    225\n",
      "Iteration :  35900, Train reward: 21.31301186863705, Eval reward: 26.732972974658793, TD loss   : 22.44177789449692, Episode   :    226\n",
      "Iteration :  36000, Train reward: 21.31301186863705, Eval reward: -24.514602380657877, TD loss   : 16.689975860118867, Episode   :    226\n",
      "Iteration :  36100, Train reward: 15.360935404745982, Eval reward: -24.514602380657877, TD loss   : 15.657636194229125, Episode   :    227\n",
      "Iteration :  36200, Train reward: 15.360935404745982, Eval reward: -24.514602380657877, TD loss   : 19.260497159957886, Episode   :    227\n",
      "Iteration :  36300, Train reward: 15.360935404745982, Eval reward: -24.514602380657877, TD loss   : 15.084442518949508, Episode   :    227\n",
      "Iteration :  36400, Train reward: 15.155150113134312, Eval reward: -24.514602380657877, TD loss   : 19.654485929608345, Episode   :    228\n",
      "Iteration :  36500, Train reward: 15.155150113134312, Eval reward: 27.526286873369788, TD loss   : 17.39298022389412, Episode   :    228\n",
      "Iteration :  36600, Train reward: 23.79811718765246, Eval reward: 27.526286873369788, TD loss   : 16.548290975093842, Episode   :    229\n",
      "Iteration :  36700, Train reward: 23.79811718765246, Eval reward: 27.526286873369788, TD loss   : 16.48868571281433, Episode   :    229\n",
      "Iteration :  36800, Train reward: 17.040369439732093, Eval reward: 27.526286873369788, TD loss   : 19.9145727288723, Episode   :    230\n",
      "Iteration :  36900, Train reward: 17.040369439732093, Eval reward: 27.526286873369788, TD loss   : 16.22397858262062, Episode   :    230\n",
      "Iteration :  37000, Train reward: 17.040369439732093, Eval reward: -34.801685057105736, TD loss   : 24.044301434755326, Episode   :    230\n",
      "Iteration :  37100, Train reward: 10.975294697245884, Eval reward: -34.801685057105736, TD loss   : 26.620610023736955, Episode   :    231\n",
      "Iteration :  37200, Train reward: 10.975294697245884, Eval reward: -34.801685057105736, TD loss   : 18.478854414224624, Episode   :    231\n",
      "Iteration :  37300, Train reward: 10.975294697245884, Eval reward: -34.801685057105736, TD loss   : 23.880673161745072, Episode   :    231\n",
      "Iteration :  37400, Train reward: 10.158189934335766, Eval reward: -34.801685057105736, TD loss   : 19.03057186126709, Episode   :    233\n",
      "Iteration :  37500, Train reward: 10.158189934335766, Eval reward: -6.198404704772817, TD loss   : 21.755695501565935, Episode   :    233\n",
      "Iteration :  37600, Train reward: 10.368067683348976, Eval reward: -6.198404704772817, TD loss   : 17.71941438138485, Episode   :    234\n",
      "Iteration :  37700, Train reward: 10.368067683348976, Eval reward: -6.198404704772817, TD loss   : 16.26963303923607, Episode   :    234\n",
      "Iteration :  37800, Train reward: 10.368067683348976, Eval reward: -6.198404704772817, TD loss   : 13.619759483337402, Episode   :    234\n",
      "Iteration :  37900, Train reward: 23.87094245560794, Eval reward: -6.198404704772817, TD loss   : 29.766875950098036, Episode   :    235\n",
      "Iteration :  38000, Train reward: 23.87094245560794, Eval reward: -73.74654083192362, TD loss   : 19.80403929233551, Episode   :    235\n",
      "Iteration :  38100, Train reward: 22.19894237709163, Eval reward: -73.74654083192362, TD loss   : 18.27796791791916, Episode   :    236\n",
      "Iteration :  38200, Train reward: 22.19894237709163, Eval reward: -73.74654083192362, TD loss   : 14.275448169708252, Episode   :    236\n",
      "Iteration :  38300, Train reward: 22.19894237709163, Eval reward: -73.74654083192362, TD loss   : 14.093969556093215, Episode   :    236\n",
      "Iteration :  38400, Train reward: 20.287821824460103, Eval reward: -73.74654083192362, TD loss   : 12.933971734046937, Episode   :    237\n",
      "Iteration :  38500, Train reward: 20.287821824460103, Eval reward: 54.729778109377264, TD loss   : 19.278927712440492, Episode   :    237\n",
      "Iteration :  38600, Train reward: 21.029170381818027, Eval reward: 54.729778109377264, TD loss   : 17.56090191960335, Episode   :    238\n",
      "Iteration :  38700, Train reward: 21.029170381818027, Eval reward: 54.729778109377264, TD loss   : 19.431979641914367, Episode   :    238\n",
      "Iteration :  38800, Train reward: 21.029170381818027, Eval reward: 54.729778109377264, TD loss   : 11.020544213056564, Episode   :    238\n",
      "Iteration :  38900, Train reward: 22.300402567824573, Eval reward: 54.729778109377264, TD loss   : 18.504033468961715, Episode   :    239\n",
      "Iteration :  39000, Train reward: 22.300402567824573, Eval reward: 48.52721160032017, TD loss   : 20.40737168312073, Episode   :    239\n",
      "Iteration :  39100, Train reward: 24.456964883032725, Eval reward: 48.52721160032017, TD loss   : 22.18232378959656, Episode   :    240\n",
      "Iteration :  39200, Train reward: 24.456964883032725, Eval reward: 48.52721160032017, TD loss   : 19.103926250934602, Episode   :    240\n",
      "Iteration :  39300, Train reward: 24.456964883032725, Eval reward: 48.52721160032017, TD loss   : 18.020356456041338, Episode   :    240\n",
      "Iteration :  39400, Train reward: 17.806830934979057, Eval reward: 48.52721160032017, TD loss   : 13.949502688646316, Episode   :    242\n",
      "Iteration :  39500, Train reward: 17.806830934979057, Eval reward: 12.045747988873064, TD loss   : 22.10055524587631, Episode   :    242\n",
      "Iteration :  39600, Train reward: 18.39638226454256, Eval reward: 12.045747988873064, TD loss   : 18.289135484695436, Episode   :    243\n",
      "Iteration :  39700, Train reward: 18.39638226454256, Eval reward: 12.045747988873064, TD loss   : 18.794419558048247, Episode   :    243\n",
      "Iteration :  39800, Train reward: 18.39638226454256, Eval reward: 12.045747988873064, TD loss   : 15.27044918179512, Episode   :    243\n",
      "Iteration :  39900, Train reward: 18.890097369705177, Eval reward: 12.045747988873064, TD loss   : 20.827076840400697, Episode   :    244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HasanErdin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\HasanErdin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :      0, Train reward:    nan, Eval reward: -196.66800230314033, TD loss   :    nan, Episode   :      0\n",
      "Iteration :    100, Train reward: -125.40124810674646, Eval reward: -196.66800230314033, TD loss   : 167.2030792236328, Episode   :      2\n",
      "Iteration :    200, Train reward: -178.05581072555273, Eval reward: -196.66800230314033, TD loss   : 131.5978671681881, Episode   :      3\n",
      "Iteration :    300, Train reward: -178.05581072555273, Eval reward: -196.66800230314033, TD loss   : 105.85359104394912, Episode   :      3\n",
      "Iteration :    400, Train reward: -142.6063360493454, Eval reward: -196.66800230314033, TD loss   : 101.78550998210908, Episode   :      4\n",
      "Iteration :    500, Train reward: -173.65778178144356, Eval reward: -310.3616313137457, TD loss   : 131.48034865379333, Episode   :      6\n",
      "Iteration :    600, Train reward: -156.78787523558563, Eval reward: -310.3616313137457, TD loss   : 135.32892698526382, Episode   :      8\n",
      "Iteration :    700, Train reward: -172.03680903126693, Eval reward: -310.3616313137457, TD loss   : 95.01030148029328, Episode   :      9\n",
      "Iteration :    800, Train reward: -166.2622036442498, Eval reward: -310.3616313137457, TD loss   : 110.38709987401963, Episode   :     10\n",
      "Iteration :    900, Train reward: -175.6404877523424, Eval reward: -310.3616313137457, TD loss   : 101.9058842921257, Episode   :     11\n",
      "Iteration :   1000, Train reward: -175.6404877523424, Eval reward: -134.20813386582873, TD loss   : 83.85434786558152, Episode   :     11\n",
      "Iteration :   1100, Train reward: -163.75231764557896, Eval reward: -134.20813386582873, TD loss   : 84.14088485479355, Episode   :     13\n",
      "Iteration :   1200, Train reward: -156.61214208466973, Eval reward: -134.20813386582873, TD loss   : 84.22724656581879, Episode   :     14\n",
      "Iteration :   1300, Train reward: -156.61214208466973, Eval reward: -134.20813386582873, TD loss   : 82.6669591331482, Episode   :     14\n",
      "Iteration :   1400, Train reward: -174.59610071423714, Eval reward: -134.20813386582873, TD loss   : 88.36454733133316, Episode   :     15\n",
      "Iteration :   1500, Train reward: -174.65169963433164, Eval reward: -115.9610114848384, TD loss   : 95.45637042164803, Episode   :     16\n",
      "Iteration :   1600, Train reward: -172.5167162319551, Eval reward: -115.9610114848384, TD loss   : 75.08202648758888, Episode   :     17\n",
      "Iteration :   1700, Train reward: -168.03777148560536, Eval reward: -115.9610114848384, TD loss   : 85.51433880090714, Episode   :     18\n",
      "Iteration :   1800, Train reward: -159.86492788835932, Eval reward: -115.9610114848384, TD loss   : 86.69478010058403, Episode   :     19\n",
      "Iteration :   1900, Train reward: -167.88355175336147, Eval reward: -115.9610114848384, TD loss   : 101.51063462257385, Episode   :     20\n",
      "Iteration :   2000, Train reward: -167.86587952218616, Eval reward: -391.58244252119096, TD loss   : 80.34016108632088, Episode   :     21\n",
      "Iteration :   2100, Train reward: -162.40641935838667, Eval reward: -391.58244252119096, TD loss   : 79.51135570526122, Episode   :     23\n",
      "Iteration :   2200, Train reward: -181.58830350011502, Eval reward: -391.58244252119096, TD loss   : 79.36484837055207, Episode   :     24\n",
      "Iteration :   2300, Train reward: -179.71454476569514, Eval reward: -391.58244252119096, TD loss   : 78.3024943614006, Episode   :     25\n",
      "Iteration :   2400, Train reward: -179.71454476569514, Eval reward: -391.58244252119096, TD loss   : 66.08588950634002, Episode   :     25\n",
      "Iteration :   2500, Train reward: -169.12187436896505, Eval reward: -449.31245341317833, TD loss   : 82.72368389368057, Episode   :     26\n",
      "Iteration :   2600, Train reward: -168.8968243010383, Eval reward: -449.31245341317833, TD loss   : 76.3296617436409, Episode   :     27\n",
      "Iteration :   2700, Train reward: -181.58058638255505, Eval reward: -449.31245341317833, TD loss   : 85.3336551141739, Episode   :     28\n",
      "Iteration :   2800, Train reward: -174.02222069713665, Eval reward: -449.31245341317833, TD loss   : 74.9663134932518, Episode   :     29\n",
      "Iteration :   2900, Train reward: -172.13599724514106, Eval reward: -449.31245341317833, TD loss   : 78.5925305700302, Episode   :     30\n",
      "Iteration :   3000, Train reward: -165.2448229034789, Eval reward: -593.4106544523602, TD loss   : 95.86315242528916, Episode   :     31\n",
      "Iteration :   3100, Train reward: -164.22370564490652, Eval reward: -593.4106544523602, TD loss   : 80.5030795097351, Episode   :     32\n",
      "Iteration :   3200, Train reward: -175.69990921969443, Eval reward: -593.4106544523602, TD loss   : 61.044988787174226, Episode   :     33\n",
      "Iteration :   3300, Train reward: -180.2753846810151, Eval reward: -593.4106544523602, TD loss   : 72.33456543684005, Episode   :     34\n",
      "Iteration :   3400, Train reward: -166.63462042394295, Eval reward: -593.4106544523602, TD loss   : 70.74091224431992, Episode   :     35\n",
      "Iteration :   3500, Train reward: -164.12390871224846, Eval reward: -417.49477171239386, TD loss   : 65.17146146297455, Episode   :     36\n",
      "Iteration :   3600, Train reward: -168.12994765338334, Eval reward: -417.49477171239386, TD loss   : 66.50654994726182, Episode   :     38\n",
      "Iteration :   3700, Train reward: -180.91538614208585, Eval reward: -417.49477171239386, TD loss   : 63.46053333997727, Episode   :     39\n",
      "Iteration :   3800, Train reward: -174.01731620792685, Eval reward: -417.49477171239386, TD loss   : 64.86613705158234, Episode   :     40\n",
      "Iteration :   3900, Train reward: -171.25174960623835, Eval reward: -417.49477171239386, TD loss   : 67.77746401309967, Episode   :     41\n",
      "Iteration :   4000, Train reward: -171.15818611720545, Eval reward: -547.375227763815, TD loss   : 61.8975703907013, Episode   :     42\n",
      "Iteration :   4100, Train reward: -165.22429299217396, Eval reward: -547.375227763815, TD loss   : 55.55517280101776, Episode   :     43\n",
      "Iteration :   4200, Train reward: -146.88310596709493, Eval reward: -547.375227763815, TD loss   : 66.36241893053055, Episode   :     44\n",
      "Iteration :   4300, Train reward: -146.88310596709493, Eval reward: -547.375227763815, TD loss   : 69.35935686349869, Episode   :     44\n",
      "Iteration :   4400, Train reward: -160.27074815686032, Eval reward: -547.375227763815, TD loss   : 56.87536511421204, Episode   :     45\n",
      "Iteration :   4500, Train reward: -181.90665509943616, Eval reward: -269.2800756623979, TD loss   : 67.10118313789367, Episode   :     46\n",
      "Iteration :   4600, Train reward: -183.66759073760636, Eval reward: -269.2800756623979, TD loss   : 71.07622953891754, Episode   :     47\n",
      "Iteration :   4700, Train reward: -171.16667584124926, Eval reward: -269.2800756623979, TD loss   : 54.11449978470802, Episode   :     48\n",
      "Iteration :   4800, Train reward: -164.59026164590176, Eval reward: -269.2800756623979, TD loss   : 62.90062130987644, Episode   :     49\n",
      "Iteration :   4900, Train reward: -164.59026164590176, Eval reward: -269.2800756623979, TD loss   : 64.91194745302201, Episode   :     49\n",
      "Iteration :   5000, Train reward: -175.1635565690364, Eval reward: -277.0890416028382, TD loss   : 63.901295557022095, Episode   :     50\n",
      "Iteration :   5100, Train reward: -174.307887239887, Eval reward: -277.0890416028382, TD loss   : 61.42630531549454, Episode   :     52\n",
      "Iteration :   5200, Train reward: -174.307887239887, Eval reward: -277.0890416028382, TD loss   : 54.22930062532425, Episode   :     52\n",
      "Iteration :   5300, Train reward: -167.997862028908, Eval reward: -277.0890416028382, TD loss   : 59.61263386249542, Episode   :     53\n",
      "Iteration :   5400, Train reward: -161.60212935584798, Eval reward: -277.0890416028382, TD loss   : 50.73863302946091, Episode   :     54\n",
      "Iteration :   5500, Train reward: -159.93674420087302, Eval reward: -398.5188872466691, TD loss   : 57.94344749808312, Episode   :     55\n",
      "Iteration :   5600, Train reward: -159.09007425527892, Eval reward: -398.5188872466691, TD loss   : 51.16810750961304, Episode   :     56\n",
      "Iteration :   5700, Train reward: -154.40411132119462, Eval reward: -398.5188872466691, TD loss   : 49.20070918679237, Episode   :     57\n",
      "Iteration :   5800, Train reward: -149.15355721122899, Eval reward: -398.5188872466691, TD loss   : 75.8668222618103, Episode   :     58\n",
      "Iteration :   5900, Train reward: -137.5201679241645, Eval reward: -398.5188872466691, TD loss   : 58.4894015276432, Episode   :     59\n",
      "Iteration :   6000, Train reward: -137.5201679241645, Eval reward: -417.0271630170344, TD loss   : 65.06928943395614, Episode   :     59\n",
      "Iteration :   6100, Train reward: -136.33914026586467, Eval reward: -417.0271630170344, TD loss   : 48.830828374624254, Episode   :     60\n",
      "Iteration :   6200, Train reward: -140.56614431923904, Eval reward: -417.0271630170344, TD loss   : 38.284627180099484, Episode   :     61\n",
      "Iteration :   6300, Train reward: -141.35193748119042, Eval reward: -417.0271630170344, TD loss   : 52.08598890542984, Episode   :     62\n",
      "Iteration :   6400, Train reward: -152.0008117565626, Eval reward: -417.0271630170344, TD loss   : 49.58946847558022, Episode   :     63\n",
      "Iteration :   6500, Train reward: -152.0008117565626, Eval reward: -326.00224775530666, TD loss   : 46.43803658366203, Episode   :     63\n",
      "Iteration :   6600, Train reward: -155.17326236144797, Eval reward: -326.00224775530666, TD loss   : 60.33005996704102, Episode   :     64\n",
      "Iteration :   6700, Train reward: -141.38370219060837, Eval reward: -326.00224775530666, TD loss   : 44.83594007611275, Episode   :     65\n",
      "Iteration :   6800, Train reward: -115.38043047920182, Eval reward: -326.00224775530666, TD loss   : 42.774882731437685, Episode   :     66\n",
      "Iteration :   6900, Train reward: -115.38043047920182, Eval reward: -326.00224775530666, TD loss   : 47.79558624863625, Episode   :     66\n",
      "Iteration :   7000, Train reward: -116.09239059683519, Eval reward: -398.5100091280127, TD loss   : 48.910990973711016, Episode   :     67\n",
      "Iteration :   7100, Train reward: -114.62443848121896, Eval reward: -398.5100091280127, TD loss   : 53.67114647388458, Episode   :     68\n",
      "Iteration :   7200, Train reward: -117.74645693108076, Eval reward: -398.5100091280127, TD loss   : 27.78916470527649, Episode   :     69\n",
      "Iteration :   7300, Train reward: -117.74645693108076, Eval reward: -398.5100091280127, TD loss   : 41.34617530822754, Episode   :     69\n",
      "Iteration :   7400, Train reward: -106.06611996049796, Eval reward: -398.5100091280127, TD loss   : 47.21944661736488, Episode   :     70\n",
      "Iteration :   7500, Train reward: -104.52682227674526, Eval reward: -334.82647465318223, TD loss   : 41.47068037629128, Episode   :     71\n",
      "Iteration :   7600, Train reward: -105.63612857401195, Eval reward: -334.82647465318223, TD loss   : 34.192024161815645, Episode   :     72\n",
      "Iteration :   7700, Train reward: -105.63612857401195, Eval reward: -334.82647465318223, TD loss   : 44.31708352804184, Episode   :     72\n",
      "Iteration :   7800, Train reward: -100.25521860934548, Eval reward: -334.82647465318223, TD loss   : 51.45129349112511, Episode   :     73\n",
      "Iteration :   7900, Train reward: -100.25521860934548, Eval reward: -334.82647465318223, TD loss   : 42.457091645002365, Episode   :     73\n",
      "Iteration :   8000, Train reward: -103.73735057868574, Eval reward: -32.995747971465924, TD loss   : 37.617681213617324, Episode   :     74\n",
      "Iteration :   8100, Train reward: -97.15886522920175, Eval reward: -32.995747971465924, TD loss   : 50.1213317990303, Episode   :     75\n",
      "Iteration :   8200, Train reward: -95.52041788210934, Eval reward: -32.995747971465924, TD loss   : 30.226826754808425, Episode   :     76\n",
      "Iteration :   8300, Train reward: -95.52041788210934, Eval reward: -32.995747971465924, TD loss   : 48.78007471442223, Episode   :     76\n",
      "Iteration :   8400, Train reward: -99.15156171034344, Eval reward: -32.995747971465924, TD loss   : 28.66981069087982, Episode   :     77\n",
      "Iteration :   8500, Train reward: -100.49191122713147, Eval reward: -104.84029260191635, TD loss   : 28.815515211820603, Episode   :     78\n",
      "Iteration :   8600, Train reward: -97.92621131960384, Eval reward: -104.84029260191635, TD loss   : 35.47147827863693, Episode   :     80\n",
      "Iteration :   8700, Train reward: -97.92621131960384, Eval reward: -104.84029260191635, TD loss   : 35.99215553402901, Episode   :     80\n",
      "Iteration :   8800, Train reward: -95.32889453099602, Eval reward: -104.84029260191635, TD loss   : 45.50625222563744, Episode   :     81\n",
      "Iteration :   8900, Train reward: -92.24260234702292, Eval reward: -104.84029260191635, TD loss   : 36.88847143411636, Episode   :     82\n",
      "Iteration :   9000, Train reward: -79.99333038466929, Eval reward: -278.7372084953408, TD loss   : 44.66577063918114, Episode   :     83\n",
      "Iteration :   9100, Train reward: -79.24650787057877, Eval reward: -278.7372084953408, TD loss   : 49.12926931142807, Episode   :     84\n",
      "Iteration :   9200, Train reward: -79.24650787057877, Eval reward: -278.7372084953408, TD loss   : 37.05908371329308, Episode   :     84\n",
      "Iteration :   9300, Train reward: -75.77962724476001, Eval reward: -278.7372084953408, TD loss   : 51.01388911128044, Episode   :     85\n",
      "Iteration :   9400, Train reward: -75.77962724476001, Eval reward: -278.7372084953408, TD loss   : 41.93287496685982, Episode   :     85\n",
      "Iteration :   9500, Train reward: -83.8890468688986, Eval reward: -105.91640489033004, TD loss   : 44.02109922766685, Episode   :     86\n",
      "Iteration :   9600, Train reward: -76.36802433219636, Eval reward: -105.91640489033004, TD loss   : 37.622800661325456, Episode   :     87\n",
      "Iteration :   9700, Train reward: -76.36802433219636, Eval reward: -105.91640489033004, TD loss   : 46.89563330888748, Episode   :     87\n",
      "Iteration :   9800, Train reward: -77.47900187190042, Eval reward: -105.91640489033004, TD loss   : 47.07761696457863, Episode   :     88\n",
      "Iteration :   9900, Train reward: -77.47900187190042, Eval reward: -105.91640489033004, TD loss   : 41.29059322714806, Episode   :     88\n",
      "Iteration :  10000, Train reward: -80.04919777859507, Eval reward: -144.7912527171456, TD loss   : 25.707006485462188, Episode   :     89\n",
      "Iteration :  10100, Train reward: -76.66209420460649, Eval reward: -144.7912527171456, TD loss   : 31.491832512617112, Episode   :     90\n",
      "Iteration :  10200, Train reward: -74.56136236658317, Eval reward: -144.7912527171456, TD loss   : 39.95823463439942, Episode   :     91\n",
      "Iteration :  10300, Train reward: -74.56136236658317, Eval reward: -144.7912527171456, TD loss   : 32.58070841431618, Episode   :     91\n",
      "Iteration :  10400, Train reward: -71.34108306076841, Eval reward: -144.7912527171456, TD loss   : 35.965031046867374, Episode   :     92\n",
      "Iteration :  10500, Train reward: -71.34108306076841, Eval reward: -69.39269816492956, TD loss   : 39.92488825798035, Episode   :     92\n",
      "Iteration :  10600, Train reward: -65.25520177368915, Eval reward: -69.39269816492956, TD loss   : 34.481204442977905, Episode   :     94\n",
      "Iteration :  10700, Train reward: -65.25520177368915, Eval reward: -69.39269816492956, TD loss   : 33.589693958759305, Episode   :     94\n",
      "Iteration :  10800, Train reward: -73.53563371255719, Eval reward: -69.39269816492956, TD loss   : 30.910560508966444, Episode   :     95\n",
      "Iteration :  10900, Train reward: -73.53563371255719, Eval reward: -69.39269816492956, TD loss   : 31.623728220462798, Episode   :     95\n",
      "Iteration :  11000, Train reward: -73.53563371255719, Eval reward: -97.91280079653399, TD loss   : 32.82084493041039, Episode   :     95\n",
      "Iteration :  11100, Train reward: -72.53477295013757, Eval reward: -97.91280079653399, TD loss   : 26.996402708292006, Episode   :     96\n",
      "Iteration :  11200, Train reward: -70.83407919066923, Eval reward: -97.91280079653399, TD loss   : 38.92012006044388, Episode   :     97\n",
      "Iteration :  11300, Train reward: -70.83407919066923, Eval reward: -97.91280079653399, TD loss   : 43.227527010440824, Episode   :     97\n",
      "Iteration :  11400, Train reward: -69.98205044352223, Eval reward: -97.91280079653399, TD loss   : 35.09077722430229, Episode   :     98\n",
      "Iteration :  11500, Train reward: -69.98205044352223, Eval reward: -62.73166920788507, TD loss   : 32.58372219324112, Episode   :     98\n",
      "Iteration :  11600, Train reward: -70.79940537422358, Eval reward: -62.73166920788507, TD loss   : 24.470041428804397, Episode   :     99\n",
      "Iteration :  11700, Train reward: -70.79940537422358, Eval reward: -62.73166920788507, TD loss   : 39.158223835229876, Episode   :     99\n",
      "Iteration :  11800, Train reward: -69.08898773370976, Eval reward: -62.73166920788507, TD loss   : 34.47932104229927, Episode   :    100\n",
      "Iteration :  11900, Train reward: -69.08898773370976, Eval reward: -62.73166920788507, TD loss   : 26.646608585119246, Episode   :    100\n",
      "Iteration :  12000, Train reward: -72.03323573978709, Eval reward: -41.860043149223245, TD loss   : 25.265394197702406, Episode   :    101\n",
      "Iteration :  12100, Train reward: -69.2279366603738, Eval reward: -41.860043149223245, TD loss   : 25.841813019514085, Episode   :    102\n",
      "Iteration :  12200, Train reward: -69.2279366603738, Eval reward: -41.860043149223245, TD loss   : 28.404516632556916, Episode   :    102\n",
      "Iteration :  12300, Train reward: -64.64845147507222, Eval reward: -41.860043149223245, TD loss   : 29.156557272672654, Episode   :    103\n",
      "Iteration :  12400, Train reward: -64.64845147507222, Eval reward: -41.860043149223245, TD loss   : 20.336666663885115, Episode   :    103\n",
      "Iteration :  12500, Train reward: -64.64845147507222, Eval reward: -127.00833411739104, TD loss   : 34.17689061284065, Episode   :    103\n",
      "Iteration :  12600, Train reward: -64.1919254520599, Eval reward: -127.00833411739104, TD loss   : 52.43610369920731, Episode   :    104\n",
      "Iteration :  12700, Train reward: -64.1919254520599, Eval reward: -127.00833411739104, TD loss   : 38.853157159090046, Episode   :    104\n",
      "Iteration :  12800, Train reward: -64.1919254520599, Eval reward: -127.00833411739104, TD loss   : 37.4788101196289, Episode   :    104\n",
      "Iteration :  12900, Train reward: -68.04383808539994, Eval reward: -127.00833411739104, TD loss   : 37.491015467643734, Episode   :    105\n",
      "Iteration :  13000, Train reward: -66.03532638306488, Eval reward: 21.7193632418655, TD loss   : 25.886702089309694, Episode   :    106\n",
      "Iteration :  13100, Train reward: -70.26023180138034, Eval reward: 21.7193632418655, TD loss   : 31.008513090610503, Episode   :    107\n",
      "Iteration :  13200, Train reward: -70.26023180138034, Eval reward: 21.7193632418655, TD loss   : 38.57417352318764, Episode   :    107\n",
      "Iteration :  13300, Train reward: -66.3029942111312, Eval reward: 21.7193632418655, TD loss   : 35.58123911499977, Episode   :    108\n",
      "Iteration :  13400, Train reward: -66.3029942111312, Eval reward: 21.7193632418655, TD loss   : 25.004679987430574, Episode   :    108\n",
      "Iteration :  13500, Train reward: -64.57576824008505, Eval reward: -2.546102909371366, TD loss   : 24.594510930776597, Episode   :    109\n",
      "Iteration :  13600, Train reward: -71.04105469818208, Eval reward: -2.546102909371366, TD loss   : 20.29479896605015, Episode   :    110\n",
      "Iteration :  13700, Train reward: -71.56850222805703, Eval reward: -2.546102909371366, TD loss   : 28.129964792728423, Episode   :    111\n",
      "Iteration :  13800, Train reward: -71.99129683184422, Eval reward: -2.546102909371366, TD loss   : 28.01987367272377, Episode   :    112\n",
      "Iteration :  13900, Train reward: -71.99129683184422, Eval reward: -2.546102909371366, TD loss   : 28.060944825410843, Episode   :    112\n",
      "Iteration :  14000, Train reward: -71.99129683184422, Eval reward: -36.697542962633726, TD loss   : 29.495396419763566, Episode   :    112\n",
      "Iteration :  14100, Train reward: -68.78318914975799, Eval reward: -36.697542962633726, TD loss   : 39.22867253541946, Episode   :    113\n",
      "Iteration :  14200, Train reward: -68.78318914975799, Eval reward: -36.697542962633726, TD loss   : 42.336709657907484, Episode   :    113\n",
      "Iteration :  14300, Train reward: -69.7947920192158, Eval reward: -36.697542962633726, TD loss   : 31.919287140369416, Episode   :    114\n",
      "Iteration :  14400, Train reward: -69.7947920192158, Eval reward: -36.697542962633726, TD loss   : 20.302408978939056, Episode   :    114\n",
      "Iteration :  14500, Train reward: -69.7947920192158, Eval reward: 4.187327126448646, TD loss   : 28.692428240776064, Episode   :    114\n",
      "Iteration :  14600, Train reward: -60.91340104875862, Eval reward: 4.187327126448646, TD loss   : 37.400960776805874, Episode   :    115\n",
      "Iteration :  14700, Train reward: -60.91340104875862, Eval reward: 4.187327126448646, TD loss   : 31.97154641866684, Episode   :    115\n",
      "Iteration :  14800, Train reward: -60.91340104875862, Eval reward: 4.187327126448646, TD loss   : 22.926099557876586, Episode   :    115\n",
      "Iteration :  14900, Train reward: -56.419746193523295, Eval reward: 4.187327126448646, TD loss   : 24.699807707071304, Episode   :    116\n",
      "Iteration :  15000, Train reward: -49.558846388617134, Eval reward: 65.44916097967773, TD loss   : 25.878405715227128, Episode   :    117\n",
      "Iteration :  15100, Train reward: -44.762817093190286, Eval reward: 65.44916097967773, TD loss   : 30.66379159450531, Episode   :    118\n",
      "Iteration :  15200, Train reward: -41.469448231569345, Eval reward: 65.44916097967773, TD loss   : 27.036437145471574, Episode   :    119\n",
      "Iteration :  15300, Train reward: -49.50954451107434, Eval reward: 65.44916097967773, TD loss   : 34.55538163423538, Episode   :    120\n",
      "Iteration :  15400, Train reward: -49.50954451107434, Eval reward: 65.44916097967773, TD loss   : 24.763164150714875, Episode   :    120\n",
      "Iteration :  15500, Train reward: -49.50954451107434, Eval reward: -1.8589971298821943, TD loss   : 24.742047678232193, Episode   :    120\n",
      "Iteration :  15600, Train reward: -41.17426878316348, Eval reward: -1.8589971298821943, TD loss   : 17.666960492134095, Episode   :    121\n",
      "Iteration :  15700, Train reward: -41.17426878316348, Eval reward: -1.8589971298821943, TD loss   : 33.713063188791274, Episode   :    121\n",
      "Iteration :  15800, Train reward: -41.17426878316348, Eval reward: -1.8589971298821943, TD loss   : 29.213624428510666, Episode   :    121\n",
      "Iteration :  15900, Train reward: -38.37190957309416, Eval reward: -1.8589971298821943, TD loss   : 31.801287001371385, Episode   :    122\n",
      "Iteration :  16000, Train reward: -38.37190957309416, Eval reward: 24.350480188889186, TD loss   : 17.37763311624527, Episode   :    122\n",
      "Iteration :  16100, Train reward: -38.83955119457671, Eval reward: 24.350480188889186, TD loss   : 21.700574262142183, Episode   :    123\n",
      "Iteration :  16200, Train reward: -34.839749443896515, Eval reward: 24.350480188889186, TD loss   : 21.806018199920654, Episode   :    124\n",
      "Iteration :  16300, Train reward: -34.839749443896515, Eval reward: 24.350480188889186, TD loss   : 31.841152364015578, Episode   :    124\n",
      "Iteration :  16400, Train reward: -34.839749443896515, Eval reward: 24.350480188889186, TD loss   : 32.15457219362259, Episode   :    124\n",
      "Iteration :  16500, Train reward: -28.80416691750555, Eval reward: 23.85891221850229, TD loss   : 20.015943006277084, Episode   :    125\n",
      "Iteration :  16600, Train reward: -22.349379590820803, Eval reward: 23.85891221850229, TD loss   : 24.03788735985756, Episode   :    126\n",
      "Iteration :  16700, Train reward: -22.349379590820803, Eval reward: 23.85891221850229, TD loss   : 21.92383019447327, Episode   :    126\n",
      "Iteration :  16800, Train reward: -18.518675833623497, Eval reward: 23.85891221850229, TD loss   : 25.208891332149506, Episode   :    127\n",
      "Iteration :  16900, Train reward: -18.518675833623497, Eval reward: 23.85891221850229, TD loss   : 25.949328360557555, Episode   :    127\n",
      "Iteration :  17000, Train reward: -18.518675833623497, Eval reward: 16.269783620019716, TD loss   : 27.824543560743333, Episode   :    127\n",
      "Iteration :  17100, Train reward: -12.600282901094607, Eval reward: 16.269783620019716, TD loss   : 28.04704380989075, Episode   :    128\n",
      "Iteration :  17200, Train reward: -12.600282901094607, Eval reward: 16.269783620019716, TD loss   : 23.78674144268036, Episode   :    128\n",
      "Iteration :  17300, Train reward: -12.600282901094607, Eval reward: 16.269783620019716, TD loss   : 20.705323193073273, Episode   :    128\n",
      "Iteration :  17400, Train reward: -5.009661676787436, Eval reward: 16.269783620019716, TD loss   : 36.27704621195793, Episode   :    129\n",
      "Iteration :  17500, Train reward: -5.009661676787436, Eval reward: -25.50419114136843, TD loss   : 28.597514268159866, Episode   :    129\n",
      "Iteration :  17600, Train reward: 5.151009739467266, Eval reward: -25.50419114136843, TD loss   : 37.1281445646286, Episode   :    130\n",
      "Iteration :  17700, Train reward: 5.151009739467266, Eval reward: -25.50419114136843, TD loss   : 23.08197292327881, Episode   :    130\n",
      "Iteration :  17800, Train reward: 5.151009739467266, Eval reward: -25.50419114136843, TD loss   : 25.32087407231331, Episode   :    130\n",
      "Iteration :  17900, Train reward: 12.629767334779393, Eval reward: -25.50419114136843, TD loss   : 15.189069172143936, Episode   :    131\n",
      "Iteration :  18000, Train reward: 18.83096922361797, Eval reward: 36.06677393043127, TD loss   : 28.204412902593614, Episode   :    132\n",
      "Iteration :  18100, Train reward: 15.843560516174051, Eval reward: 36.06677393043127, TD loss   : 28.816031692028044, Episode   :    133\n",
      "Iteration :  18200, Train reward: 15.843560516174051, Eval reward: 36.06677393043127, TD loss   : 20.09233628034592, Episode   :    133\n",
      "Iteration :  18300, Train reward: 15.843560516174051, Eval reward: 36.06677393043127, TD loss   : 35.30570412993431, Episode   :    133\n",
      "Iteration :  18400, Train reward: 19.93691820344778, Eval reward: 36.06677393043127, TD loss   : 22.909582266807558, Episode   :    134\n",
      "Iteration :  18500, Train reward: 16.623049787715697, Eval reward: 6.246740161595441, TD loss   : 21.242558829784393, Episode   :    135\n",
      "Iteration :  18600, Train reward: 15.376833304695348, Eval reward: 6.246740161595441, TD loss   : 26.199542257785797, Episode   :    136\n",
      "Iteration :  18700, Train reward: 15.376833304695348, Eval reward: 6.246740161595441, TD loss   : 16.851032292246817, Episode   :    136\n",
      "Iteration :  18800, Train reward: 15.376833304695348, Eval reward: 6.246740161595441, TD loss   : 28.06118560433388, Episode   :    136\n",
      "Iteration :  18900, Train reward: 13.731945023692413, Eval reward: 6.246740161595441, TD loss   : 17.306255799531936, Episode   :    137\n",
      "Iteration :  19000, Train reward: 13.731945023692413, Eval reward: -6.074990077090061, TD loss   : 14.482476732730866, Episode   :    137\n",
      "Iteration :  19100, Train reward: 14.375084508572655, Eval reward: -6.074990077090061, TD loss   : 11.858015648126603, Episode   :    138\n",
      "Iteration :  19200, Train reward: 14.375084508572655, Eval reward: -6.074990077090061, TD loss   : 29.93857944726944, Episode   :    138\n",
      "Iteration :  19300, Train reward: 14.375084508572655, Eval reward: -6.074990077090061, TD loss   : 22.255820208787917, Episode   :    138\n",
      "Iteration :  19400, Train reward: 21.518278322782812, Eval reward: -6.074990077090061, TD loss   : 18.753301624059677, Episode   :    139\n",
      "Iteration :  19500, Train reward: 21.518278322782812, Eval reward: -94.72425836377354, TD loss   : 21.218549854159356, Episode   :    139\n",
      "Iteration :  19600, Train reward: 33.78282728806177, Eval reward: -94.72425836377354, TD loss   : 31.597562611103058, Episode   :    140\n",
      "Iteration :  19700, Train reward: 33.78282728806177, Eval reward: -94.72425836377354, TD loss   : 26.748246141672134, Episode   :    140\n",
      "Iteration :  19800, Train reward: 33.78282728806177, Eval reward: -94.72425836377354, TD loss   : 21.97302840590477, Episode   :    140\n",
      "Iteration :  19900, Train reward: 35.2505009991602, Eval reward: -94.72425836377354, TD loss   : 30.658996003866196, Episode   :    141\n",
      "Iteration :  20000, Train reward: 35.2505009991602, Eval reward: 22.30764217267508, TD loss   : 21.63108862876892, Episode   :    141\n",
      "Iteration :  20100, Train reward: 35.89025940601199, Eval reward: 22.30764217267508, TD loss   : 22.303868973255156, Episode   :    142\n",
      "Iteration :  20200, Train reward: 35.89025940601199, Eval reward: 22.30764217267508, TD loss   : 21.790005658864974, Episode   :    142\n",
      "Iteration :  20300, Train reward: 35.89025940601199, Eval reward: 22.30764217267508, TD loss   : 22.7165371799469, Episode   :    142\n",
      "Iteration :  20400, Train reward: 35.9211680850395, Eval reward: 22.30764217267508, TD loss   : 15.858378406763077, Episode   :    143\n",
      "Iteration :  20500, Train reward: 35.9211680850395, Eval reward: 50.59917979404845, TD loss   : 27.784721122980116, Episode   :    143\n",
      "Iteration :  20600, Train reward: 39.69991523029115, Eval reward: 50.59917979404845, TD loss   : 25.378294769525528, Episode   :    144\n",
      "Iteration :  20700, Train reward: 39.69991523029115, Eval reward: 50.59917979404845, TD loss   : 15.980222229957581, Episode   :    144\n",
      "Iteration :  20800, Train reward: 39.69991523029115, Eval reward: 50.59917979404845, TD loss   : 20.448426376581192, Episode   :    144\n",
      "Iteration :  20900, Train reward: 40.21170255810481, Eval reward: 50.59917979404845, TD loss   : 24.353256857395174, Episode   :    145\n",
      "Iteration :  21000, Train reward: 41.89172878561518, Eval reward: -21.139246219138393, TD loss   : 28.20567035794258, Episode   :    146\n",
      "Iteration :  21100, Train reward: 42.71544046159679, Eval reward: -21.139246219138393, TD loss   : 21.281271287202834, Episode   :    147\n",
      "Iteration :  21200, Train reward: 42.71544046159679, Eval reward: -21.139246219138393, TD loss   : 18.79625957250595, Episode   :    147\n",
      "Iteration :  21300, Train reward: 42.71544046159679, Eval reward: -21.139246219138393, TD loss   : 24.842807003259658, Episode   :    147\n",
      "Iteration :  21400, Train reward: 39.45211359137708, Eval reward: -21.139246219138393, TD loss   : 21.92964027762413, Episode   :    148\n",
      "Iteration :  21500, Train reward: 39.45211359137708, Eval reward: 32.948224874335345, TD loss   : 27.346637917757036, Episode   :    148\n",
      "Iteration :  21600, Train reward: 40.90807932460922, Eval reward: 32.948224874335345, TD loss   : 20.159556370973586, Episode   :    149\n",
      "Iteration :  21700, Train reward: 40.90807932460922, Eval reward: 32.948224874335345, TD loss   : 21.81676914215088, Episode   :    149\n",
      "Iteration :  21800, Train reward: 9.695539572385945, Eval reward: 32.948224874335345, TD loss   : 18.71962699174881, Episode   :    150\n",
      "Iteration :  21900, Train reward: 9.695539572385945, Eval reward: 32.948224874335345, TD loss   : 22.76807638168335, Episode   :    150\n",
      "Iteration :  22000, Train reward: 9.695539572385945, Eval reward: 13.994988140913046, TD loss   : 26.36179824113846, Episode   :    150\n",
      "Iteration :  22100, Train reward: 9.769687281116465, Eval reward: 13.994988140913046, TD loss   : 18.344955912828446, Episode   :    151\n",
      "Iteration :  22200, Train reward: 9.769687281116465, Eval reward: 13.994988140913046, TD loss   : 20.757461194992064, Episode   :    151\n",
      "Iteration :  22300, Train reward: 9.769687281116465, Eval reward: 13.994988140913046, TD loss   : 21.340798052549363, Episode   :    151\n",
      "Iteration :  22400, Train reward: 9.695863445094961, Eval reward: 13.994988140913046, TD loss   : 23.297695170640946, Episode   :    152\n",
      "Iteration :  22500, Train reward: 9.695863445094961, Eval reward: 32.483147658694975, TD loss   : 19.283191002607346, Episode   :    152\n",
      "Iteration :  22600, Train reward: 11.849992731600082, Eval reward: 32.483147658694975, TD loss   : 23.288910073041915, Episode   :    153\n",
      "Iteration :  22700, Train reward: 11.849992731600082, Eval reward: 32.483147658694975, TD loss   : 20.69819116950035, Episode   :    153\n",
      "Iteration :  22800, Train reward: 11.849992731600082, Eval reward: 32.483147658694975, TD loss   : 24.077688558101656, Episode   :    153\n",
      "Iteration :  22900, Train reward: 12.61019709809636, Eval reward: 32.483147658694975, TD loss   : 23.107941596508027, Episode   :    154\n",
      "Iteration :  23000, Train reward: 12.61019709809636, Eval reward: 12.828216350353696, TD loss   : 17.974453721046448, Episode   :    154\n",
      "Iteration :  23100, Train reward: 14.352388479093829, Eval reward: 12.828216350353696, TD loss   : 11.646804322004318, Episode   :    155\n",
      "Iteration :  23200, Train reward: 14.352388479093829, Eval reward: 12.828216350353696, TD loss   : 20.578254685401916, Episode   :    155\n",
      "Iteration :  23300, Train reward: 14.352388479093829, Eval reward: 12.828216350353696, TD loss   : 19.3345030772686, Episode   :    155\n",
      "Iteration :  23400, Train reward: 17.690107522428594, Eval reward: 12.828216350353696, TD loss   : 12.854357134103775, Episode   :    156\n",
      "Iteration :  23500, Train reward: 17.690107522428594, Eval reward: 6.361834426963336, TD loss   : 28.927175440788268, Episode   :    156\n",
      "Iteration :  23600, Train reward: 12.651625314198972, Eval reward: 6.361834426963336, TD loss   : 23.644191348552702, Episode   :    157\n",
      "Iteration :  23700, Train reward: 12.651625314198972, Eval reward: 6.361834426963336, TD loss   : 11.759988323450088, Episode   :    157\n",
      "Iteration :  23800, Train reward: 12.651625314198972, Eval reward: 6.361834426963336, TD loss   : 20.07453359246254, Episode   :    157\n",
      "Iteration :  23900, Train reward: 15.260227352929249, Eval reward: 6.361834426963336, TD loss   : 19.39769674539566, Episode   :    158\n",
      "Iteration :  24000, Train reward: 15.260227352929249, Eval reward: -5.357503252363779, TD loss   : 16.309158716201782, Episode   :    158\n",
      "Iteration :  24100, Train reward: 15.689834067076145, Eval reward: -5.357503252363779, TD loss   : 24.13966959118843, Episode   :    159\n",
      "Iteration :  24200, Train reward: 15.689834067076145, Eval reward: -5.357503252363779, TD loss   : 18.72316731452942, Episode   :    159\n",
      "Iteration :  24300, Train reward: 15.689834067076145, Eval reward: -5.357503252363779, TD loss   : 21.987553544044495, Episode   :    159\n",
      "Iteration :  24400, Train reward: 12.593091162986797, Eval reward: -5.357503252363779, TD loss   : 15.457545113563537, Episode   :    160\n",
      "Iteration :  24500, Train reward: 12.593091162986797, Eval reward: 44.57772459485342, TD loss   : 17.09850107908249, Episode   :    160\n",
      "Iteration :  24600, Train reward: 10.687614678632645, Eval reward: 44.57772459485342, TD loss   : 18.940069414377213, Episode   :    161\n",
      "Iteration :  24700, Train reward: 10.687614678632645, Eval reward: 44.57772459485342, TD loss   : 22.83850921213627, Episode   :    161\n",
      "Iteration :  24800, Train reward: 10.687614678632645, Eval reward: 44.57772459485342, TD loss   : 16.5114095389843, Episode   :    161\n",
      "Iteration :  24900, Train reward: 10.07861151888227, Eval reward: 44.57772459485342, TD loss   : 20.989033386707305, Episode   :    162\n",
      "Iteration :  25000, Train reward: 10.07861151888227, Eval reward: 26.167634426137187, TD loss   : 11.873684014081954, Episode   :    162\n",
      "Iteration :  25100, Train reward: 12.287483089427667, Eval reward: 26.167634426137187, TD loss   : 19.827229849100114, Episode   :    163\n",
      "Iteration :  25200, Train reward: 12.287483089427667, Eval reward: 26.167634426137187, TD loss   : 21.506544358730316, Episode   :    163\n",
      "Iteration :  25300, Train reward: 12.287483089427667, Eval reward: 26.167634426137187, TD loss   : 15.033575396537781, Episode   :    163\n",
      "Iteration :  25400, Train reward: 9.943615520913315, Eval reward: 26.167634426137187, TD loss   : 12.921785844564438, Episode   :    164\n",
      "Iteration :  25500, Train reward: 9.943615520913315, Eval reward: -22.11832093189386, TD loss   : 16.59048922896385, Episode   :    164\n",
      "Iteration :  25600, Train reward: 8.760937557254723, Eval reward: -22.11832093189386, TD loss   : 15.163174376487731, Episode   :    165\n",
      "Iteration :  25700, Train reward: 8.760937557254723, Eval reward: -22.11832093189386, TD loss   : 23.23473225235939, Episode   :    165\n",
      "Iteration :  25800, Train reward: 8.760937557254723, Eval reward: -22.11832093189386, TD loss   : 18.799220620393754, Episode   :    165\n",
      "Iteration :  25900, Train reward: 10.321963565763264, Eval reward: -22.11832093189386, TD loss   : 26.56920176625252, Episode   :    166\n",
      "Iteration :  26000, Train reward: 10.321963565763264, Eval reward: -4.65601578534465, TD loss   : 21.472399929761888, Episode   :    166\n",
      "Iteration :  26100, Train reward: 10.760121020811559, Eval reward: -4.65601578534465, TD loss   : 23.08193397283554, Episode   :    167\n",
      "Iteration :  26200, Train reward: 10.760121020811559, Eval reward: -4.65601578534465, TD loss   : 26.701409467458724, Episode   :    167\n",
      "Iteration :  26300, Train reward: 10.760121020811559, Eval reward: -4.65601578534465, TD loss   : 29.68827707886696, Episode   :    167\n",
      "Iteration :  26400, Train reward: 10.67239072692757, Eval reward: -4.65601578534465, TD loss   : 12.177198717594147, Episode   :    168\n",
      "Iteration :  26500, Train reward: 10.67239072692757, Eval reward: 28.735546533721152, TD loss   : 17.085110907554625, Episode   :    168\n",
      "Iteration :  26600, Train reward: 10.21308296944215, Eval reward: 28.735546533721152, TD loss   : 21.241483386158944, Episode   :    169\n",
      "Iteration :  26700, Train reward: 10.21308296944215, Eval reward: 28.735546533721152, TD loss   : 13.067527965307235, Episode   :    169\n",
      "Iteration :  26800, Train reward: 10.21308296944215, Eval reward: 28.735546533721152, TD loss   : 24.8596239566803, Episode   :    169\n",
      "Iteration :  26900, Train reward: 37.58800999811719, Eval reward: 28.735546533721152, TD loss   : 18.087546031475068, Episode   :    170\n",
      "Iteration :  27000, Train reward: 37.58800999811719, Eval reward: -14.453659476310118, TD loss   : 13.889146316051484, Episode   :    170\n",
      "Iteration :  27100, Train reward: 36.877457094666326, Eval reward: -14.453659476310118, TD loss   : 14.020367686748505, Episode   :    171\n",
      "Iteration :  27200, Train reward: 36.877457094666326, Eval reward: -14.453659476310118, TD loss   : 14.5600113594532, Episode   :    171\n",
      "Iteration :  27300, Train reward: 30.451791997029297, Eval reward: -14.453659476310118, TD loss   : 20.845633115768432, Episode   :    172\n",
      "Iteration :  27400, Train reward: 30.451791997029297, Eval reward: -14.453659476310118, TD loss   : 18.693364442586898, Episode   :    172\n",
      "Iteration :  27500, Train reward: 30.451791997029297, Eval reward: 12.762706528655002, TD loss   : 18.956070255041123, Episode   :    172\n",
      "Iteration :  27600, Train reward: 28.346763622287533, Eval reward: 12.762706528655002, TD loss   : 16.49023386120796, Episode   :    173\n",
      "Iteration :  27700, Train reward: 28.346763622287533, Eval reward: 12.762706528655002, TD loss   : 17.124523985385895, Episode   :    173\n",
      "Iteration :  27800, Train reward: 28.346763622287533, Eval reward: 12.762706528655002, TD loss   : 11.751867620944976, Episode   :    173\n",
      "Iteration :  27900, Train reward: 27.585609780585692, Eval reward: 12.762706528655002, TD loss   : 10.326321914196015, Episode   :    174\n",
      "Iteration :  28000, Train reward: 27.585609780585692, Eval reward: 50.849677904615966, TD loss   : 19.692229678630827, Episode   :    174\n",
      "Iteration :  28100, Train reward: 29.551195043255753, Eval reward: 50.849677904615966, TD loss   : 25.080032840967178, Episode   :    175\n",
      "Iteration :  28200, Train reward: 29.551195043255753, Eval reward: 50.849677904615966, TD loss   : 14.663482258319855, Episode   :    175\n",
      "Iteration :  28300, Train reward: 20.78305669872711, Eval reward: 50.849677904615966, TD loss   : 20.19431660056114, Episode   :    176\n",
      "Iteration :  28400, Train reward: 20.78305669872711, Eval reward: 50.849677904615966, TD loss   : 19.621483235359193, Episode   :    176\n",
      "Iteration :  28500, Train reward: 20.78305669872711, Eval reward: -59.92062748115635, TD loss   : 24.46510098695755, Episode   :    176\n",
      "Iteration :  28600, Train reward: 27.08500096008579, Eval reward: -59.92062748115635, TD loss   : 19.234023138284684, Episode   :    177\n",
      "Iteration :  28700, Train reward: 27.08500096008579, Eval reward: -59.92062748115635, TD loss   : 14.783440082669259, Episode   :    177\n",
      "Iteration :  28800, Train reward: 27.08500096008579, Eval reward: -59.92062748115635, TD loss   : 26.365702077150345, Episode   :    177\n",
      "Iteration :  28900, Train reward: 25.87792827383035, Eval reward: -59.92062748115635, TD loss   : 20.197819573879244, Episode   :    178\n",
      "Iteration :  29000, Train reward: 25.87792827383035, Eval reward: 31.666438714668697, TD loss   : 20.262219382524492, Episode   :    178\n",
      "Iteration :  29100, Train reward: 25.31960944093018, Eval reward: 31.666438714668697, TD loss   : 18.445048340559005, Episode   :    179\n",
      "Iteration :  29200, Train reward: 25.31960944093018, Eval reward: 31.666438714668697, TD loss   : 15.87322822213173, Episode   :    179\n",
      "Iteration :  29300, Train reward: 25.31960944093018, Eval reward: 31.666438714668697, TD loss   : 21.800566143989563, Episode   :    179\n",
      "Iteration :  29400, Train reward: 29.784735360994922, Eval reward: 31.666438714668697, TD loss   : 13.541360045671462, Episode   :    180\n",
      "Iteration :  29500, Train reward: 29.784735360994922, Eval reward: 48.2718366769189, TD loss   : 22.83684385061264, Episode   :    180\n",
      "Iteration :  29600, Train reward: 34.846633968926355, Eval reward: 48.2718366769189, TD loss   : 20.751536582708358, Episode   :    181\n",
      "Iteration :  29700, Train reward: 34.846633968926355, Eval reward: 48.2718366769189, TD loss   : 20.975651333332063, Episode   :    181\n",
      "Iteration :  29800, Train reward: 34.846633968926355, Eval reward: 48.2718366769189, TD loss   : 13.66206730723381, Episode   :    181\n",
      "Iteration :  29900, Train reward: 33.57363064748371, Eval reward: 48.2718366769189, TD loss   : 16.26972364068031, Episode   :    182\n",
      "Iteration :  30000, Train reward: 33.57363064748371, Eval reward: 46.008199292789776, TD loss   : 24.04955362558365, Episode   :    182\n",
      "Iteration :  30100, Train reward: 31.36490031301752, Eval reward: 46.008199292789776, TD loss   : 18.183579080104828, Episode   :    183\n",
      "Iteration :  30200, Train reward: 31.36490031301752, Eval reward: 46.008199292789776, TD loss   : 21.173025681972504, Episode   :    183\n",
      "Iteration :  30300, Train reward: 31.36490031301752, Eval reward: 46.008199292789776, TD loss   : 20.12152480840683, Episode   :    183\n",
      "Iteration :  30400, Train reward: 34.386199645046716, Eval reward: 46.008199292789776, TD loss   : 20.363843636512755, Episode   :    184\n",
      "Iteration :  30500, Train reward: 34.386199645046716, Eval reward: 43.967641252975916, TD loss   : 16.84615786552429, Episode   :    184\n",
      "Iteration :  30600, Train reward: 34.947738795562245, Eval reward: 43.967641252975916, TD loss   : 17.042673581838606, Episode   :    185\n",
      "Iteration :  30700, Train reward: 34.947738795562245, Eval reward: 43.967641252975916, TD loss   : 19.18239689230919, Episode   :    185\n",
      "Iteration :  30800, Train reward: 34.947738795562245, Eval reward: 43.967641252975916, TD loss   : 22.551768159866334, Episode   :    185\n",
      "Iteration :  30900, Train reward: 36.02084616687931, Eval reward: 43.967641252975916, TD loss   : 10.374102333784103, Episode   :    186\n",
      "Iteration :  31000, Train reward: 36.02084616687931, Eval reward: 57.13344861793435, TD loss   : 18.299444905519486, Episode   :    186\n",
      "Iteration :  31100, Train reward: 37.058064285076874, Eval reward: 57.13344861793435, TD loss   : 19.138534091711044, Episode   :    187\n",
      "Iteration :  31200, Train reward: 37.058064285076874, Eval reward: 57.13344861793435, TD loss   : 19.199959884881974, Episode   :    187\n",
      "Iteration :  31300, Train reward: 37.058064285076874, Eval reward: 57.13344861793435, TD loss   : 12.917425296306611, Episode   :    187\n",
      "Iteration :  31400, Train reward: 40.44638731534896, Eval reward: 57.13344861793435, TD loss   : 15.902441613674164, Episode   :    188\n",
      "Iteration :  31500, Train reward: 28.155630694124813, Eval reward: 37.340346634812015, TD loss   : 19.61756382226944, Episode   :    189\n",
      "Iteration :  31600, Train reward: 28.091452153787962, Eval reward: 37.340346634812015, TD loss   : 31.242791486978533, Episode   :    190\n",
      "Iteration :  31700, Train reward: 28.091452153787962, Eval reward: 37.340346634812015, TD loss   : 11.2526708984375, Episode   :    190\n",
      "Iteration :  31800, Train reward: 16.59349361711405, Eval reward: 37.340346634812015, TD loss   : 13.239016903042794, Episode   :    191\n",
      "Iteration :  31900, Train reward: 16.59349361711405, Eval reward: 37.340346634812015, TD loss   : 16.385248911380767, Episode   :    191\n",
      "Iteration :  32000, Train reward: 16.59349361711405, Eval reward: 75.38618951272645, TD loss   : 20.624113980531693, Episode   :    191\n",
      "Iteration :  32100, Train reward: 23.850873548612494, Eval reward: 75.38618951272645, TD loss   : 15.61388062119484, Episode   :    192\n",
      "Iteration :  32200, Train reward: 23.850873548612494, Eval reward: 75.38618951272645, TD loss   : 13.490655426383018, Episode   :    192\n",
      "Iteration :  32300, Train reward: 23.850873548612494, Eval reward: 75.38618951272645, TD loss   : 17.997297451496124, Episode   :    192\n",
      "Iteration :  32400, Train reward: 24.409183916202423, Eval reward: 75.38618951272645, TD loss   : 18.17424820303917, Episode   :    193\n",
      "Iteration :  32500, Train reward: 24.409183916202423, Eval reward: 68.31200949874446, TD loss   : 11.407804901599883, Episode   :    193\n",
      "Iteration :  32600, Train reward: 24.66650869155442, Eval reward: 68.31200949874446, TD loss   : 17.650077329874037, Episode   :    194\n",
      "Iteration :  32700, Train reward: 24.66650869155442, Eval reward: 68.31200949874446, TD loss   : 9.55136864066124, Episode   :    194\n",
      "Iteration :  32800, Train reward: 24.66650869155442, Eval reward: 68.31200949874446, TD loss   : 22.234593529701232, Episode   :    194\n",
      "Iteration :  32900, Train reward: 22.533110767737547, Eval reward: 68.31200949874446, TD loss   : 11.05940817296505, Episode   :    195\n",
      "Iteration :  33000, Train reward: 22.533110767737547, Eval reward: 2.974881896302614, TD loss   : 9.125623179674148, Episode   :    195\n",
      "Iteration :  33100, Train reward: 29.636928235865412, Eval reward: 2.974881896302614, TD loss   : 26.36047257065773, Episode   :    196\n",
      "Iteration :  33200, Train reward: 29.636928235865412, Eval reward: 2.974881896302614, TD loss   : 30.93030537366867, Episode   :    196\n",
      "Iteration :  33300, Train reward: 29.636928235865412, Eval reward: 2.974881896302614, TD loss   : 23.319761213064194, Episode   :    196\n",
      "Iteration :  33400, Train reward: 31.317707251106974, Eval reward: 2.974881896302614, TD loss   : 14.827891258597374, Episode   :    197\n",
      "Iteration :  33500, Train reward: 31.317707251106974, Eval reward: 39.17317909681856, TD loss   : 17.465463634729385, Episode   :    197\n",
      "Iteration :  33600, Train reward: 29.993105269496244, Eval reward: 39.17317909681856, TD loss   : 19.554910267591477, Episode   :    198\n",
      "Iteration :  33700, Train reward: 29.993105269496244, Eval reward: 39.17317909681856, TD loss   : 22.83055967092514, Episode   :    198\n",
      "Iteration :  33800, Train reward: 29.993105269496244, Eval reward: 39.17317909681856, TD loss   : 14.010986925363541, Episode   :    198\n",
      "Iteration :  33900, Train reward: 28.5313486405852, Eval reward: 39.17317909681856, TD loss   : 17.653146259784698, Episode   :    199\n",
      "Iteration :  34000, Train reward: 28.5313486405852, Eval reward: 46.24881858993449, TD loss   : 18.748338503837587, Episode   :    199\n",
      "Iteration :  34100, Train reward: 26.484817359695786, Eval reward: 46.24881858993449, TD loss   : 16.82391920924187, Episode   :    200\n",
      "Iteration :  34200, Train reward: 16.331249194436424, Eval reward: 46.24881858993449, TD loss   : 21.821601716279982, Episode   :    201\n",
      "Iteration :  34300, Train reward: 16.331249194436424, Eval reward: 46.24881858993449, TD loss   : 30.522721025943756, Episode   :    201\n",
      "Iteration :  34400, Train reward: 16.331249194436424, Eval reward: 46.24881858993449, TD loss   : 17.98437280654907, Episode   :    201\n",
      "Iteration :  34500, Train reward: 11.722307091956466, Eval reward: 80.3848112286917, TD loss   : 18.457227963209153, Episode   :    202\n",
      "Iteration :  34600, Train reward: 10.166478648170614, Eval reward: 80.3848112286917, TD loss   : 23.158182595968245, Episode   :    203\n",
      "Iteration :  34700, Train reward: 10.166478648170614, Eval reward: 80.3848112286917, TD loss   : 28.61820841193199, Episode   :    203\n",
      "Iteration :  34800, Train reward: 10.166478648170614, Eval reward: 80.3848112286917, TD loss   : 17.200201704502106, Episode   :    203\n",
      "Iteration :  34900, Train reward: 11.196388859596674, Eval reward: 80.3848112286917, TD loss   : 15.777877932786941, Episode   :    204\n",
      "Iteration :  35000, Train reward: 11.196388859596674, Eval reward: 54.89370569628634, TD loss   : 13.24524309873581, Episode   :    204\n",
      "Iteration :  35100, Train reward: 12.172900119088684, Eval reward: 54.89370569628634, TD loss   : 14.871701747179031, Episode   :    205\n",
      "Iteration :  35200, Train reward: 12.172900119088684, Eval reward: 54.89370569628634, TD loss   : 17.063377259969712, Episode   :    205\n",
      "Iteration :  35300, Train reward: 12.172900119088684, Eval reward: 54.89370569628634, TD loss   : 27.37696489036083, Episode   :    205\n",
      "Iteration :  35400, Train reward: 11.965529589675352, Eval reward: 54.89370569628634, TD loss   : 10.717754577994347, Episode   :    206\n",
      "Iteration :  35500, Train reward: 11.965529589675352, Eval reward: 101.41466650608496, TD loss   : 23.32999034166336, Episode   :    206\n",
      "Iteration :  35600, Train reward: 13.730815069196183, Eval reward: 101.41466650608496, TD loss   : 17.001541026830672, Episode   :    207\n",
      "Iteration :  35700, Train reward: 13.730815069196183, Eval reward: 101.41466650608496, TD loss   : 23.320261979103087, Episode   :    207\n",
      "Iteration :  35800, Train reward: 13.730815069196183, Eval reward: 101.41466650608496, TD loss   : 14.28039959192276, Episode   :    207\n",
      "Iteration :  35900, Train reward: 11.747149379270308, Eval reward: 101.41466650608496, TD loss   : 18.180887347459795, Episode   :    208\n",
      "Iteration :  36000, Train reward: 11.747149379270308, Eval reward: 107.60752073759264, TD loss   : 24.264601633548736, Episode   :    208\n",
      "Iteration :  36100, Train reward: 22.777313519020254, Eval reward: 107.60752073759264, TD loss   : 7.915186547040939, Episode   :    209\n",
      "Iteration :  36200, Train reward: 22.777313519020254, Eval reward: 107.60752073759264, TD loss   : 12.778753267526627, Episode   :    209\n",
      "Iteration :  36300, Train reward: 22.777313519020254, Eval reward: 107.60752073759264, TD loss   : 10.634499685764313, Episode   :    209\n",
      "Iteration :  36400, Train reward: 25.44506664184363, Eval reward: 107.60752073759264, TD loss   : 17.87290859699249, Episode   :    210\n",
      "Iteration :  36500, Train reward: 25.44506664184363, Eval reward: 99.7251072176438, TD loss   : 20.58567034482956, Episode   :    210\n",
      "Iteration :  36600, Train reward: 39.58227322849297, Eval reward: 99.7251072176438, TD loss   : 16.042954881191253, Episode   :    211\n",
      "Iteration :  36700, Train reward: 39.58227322849297, Eval reward: 99.7251072176438, TD loss   : 8.33768853008747, Episode   :    211\n",
      "Iteration :  36800, Train reward: 39.58227322849297, Eval reward: 99.7251072176438, TD loss   : 12.985155445337295, Episode   :    211\n",
      "Iteration :  36900, Train reward: 38.037533348557794, Eval reward: 99.7251072176438, TD loss   : 18.15562871992588, Episode   :    212\n",
      "Iteration :  37000, Train reward: 38.037533348557794, Eval reward: 113.60409984496104, TD loss   : 12.62074810743332, Episode   :    212\n",
      "Iteration :  37100, Train reward: 40.68927046303586, Eval reward: 113.60409984496104, TD loss   : 7.871666857004166, Episode   :    213\n",
      "Iteration :  37200, Train reward: 40.68927046303586, Eval reward: 113.60409984496104, TD loss   : 18.540573318004608, Episode   :    213\n",
      "Iteration :  37300, Train reward: 40.68927046303586, Eval reward: 113.60409984496104, TD loss   : 14.474392642974854, Episode   :    213\n",
      "Iteration :  37400, Train reward: 39.533342374511285, Eval reward: 113.60409984496104, TD loss   : 17.294178445339202, Episode   :    214\n",
      "Iteration :  37500, Train reward: 39.533342374511285, Eval reward: 101.44506904599515, TD loss   : 14.586224927902222, Episode   :    214\n",
      "Iteration :  37600, Train reward: 42.95061285193093, Eval reward: 101.44506904599515, TD loss   : 18.899261417388917, Episode   :    215\n",
      "Iteration :  37700, Train reward: 42.95061285193093, Eval reward: 101.44506904599515, TD loss   : 30.96942115187645, Episode   :    215\n",
      "Iteration :  37800, Train reward: 42.95061285193093, Eval reward: 101.44506904599515, TD loss   : 22.783094272613525, Episode   :    215\n",
      "Iteration :  37900, Train reward: 45.94112220623987, Eval reward: 101.44506904599515, TD loss   : 12.07375235915184, Episode   :    216\n",
      "Iteration :  38000, Train reward: 45.94112220623987, Eval reward: 28.568139769019297, TD loss   : 16.186879169940948, Episode   :    216\n",
      "Iteration :  38100, Train reward: 42.781248562477096, Eval reward: 28.568139769019297, TD loss   : 17.243240109682084, Episode   :    217\n",
      "Iteration :  38200, Train reward: 42.781248562477096, Eval reward: 28.568139769019297, TD loss   : 10.612258462905883, Episode   :    217\n",
      "Iteration :  38300, Train reward: 42.781248562477096, Eval reward: 28.568139769019297, TD loss   : 17.039901505708695, Episode   :    217\n",
      "Iteration :  38400, Train reward: 43.97943954380274, Eval reward: 28.568139769019297, TD loss   : 12.763957455158234, Episode   :    218\n",
      "Iteration :  38500, Train reward: 43.97943954380274, Eval reward: 57.74467307010275, TD loss   : 15.546646908521652, Episode   :    218\n",
      "Iteration :  38600, Train reward: 46.23343804129631, Eval reward: 57.74467307010275, TD loss   : 20.927064999341965, Episode   :    219\n",
      "Iteration :  38700, Train reward: 46.23343804129631, Eval reward: 57.74467307010275, TD loss   : 15.481606789827346, Episode   :    219\n",
      "Iteration :  38800, Train reward: 38.791310888854696, Eval reward: 57.74467307010275, TD loss   : 20.445762342214586, Episode   :    220\n",
      "Iteration :  38900, Train reward: 38.791310888854696, Eval reward: 57.74467307010275, TD loss   : 13.067071301341057, Episode   :    220\n",
      "Iteration :  39000, Train reward: 38.791310888854696, Eval reward: 74.44675908311325, TD loss   : 9.571622648835183, Episode   :    220\n",
      "Iteration :  39100, Train reward: 45.15760686259417, Eval reward: 74.44675908311325, TD loss   : 18.180820623636247, Episode   :    221\n",
      "Iteration :  39200, Train reward: 45.15760686259417, Eval reward: 74.44675908311325, TD loss   : 13.472743880748748, Episode   :    221\n",
      "Iteration :  39300, Train reward: 45.15760686259417, Eval reward: 74.44675908311325, TD loss   : 22.460781781673433, Episode   :    221\n",
      "Iteration :  39400, Train reward: 50.97079392441087, Eval reward: 74.44675908311325, TD loss   : 27.657324664592743, Episode   :    222\n",
      "Iteration :  39500, Train reward: 50.97079392441087, Eval reward: 87.3458059972317, TD loss   : 16.341974169015884, Episode   :    222\n",
      "Iteration :  39600, Train reward: 55.112432169053946, Eval reward: 87.3458059972317, TD loss   : 24.76788407921791, Episode   :    223\n",
      "Iteration :  39700, Train reward: 55.112432169053946, Eval reward: 87.3458059972317, TD loss   : 16.016567711830138, Episode   :    223\n",
      "Iteration :  39800, Train reward: 55.112432169053946, Eval reward: 87.3458059972317, TD loss   : 18.026625393629075, Episode   :    223\n",
      "Iteration :  39900, Train reward: 53.78408272520441, Eval reward: 87.3458059972317, TD loss   : 17.504349818229674, Episode   :    224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HasanErdin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\HasanErdin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :      0, Train reward:    nan, Eval reward: -135.11636434603543, TD loss   :    nan, Episode   :      0\n",
      "Iteration :    100, Train reward: -115.0765684131988, Eval reward: -135.11636434603543, TD loss   : 182.3194580078125, Episode   :      2\n",
      "Iteration :    200, Train reward: -115.0765684131988, Eval reward: -135.11636434603543, TD loss   : 145.07866658747196, Episode   :      2\n",
      "Iteration :    300, Train reward: -150.25905404224923, Eval reward: -135.11636434603543, TD loss   : 127.18719882965088, Episode   :      4\n",
      "Iteration :    400, Train reward: -150.25905404224923, Eval reward: -135.11636434603543, TD loss   : 113.04602030992508, Episode   :      4\n",
      "Iteration :    500, Train reward: -126.79677397210541, Eval reward: -721.2387715069616, TD loss   : 99.89893148899078, Episode   :      6\n",
      "Iteration :    600, Train reward: -120.89698577134767, Eval reward: -721.2387715069616, TD loss   : 102.73480292201042, Episode   :      7\n",
      "Iteration :    700, Train reward: -114.08592047149625, Eval reward: -721.2387715069616, TD loss   : 111.22275100708008, Episode   :      8\n",
      "Iteration :    800, Train reward: -104.8977397100774, Eval reward: -721.2387715069616, TD loss   : 105.31901783704758, Episode   :      9\n",
      "Iteration :    900, Train reward: -135.22872017181737, Eval reward: -721.2387715069616, TD loss   : 91.50317170619965, Episode   :     10\n",
      "Iteration :   1000, Train reward: -143.24297394199786, Eval reward: -265.9106546209334, TD loss   : 77.73401258707047, Episode   :     11\n",
      "Iteration :   1100, Train reward: -159.00609781805454, Eval reward: -265.9106546209334, TD loss   : 101.81473380565643, Episode   :     13\n",
      "Iteration :   1200, Train reward: -153.6984560744793, Eval reward: -265.9106546209334, TD loss   : 89.9348263168335, Episode   :     14\n",
      "Iteration :   1300, Train reward: -147.75780214430603, Eval reward: -265.9106546209334, TD loss   : 83.4845942234993, Episode   :     15\n",
      "Iteration :   1400, Train reward: -143.4698619395988, Eval reward: -265.9106546209334, TD loss   : 72.24636474013329, Episode   :     16\n",
      "Iteration :   1500, Train reward: -152.6487277817302, Eval reward: -184.05010146537447, TD loss   : 64.00690860509873, Episode   :     17\n",
      "Iteration :   1600, Train reward: -150.15540423913964, Eval reward: -184.05010146537447, TD loss   : 79.91160933375359, Episode   :     18\n",
      "Iteration :   1700, Train reward: -146.23540595606013, Eval reward: -184.05010146537447, TD loss   : 75.29448443174363, Episode   :     19\n",
      "Iteration :   1800, Train reward: -148.7185652985478, Eval reward: -184.05010146537447, TD loss   : 60.55088798999786, Episode   :     20\n",
      "Iteration :   1900, Train reward: -144.93987342895454, Eval reward: -184.05010146537447, TD loss   : 86.35497502326966, Episode   :     21\n",
      "Iteration :   2000, Train reward: -146.84912615824507, Eval reward: -246.30024169971884, TD loss   : 71.09851692318917, Episode   :     22\n",
      "Iteration :   2100, Train reward: -151.54561569302024, Eval reward: -246.30024169971884, TD loss   : 75.09443141460419, Episode   :     23\n",
      "Iteration :   2200, Train reward: -140.2314918712015, Eval reward: -246.30024169971884, TD loss   : 94.63894268035888, Episode   :     24\n",
      "Iteration :   2300, Train reward: -143.37679986184907, Eval reward: -246.30024169971884, TD loss   : 88.1514927482605, Episode   :     25\n",
      "Iteration :   2400, Train reward: -143.3017254182202, Eval reward: -246.30024169971884, TD loss   : 69.8876981830597, Episode   :     26\n",
      "Iteration :   2500, Train reward: -141.23946268426633, Eval reward: -379.6533862228338, TD loss   : 88.54465171337128, Episode   :     27\n",
      "Iteration :   2600, Train reward: -148.3628458896521, Eval reward: -379.6533862228338, TD loss   : 80.71095199942589, Episode   :     28\n",
      "Iteration :   2700, Train reward: -147.45141438486127, Eval reward: -379.6533862228338, TD loss   : 80.10153698921204, Episode   :     29\n",
      "Iteration :   2800, Train reward: -133.16639291022813, Eval reward: -379.6533862228338, TD loss   : 92.97858363866806, Episode   :     30\n",
      "Iteration :   2900, Train reward: -122.00663081042202, Eval reward: -379.6533862228338, TD loss   : 81.83217865347862, Episode   :     31\n",
      "Iteration :   3000, Train reward: -120.74859908277435, Eval reward: -250.08623686478123, TD loss   : 92.12627688169479, Episode   :     32\n",
      "Iteration :   3100, Train reward: -106.79825744766352, Eval reward: -250.08623686478123, TD loss   : 91.47324041604996, Episode   :     33\n",
      "Iteration :   3200, Train reward: -110.02612849945123, Eval reward: -250.08623686478123, TD loss   : 116.4470540380478, Episode   :     34\n",
      "Iteration :   3300, Train reward: -113.15261327060098, Eval reward: -250.08623686478123, TD loss   : 80.56811331987382, Episode   :     35\n",
      "Iteration :   3400, Train reward: -116.38768168388538, Eval reward: -250.08623686478123, TD loss   : 101.0173981809616, Episode   :     36\n",
      "Iteration :   3500, Train reward: -106.38517798124629, Eval reward: -324.0541413168677, TD loss   : 94.67587375402451, Episode   :     37\n",
      "Iteration :   3600, Train reward: -104.51128715190046, Eval reward: -324.0541413168677, TD loss   : 90.71008368968964, Episode   :     38\n",
      "Iteration :   3700, Train reward: -120.48875501978371, Eval reward: -324.0541413168677, TD loss   : 80.74230668902398, Episode   :     40\n",
      "Iteration :   3800, Train reward: -135.23465573978964, Eval reward: -324.0541413168677, TD loss   : 80.22580101251602, Episode   :     41\n",
      "Iteration :   3900, Train reward: -135.470759405298, Eval reward: -324.0541413168677, TD loss   : 89.1819874703884, Episode   :     42\n",
      "Iteration :   4000, Train reward: -131.3687399224878, Eval reward: -293.3777330320262, TD loss   : 70.10940546393394, Episode   :     43\n",
      "Iteration :   4100, Train reward: -136.31427944939358, Eval reward: -293.3777330320262, TD loss   : 101.94198996305465, Episode   :     44\n",
      "Iteration :   4200, Train reward: -132.71337310616553, Eval reward: -293.3777330320262, TD loss   : 92.94690129995347, Episode   :     45\n",
      "Iteration :   4300, Train reward: -129.4008705909816, Eval reward: -293.3777330320262, TD loss   : 100.28213480234146, Episode   :     46\n",
      "Iteration :   4400, Train reward: -132.02291190723295, Eval reward: -293.3777330320262, TD loss   : 86.07826187372207, Episode   :     47\n",
      "Iteration :   4500, Train reward: -130.93407833380934, Eval reward: -340.80148208969376, TD loss   : 82.2918663072586, Episode   :     48\n",
      "Iteration :   4600, Train reward: -135.65874623582607, Eval reward: -340.80148208969376, TD loss   : 93.35853231906891, Episode   :     49\n",
      "Iteration :   4700, Train reward: -141.6629664911462, Eval reward: -340.80148208969376, TD loss   : 82.23259991168976, Episode   :     50\n",
      "Iteration :   4800, Train reward: -145.30936763999443, Eval reward: -340.80148208969376, TD loss   : 59.164800844192506, Episode   :     51\n",
      "Iteration :   4900, Train reward: -145.30936763999443, Eval reward: -340.80148208969376, TD loss   : 87.11070980787277, Episode   :     51\n",
      "Iteration :   5000, Train reward: -149.7595761138477, Eval reward: -405.9011980751099, TD loss   : 82.11187238454819, Episode   :     52\n",
      "Iteration :   5100, Train reward: -155.29854478533827, Eval reward: -405.9011980751099, TD loss   : 83.38004419326782, Episode   :     54\n",
      "Iteration :   5200, Train reward: -164.72237948535434, Eval reward: -405.9011980751099, TD loss   : 66.96909978151321, Episode   :     55\n",
      "Iteration :   5300, Train reward: -162.69806009532044, Eval reward: -405.9011980751099, TD loss   : 65.15133480548859, Episode   :     56\n",
      "Iteration :   5400, Train reward: -162.69806009532044, Eval reward: -405.9011980751099, TD loss   : 84.92392580986024, Episode   :     56\n",
      "Iteration :   5500, Train reward: -164.16850599490897, Eval reward: -301.75943906501936, TD loss   : 60.390746881961824, Episode   :     57\n",
      "Iteration :   5600, Train reward: -168.08206165339442, Eval reward: -301.75943906501936, TD loss   : 81.18500789642334, Episode   :     58\n",
      "Iteration :   5700, Train reward: -160.67891039248445, Eval reward: -301.75943906501936, TD loss   : 78.66006691217423, Episode   :     59\n",
      "Iteration :   5800, Train reward: -153.2774641975114, Eval reward: -301.75943906501936, TD loss   : 79.48173892736435, Episode   :     60\n",
      "Iteration :   5900, Train reward: -137.50233369102716, Eval reward: -301.75943906501936, TD loss   : 71.86755493879318, Episode   :     61\n",
      "Iteration :   6000, Train reward: -130.9340426719979, Eval reward: -362.82482510431, TD loss   : 62.23086208820343, Episode   :     62\n",
      "Iteration :   6100, Train reward: -130.40837253091192, Eval reward: -362.82482510431, TD loss   : 77.09466884374619, Episode   :     63\n",
      "Iteration :   6200, Train reward: -130.14703425247941, Eval reward: -362.82482510431, TD loss   : 75.4964073586464, Episode   :     65\n",
      "Iteration :   6300, Train reward: -130.14703425247941, Eval reward: -362.82482510431, TD loss   : 63.99850757241249, Episode   :     65\n",
      "Iteration :   6400, Train reward: -144.02902288075398, Eval reward: -362.82482510431, TD loss   : 57.3823358309269, Episode   :     66\n",
      "Iteration :   6500, Train reward: -142.22778168405503, Eval reward: -410.0318122314278, TD loss   : 66.03966630458832, Episode   :     67\n",
      "Iteration :   6600, Train reward: -133.68392263033672, Eval reward: -410.0318122314278, TD loss   : 73.51067505717278, Episode   :     68\n",
      "Iteration :   6700, Train reward: -138.4658672833005, Eval reward: -410.0318122314278, TD loss   : 81.78649665951728, Episode   :     69\n",
      "Iteration :   6800, Train reward: -138.4658672833005, Eval reward: -410.0318122314278, TD loss   : 74.75435482978821, Episode   :     69\n",
      "Iteration :   6900, Train reward: -138.4658672833005, Eval reward: -410.0318122314278, TD loss   : 85.23251607894898, Episode   :     69\n",
      "Iteration :   7000, Train reward: -118.37832273087415, Eval reward: -236.68194944256487, TD loss   : 61.354973747730256, Episode   :     70\n",
      "Iteration :   7100, Train reward: -118.72934272602527, Eval reward: -236.68194944256487, TD loss   : 61.26242993354797, Episode   :     71\n",
      "Iteration :   7200, Train reward: -123.19767623170421, Eval reward: -236.68194944256487, TD loss   : 63.917549264431, Episode   :     72\n",
      "Iteration :   7300, Train reward: -132.021362850206, Eval reward: -236.68194944256487, TD loss   : 57.401253228187564, Episode   :     73\n",
      "Iteration :   7400, Train reward: -126.64450430024829, Eval reward: -236.68194944256487, TD loss   : 71.1795954465866, Episode   :     74\n",
      "Iteration :   7500, Train reward: -126.64450430024829, Eval reward: -366.0922487493658, TD loss   : 60.49642716407776, Episode   :     74\n",
      "Iteration :   7600, Train reward: -116.9927179192113, Eval reward: -366.0922487493658, TD loss   : 46.7463716685772, Episode   :     75\n",
      "Iteration :   7700, Train reward: -112.74864394995787, Eval reward: -366.0922487493658, TD loss   : 59.62997478246689, Episode   :     76\n",
      "Iteration :   7800, Train reward: -112.74864394995787, Eval reward: -366.0922487493658, TD loss   : 57.75945062160492, Episode   :     76\n",
      "Iteration :   7900, Train reward: -107.63873075106605, Eval reward: -366.0922487493658, TD loss   : 64.31338427782059, Episode   :     77\n",
      "Iteration :   8000, Train reward: -107.63873075106605, Eval reward: -237.62079676587115, TD loss   : 76.19883955717087, Episode   :     77\n",
      "Iteration :   8100, Train reward: -109.81675251643408, Eval reward: -237.62079676587115, TD loss   : 56.218650653362275, Episode   :     78\n",
      "Iteration :   8200, Train reward: -102.19027828981612, Eval reward: -237.62079676587115, TD loss   : 46.40830365896225, Episode   :     79\n",
      "Iteration :   8300, Train reward: -110.36976109567797, Eval reward: -237.62079676587115, TD loss   : 59.457434990406036, Episode   :     80\n",
      "Iteration :   8400, Train reward: -114.14560316665566, Eval reward: -237.62079676587115, TD loss   : 53.58494076967239, Episode   :     81\n",
      "Iteration :   8500, Train reward: -116.5416704867055, Eval reward: -136.80171313972116, TD loss   : 55.613769958019255, Episode   :     82\n",
      "Iteration :   8600, Train reward: -110.89796217100579, Eval reward: -136.80171313972116, TD loss   : 60.44454937458038, Episode   :     83\n",
      "Iteration :   8700, Train reward: -115.38412664608674, Eval reward: -136.80171313972116, TD loss   : 62.32665119171143, Episode   :     84\n",
      "Iteration :   8800, Train reward: -116.96406511590867, Eval reward: -136.80171313972116, TD loss   : 44.00069566845894, Episode   :     85\n",
      "Iteration :   8900, Train reward: -116.96406511590867, Eval reward: -136.80171313972116, TD loss   : 44.57977992415428, Episode   :     85\n",
      "Iteration :   9000, Train reward: -109.59361846929323, Eval reward: -15.122768404164432, TD loss   : 68.73702286481857, Episode   :     86\n",
      "Iteration :   9100, Train reward: -108.61006705722957, Eval reward: -15.122768404164432, TD loss   : 54.62333131313324, Episode   :     88\n",
      "Iteration :   9200, Train reward: -108.61006705722957, Eval reward: -15.122768404164432, TD loss   : 57.021446182727814, Episode   :     88\n",
      "Iteration :   9300, Train reward: -102.83415432296768, Eval reward: -15.122768404164432, TD loss   : 57.097759792804716, Episode   :     89\n",
      "Iteration :   9400, Train reward: -102.83415432296768, Eval reward: -15.122768404164432, TD loss   : 56.49308861732483, Episode   :     89\n",
      "Iteration :   9500, Train reward: -127.10488351505259, Eval reward: -10.95663239389297, TD loss   : 52.08924266576767, Episode   :     90\n",
      "Iteration :   9600, Train reward: -114.95003275517315, Eval reward: -10.95663239389297, TD loss   : 63.77576290845871, Episode   :     92\n",
      "Iteration :   9700, Train reward: -114.95003275517315, Eval reward: -10.95663239389297, TD loss   : 50.94056228637695, Episode   :     92\n",
      "Iteration :   9800, Train reward: -104.58867387477696, Eval reward: -10.95663239389297, TD loss   : 46.15316929101944, Episode   :     93\n",
      "Iteration :   9900, Train reward: -104.95228847181625, Eval reward: -10.95663239389297, TD loss   : 52.79373305678368, Episode   :     94\n",
      "Iteration :  10000, Train reward: -103.93273761064363, Eval reward: 13.029165611776381, TD loss   : 40.84423910140991, Episode   :     95\n",
      "Iteration :  10100, Train reward: -102.93137313018993, Eval reward: 13.029165611776381, TD loss   : 45.944904038906095, Episode   :     96\n",
      "Iteration :  10200, Train reward: -102.93137313018993, Eval reward: 13.029165611776381, TD loss   : 41.705361092090605, Episode   :     96\n",
      "Iteration :  10300, Train reward: -105.66591942913503, Eval reward: 13.029165611776381, TD loss   : 43.439076116085054, Episode   :     97\n",
      "Iteration :  10400, Train reward: -99.60553293595876, Eval reward: 13.029165611776381, TD loss   : 42.20407287240028, Episode   :     98\n",
      "Iteration :  10500, Train reward: -99.60553293595876, Eval reward: -3.945146713410079, TD loss   : 46.9937812423706, Episode   :     98\n",
      "Iteration :  10600, Train reward: -93.03242376520487, Eval reward: -3.945146713410079, TD loss   : 38.00393160820008, Episode   :     99\n",
      "Iteration :  10700, Train reward: -93.03242376520487, Eval reward: -3.945146713410079, TD loss   : 51.68366870522499, Episode   :     99\n",
      "Iteration :  10800, Train reward: -87.39521371609666, Eval reward: -3.945146713410079, TD loss   : 43.99102277636528, Episode   :    100\n",
      "Iteration :  10900, Train reward: -89.07124005737741, Eval reward: -3.945146713410079, TD loss   : 45.53386200547218, Episode   :    101\n",
      "Iteration :  11000, Train reward: -88.0839847601774, Eval reward: 7.673756668304174, TD loss   : 49.76903018712997, Episode   :    102\n",
      "Iteration :  11100, Train reward: -89.25614917267514, Eval reward: 7.673756668304174, TD loss   : 55.12037916898728, Episode   :    103\n",
      "Iteration :  11200, Train reward: -89.25614917267514, Eval reward: 7.673756668304174, TD loss   : 64.84893208742142, Episode   :    103\n",
      "Iteration :  11300, Train reward: -81.35391550639473, Eval reward: 7.673756668304174, TD loss   : 45.88868631124497, Episode   :    104\n",
      "Iteration :  11400, Train reward: -81.35391550639473, Eval reward: 7.673756668304174, TD loss   : 58.420020530223844, Episode   :    104\n",
      "Iteration :  11500, Train reward: -87.86247984048535, Eval reward: 17.426769725352948, TD loss   : 41.905409116745, Episode   :    105\n",
      "Iteration :  11600, Train reward: -79.86417722343558, Eval reward: 17.426769725352948, TD loss   : 53.16531723260879, Episode   :    106\n",
      "Iteration :  11700, Train reward: -84.17524485315889, Eval reward: 17.426769725352948, TD loss   : 52.63401325345039, Episode   :    107\n",
      "Iteration :  11800, Train reward: -84.17524485315889, Eval reward: 17.426769725352948, TD loss   : 45.77650933504105, Episode   :    107\n",
      "Iteration :  11900, Train reward: -84.17524485315889, Eval reward: 17.426769725352948, TD loss   : 38.31168792009353, Episode   :    107\n",
      "Iteration :  12000, Train reward: -77.05721625155317, Eval reward: 38.75748741441227, TD loss   : 57.06389599084854, Episode   :    108\n",
      "Iteration :  12100, Train reward: -72.56970424844786, Eval reward: 38.75748741441227, TD loss   : 43.276456220149996, Episode   :    109\n",
      "Iteration :  12200, Train reward: -72.56970424844786, Eval reward: 38.75748741441227, TD loss   : 43.0829844892025, Episode   :    109\n",
      "Iteration :  12300, Train reward: -58.35835520763891, Eval reward: 38.75748741441227, TD loss   : 43.56885733366013, Episode   :    110\n",
      "Iteration :  12400, Train reward: -58.35835520763891, Eval reward: 38.75748741441227, TD loss   : 44.450178827047345, Episode   :    110\n",
      "Iteration :  12500, Train reward: -58.35835520763891, Eval reward: -42.19471748057466, TD loss   : 29.144574563503266, Episode   :    110\n",
      "Iteration :  12600, Train reward: -58.63926396246866, Eval reward: -42.19471748057466, TD loss   : 35.09595688223839, Episode   :    111\n",
      "Iteration :  12700, Train reward: -55.00883189112976, Eval reward: -42.19471748057466, TD loss   : 33.83269001960755, Episode   :    113\n",
      "Iteration :  12800, Train reward: -55.00883189112976, Eval reward: -42.19471748057466, TD loss   : 41.95201983451843, Episode   :    113\n",
      "Iteration :  12900, Train reward: -55.00883189112976, Eval reward: -42.19471748057466, TD loss   : 39.64182084679604, Episode   :    113\n",
      "Iteration :  13000, Train reward: -51.348636622346376, Eval reward: -7.025335025567874, TD loss   : 43.94986588001251, Episode   :    114\n",
      "Iteration :  13100, Train reward: -43.90901936431211, Eval reward: -7.025335025567874, TD loss   : 40.64618178844452, Episode   :    115\n",
      "Iteration :  13200, Train reward: -43.90901936431211, Eval reward: -7.025335025567874, TD loss   : 50.05635464429855, Episode   :    115\n",
      "Iteration :  13300, Train reward: -48.96461230547828, Eval reward: -7.025335025567874, TD loss   : 59.858115286827086, Episode   :    116\n",
      "Iteration :  13400, Train reward: -48.96461230547828, Eval reward: -7.025335025567874, TD loss   : 55.6992900121212, Episode   :    116\n",
      "Iteration :  13500, Train reward: -49.275612188675005, Eval reward: -26.675068820127592, TD loss   : 36.64947495222091, Episode   :    117\n",
      "Iteration :  13600, Train reward: -45.56203869096052, Eval reward: -26.675068820127592, TD loss   : 38.06627148151398, Episode   :    118\n",
      "Iteration :  13700, Train reward: -47.851339634527065, Eval reward: -26.675068820127592, TD loss   : 35.18621344208717, Episode   :    119\n",
      "Iteration :  13800, Train reward: -59.010118455379164, Eval reward: -26.675068820127592, TD loss   : 50.839175975322725, Episode   :    120\n",
      "Iteration :  13900, Train reward: -59.010118455379164, Eval reward: -26.675068820127592, TD loss   : 44.62538468122482, Episode   :    120\n",
      "Iteration :  14000, Train reward: -56.79945132545978, Eval reward: 35.19891790868418, TD loss   : 54.243655790090564, Episode   :    121\n",
      "Iteration :  14100, Train reward: -52.64578087287914, Eval reward: 35.19891790868418, TD loss   : 45.40392682790756, Episode   :    122\n",
      "Iteration :  14200, Train reward: -62.106593786065616, Eval reward: 35.19891790868418, TD loss   : 59.133585891723634, Episode   :    123\n",
      "Iteration :  14300, Train reward: -62.106593786065616, Eval reward: 35.19891790868418, TD loss   : 64.11350533485412, Episode   :    123\n",
      "Iteration :  14400, Train reward: -62.106593786065616, Eval reward: 35.19891790868418, TD loss   : 32.898853726387024, Episode   :    123\n",
      "Iteration :  14500, Train reward: -58.896938466834754, Eval reward: 37.482856875347, TD loss   : 48.693788778781894, Episode   :    124\n",
      "Iteration :  14600, Train reward: -46.95163937657226, Eval reward: 37.482856875347, TD loss   : 57.78840370774269, Episode   :    125\n",
      "Iteration :  14700, Train reward: -46.95163937657226, Eval reward: 37.482856875347, TD loss   : 44.11745447993278, Episode   :    125\n",
      "Iteration :  14800, Train reward: -53.719681169331935, Eval reward: 37.482856875347, TD loss   : 41.58093347549438, Episode   :    126\n",
      "Iteration :  14900, Train reward: -53.719681169331935, Eval reward: 37.482856875347, TD loss   : 58.22893686771393, Episode   :    126\n",
      "Iteration :  15000, Train reward: -51.9293977107085, Eval reward: -20.33884536468648, TD loss   : 51.084553047418595, Episode   :    127\n",
      "Iteration :  15100, Train reward: -54.097758353335095, Eval reward: -20.33884536468648, TD loss   : 52.77441222429275, Episode   :    128\n",
      "Iteration :  15200, Train reward: -57.7012697760142, Eval reward: -20.33884536468648, TD loss   : 51.37761026620865, Episode   :    129\n",
      "Iteration :  15300, Train reward: -57.7012697760142, Eval reward: -20.33884536468648, TD loss   : 50.49402056097984, Episode   :    129\n",
      "Iteration :  15400, Train reward: -57.7012697760142, Eval reward: -20.33884536468648, TD loss   : 52.56991855144501, Episode   :    129\n",
      "Iteration :  15500, Train reward: -58.87513656533495, Eval reward: 2.8366556418614985, TD loss   : 44.59305228114128, Episode   :    130\n",
      "Iteration :  15600, Train reward: -58.84102590807248, Eval reward: 2.8366556418614985, TD loss   : 50.842472150325776, Episode   :    131\n",
      "Iteration :  15700, Train reward: -58.84102590807248, Eval reward: 2.8366556418614985, TD loss   : 48.67825368762016, Episode   :    131\n",
      "Iteration :  15800, Train reward: -58.84102590807248, Eval reward: 2.8366556418614985, TD loss   : 44.02136314511299, Episode   :    131\n",
      "Iteration :  15900, Train reward: -53.90956223680953, Eval reward: 2.8366556418614985, TD loss   : 36.536676309108735, Episode   :    132\n",
      "Iteration :  16000, Train reward: -52.1303864001073, Eval reward: 43.03040159450899, TD loss   : 52.651582007408145, Episode   :    133\n",
      "Iteration :  16100, Train reward: -50.91097797290208, Eval reward: 43.03040159450899, TD loss   : 36.284464457035064, Episode   :    134\n",
      "Iteration :  16200, Train reward: -53.89908739972562, Eval reward: 43.03040159450899, TD loss   : 43.914531556367876, Episode   :    135\n",
      "Iteration :  16300, Train reward: -53.89908739972562, Eval reward: 43.03040159450899, TD loss   : 43.63179184556007, Episode   :    135\n",
      "Iteration :  16400, Train reward: -59.50479572129211, Eval reward: 43.03040159450899, TD loss   : 41.37252571821213, Episode   :    136\n",
      "Iteration :  16500, Train reward: -59.50479572129211, Eval reward: 55.31764240739246, TD loss   : 37.76882206082344, Episode   :    136\n",
      "Iteration :  16600, Train reward: -53.74639621049005, Eval reward: 55.31764240739246, TD loss   : 48.32746960878372, Episode   :    137\n",
      "Iteration :  16700, Train reward: -53.74639621049005, Eval reward: 55.31764240739246, TD loss   : 45.80458039999008, Episode   :    137\n",
      "Iteration :  16800, Train reward: -53.74639621049005, Eval reward: 55.31764240739246, TD loss   : 39.21498792886734, Episode   :    137\n",
      "Iteration :  16900, Train reward: -54.860823220885514, Eval reward: 55.31764240739246, TD loss   : 41.236077749729155, Episode   :    138\n",
      "Iteration :  17000, Train reward: -54.860823220885514, Eval reward: -46.313362818407384, TD loss   : 35.12279362797737, Episode   :    138\n",
      "Iteration :  17100, Train reward: -55.248835242034396, Eval reward: -46.313362818407384, TD loss   : 39.51031406521797, Episode   :    139\n",
      "Iteration :  17200, Train reward: -55.248835242034396, Eval reward: -46.313362818407384, TD loss   : 40.83945340156555, Episode   :    139\n",
      "Iteration :  17300, Train reward: -55.248835242034396, Eval reward: -46.313362818407384, TD loss   : 32.62744118690491, Episode   :    139\n",
      "Iteration :  17400, Train reward: -39.61290353158132, Eval reward: -46.313362818407384, TD loss   : 45.03627702116966, Episode   :    140\n",
      "Iteration :  17500, Train reward: -39.61290353158132, Eval reward: 25.837565964438607, TD loss   : 38.79274912118912, Episode   :    140\n",
      "Iteration :  17600, Train reward: -33.52981140068989, Eval reward: 25.837565964438607, TD loss   : 29.619305237531663, Episode   :    141\n",
      "Iteration :  17700, Train reward: -33.52981140068989, Eval reward: 25.837565964438607, TD loss   : 47.50097907781601, Episode   :    141\n",
      "Iteration :  17800, Train reward: -40.834494191092716, Eval reward: 25.837565964438607, TD loss   : 38.59554295063019, Episode   :    142\n",
      "Iteration :  17900, Train reward: -34.84754569030779, Eval reward: 25.837565964438607, TD loss   : 28.49547882556915, Episode   :    143\n",
      "Iteration :  18000, Train reward: -34.84754569030779, Eval reward: 28.82035503880578, TD loss   : 48.800687671899794, Episode   :    143\n",
      "Iteration :  18100, Train reward: -34.962960214005435, Eval reward: 28.82035503880578, TD loss   : 41.20546609640122, Episode   :    144\n",
      "Iteration :  18200, Train reward: -34.962960214005435, Eval reward: 28.82035503880578, TD loss   : 40.26980539798737, Episode   :    144\n",
      "Iteration :  18300, Train reward: -34.962960214005435, Eval reward: 28.82035503880578, TD loss   : 30.803547662496566, Episode   :    144\n",
      "Iteration :  18400, Train reward: -31.675680847006284, Eval reward: 28.82035503880578, TD loss   : 35.43118200063705, Episode   :    145\n",
      "Iteration :  18500, Train reward: -31.675680847006284, Eval reward: 12.303804985575402, TD loss   : 32.86623867750168, Episode   :    145\n",
      "Iteration :  18600, Train reward: -24.60587837333452, Eval reward: 12.303804985575402, TD loss   : 36.081390286684034, Episode   :    146\n",
      "Iteration :  18700, Train reward: -24.60587837333452, Eval reward: 12.303804985575402, TD loss   : 42.197768154144285, Episode   :    146\n",
      "Iteration :  18800, Train reward: -24.60587837333452, Eval reward: 12.303804985575402, TD loss   : 51.1069054710865, Episode   :    146\n",
      "Iteration :  18900, Train reward: -23.2867114054868, Eval reward: 12.303804985575402, TD loss   : 29.036970838308335, Episode   :    147\n",
      "Iteration :  19000, Train reward: -23.2867114054868, Eval reward: -128.77719918516576, TD loss   : 29.341436479091644, Episode   :    147\n",
      "Iteration :  19100, Train reward: -26.878988951630816, Eval reward: -128.77719918516576, TD loss   : 47.23403627276421, Episode   :    148\n",
      "Iteration :  19200, Train reward: -26.878988951630816, Eval reward: -128.77719918516576, TD loss   : 46.578059653043745, Episode   :    148\n",
      "Iteration :  19300, Train reward: -26.878988951630816, Eval reward: -128.77719918516576, TD loss   : 47.937679134607315, Episode   :    148\n",
      "Iteration :  19400, Train reward: -22.35248842312223, Eval reward: -128.77719918516576, TD loss   : 37.21817616343498, Episode   :    149\n",
      "Iteration :  19500, Train reward: -22.35248842312223, Eval reward: -19.794578008397938, TD loss   : 47.63686912298203, Episode   :    149\n",
      "Iteration :  19600, Train reward: -18.25609608647424, Eval reward: -19.794578008397938, TD loss   : 34.75168707847595, Episode   :    150\n",
      "Iteration :  19700, Train reward: -18.25609608647424, Eval reward: -19.794578008397938, TD loss   : 35.14707963466644, Episode   :    150\n",
      "Iteration :  19800, Train reward: -18.25609608647424, Eval reward: -19.794578008397938, TD loss   : 30.531519019603728, Episode   :    150\n",
      "Iteration :  19900, Train reward: -20.53241772726492, Eval reward: -19.794578008397938, TD loss   : 34.40517031788826, Episode   :    151\n",
      "Iteration :  20000, Train reward: -20.53241772726492, Eval reward: 16.75190932993076, TD loss   : 31.261975865364075, Episode   :    151\n",
      "Iteration :  20100, Train reward: -22.23671746798234, Eval reward: 16.75190932993076, TD loss   : 34.447247529029845, Episode   :    152\n",
      "Iteration :  20200, Train reward: -22.23671746798234, Eval reward: 16.75190932993076, TD loss   : 28.215149993896485, Episode   :    152\n",
      "Iteration :  20300, Train reward: -23.933983888110447, Eval reward: 16.75190932993076, TD loss   : 39.61508329868317, Episode   :    153\n",
      "Iteration :  20400, Train reward: -23.933983888110447, Eval reward: 16.75190932993076, TD loss   : 35.86013280272484, Episode   :    153\n",
      "Iteration :  20500, Train reward: -23.933983888110447, Eval reward: -54.55386633165811, TD loss   : 27.436777403354643, Episode   :    153\n",
      "Iteration :  20600, Train reward: -26.362392177274234, Eval reward: -54.55386633165811, TD loss   : 49.028508013486864, Episode   :    154\n",
      "Iteration :  20700, Train reward: -26.362392177274234, Eval reward: -54.55386633165811, TD loss   : 26.06258623957634, Episode   :    154\n",
      "Iteration :  20800, Train reward: -32.748365492863854, Eval reward: -54.55386633165811, TD loss   : 27.719303059577943, Episode   :    155\n",
      "Iteration :  20900, Train reward: -32.748365492863854, Eval reward: -54.55386633165811, TD loss   : 36.481933439970014, Episode   :    155\n",
      "Iteration :  21000, Train reward: -32.748365492863854, Eval reward: -0.5241254095505734, TD loss   : 30.62013774871826, Episode   :    155\n",
      "Iteration :  21100, Train reward: -21.093489311800838, Eval reward: -0.5241254095505734, TD loss   : 35.105856809616085, Episode   :    156\n",
      "Iteration :  21200, Train reward: -24.199084753419154, Eval reward: -0.5241254095505734, TD loss   : 21.704606113433837, Episode   :    157\n",
      "Iteration :  21300, Train reward: -24.199084753419154, Eval reward: -0.5241254095505734, TD loss   : 39.420165660381315, Episode   :    157\n",
      "Iteration :  21400, Train reward: -24.199084753419154, Eval reward: -0.5241254095505734, TD loss   : 29.560546849966048, Episode   :    157\n",
      "Iteration :  21500, Train reward: -23.16592129371812, Eval reward: 0.8148870199447842, TD loss   : 23.36987545132637, Episode   :    158\n",
      "Iteration :  21600, Train reward: -21.608161468710176, Eval reward: 0.8148870199447842, TD loss   : 30.86127179503441, Episode   :    159\n",
      "Iteration :  21700, Train reward: -21.608161468710176, Eval reward: 0.8148870199447842, TD loss   : 36.17752122879028, Episode   :    159\n",
      "Iteration :  21800, Train reward: -26.77901821990987, Eval reward: 0.8148870199447842, TD loss   : 37.70463247656822, Episode   :    160\n",
      "Iteration :  21900, Train reward: -26.77901821990987, Eval reward: 0.8148870199447842, TD loss   : 23.916446083784102, Episode   :    160\n",
      "Iteration :  22000, Train reward: -26.77901821990987, Eval reward: 24.402182817445105, TD loss   : 34.90588153243065, Episode   :    160\n",
      "Iteration :  22100, Train reward: -31.93403095296542, Eval reward: 24.402182817445105, TD loss   : 35.97087171673775, Episode   :    161\n",
      "Iteration :  22200, Train reward: -28.718196361526765, Eval reward: 24.402182817445105, TD loss   : 32.538248647451404, Episode   :    162\n",
      "Iteration :  22300, Train reward: -28.718196361526765, Eval reward: 24.402182817445105, TD loss   : 34.2670800280571, Episode   :    162\n",
      "Iteration :  22400, Train reward: -30.683619418708282, Eval reward: 24.402182817445105, TD loss   : 45.927249896526334, Episode   :    163\n",
      "Iteration :  22500, Train reward: -30.683619418708282, Eval reward: -25.526370319004258, TD loss   : 29.197061982154846, Episode   :    163\n",
      "Iteration :  22600, Train reward: -29.8327455818325, Eval reward: -25.526370319004258, TD loss   : 42.84005185723305, Episode   :    164\n",
      "Iteration :  22700, Train reward: -29.8327455818325, Eval reward: -25.526370319004258, TD loss   : 27.91682463288307, Episode   :    164\n",
      "Iteration :  22800, Train reward: -29.8327455818325, Eval reward: -25.526370319004258, TD loss   : 44.21366971135139, Episode   :    164\n",
      "Iteration :  22900, Train reward: -37.25489447243382, Eval reward: -25.526370319004258, TD loss   : 31.145663306713104, Episode   :    165\n",
      "Iteration :  23000, Train reward: -37.25489447243382, Eval reward: -68.93704877267571, TD loss   : 27.85639508962631, Episode   :    165\n",
      "Iteration :  23100, Train reward: -42.12397096326941, Eval reward: -68.93704877267571, TD loss   : 37.45523866653443, Episode   :    166\n",
      "Iteration :  23200, Train reward: -42.12397096326941, Eval reward: -68.93704877267571, TD loss   : 32.234332251548764, Episode   :    166\n",
      "Iteration :  23300, Train reward: -42.91933150386908, Eval reward: -68.93704877267571, TD loss   : 44.013215391635896, Episode   :    167\n",
      "Iteration :  23400, Train reward: -42.91933150386908, Eval reward: -68.93704877267571, TD loss   : 28.491348239183427, Episode   :    167\n",
      "Iteration :  23500, Train reward: -42.91933150386908, Eval reward: -80.90128726273903, TD loss   : 45.23919568419456, Episode   :    167\n",
      "Iteration :  23600, Train reward: -43.48807249295775, Eval reward: -80.90128726273903, TD loss   : 30.931796768903734, Episode   :    168\n",
      "Iteration :  23700, Train reward: -43.48807249295775, Eval reward: -80.90128726273903, TD loss   : 32.64885811209679, Episode   :    168\n",
      "Iteration :  23800, Train reward: -43.48807249295775, Eval reward: -80.90128726273903, TD loss   : 14.094257595539093, Episode   :    168\n",
      "Iteration :  23900, Train reward: -44.742425620629525, Eval reward: -80.90128726273903, TD loss   : 26.87747880578041, Episode   :    169\n",
      "Iteration :  24000, Train reward: -44.742425620629525, Eval reward: -38.314792992820195, TD loss   : 44.8173709988594, Episode   :    169\n",
      "Iteration :  24100, Train reward: -45.69566393497622, Eval reward: -38.314792992820195, TD loss   : 30.785989311933516, Episode   :    170\n",
      "Iteration :  24200, Train reward: -45.69566393497622, Eval reward: -38.314792992820195, TD loss   : 30.10916887164116, Episode   :    170\n",
      "Iteration :  24300, Train reward: -45.69566393497622, Eval reward: -38.314792992820195, TD loss   : 28.639065067768097, Episode   :    170\n",
      "Iteration :  24400, Train reward: -42.117398409471114, Eval reward: -38.314792992820195, TD loss   : 25.890775505304337, Episode   :    171\n",
      "Iteration :  24500, Train reward: -42.117398409471114, Eval reward: -9.190817390841408, TD loss   : 29.047448624372482, Episode   :    171\n",
      "Iteration :  24600, Train reward: -42.07736156844662, Eval reward: -9.190817390841408, TD loss   : 33.73429161787033, Episode   :    172\n",
      "Iteration :  24700, Train reward: -42.07736156844662, Eval reward: -9.190817390841408, TD loss   : 28.581683288812638, Episode   :    172\n",
      "Iteration :  24800, Train reward: -42.07736156844662, Eval reward: -9.190817390841408, TD loss   : 25.224436892271044, Episode   :    172\n",
      "Iteration :  24900, Train reward: -41.50315862408568, Eval reward: -9.190817390841408, TD loss   : 27.785525447130205, Episode   :    173\n",
      "Iteration :  25000, Train reward: -41.50315862408568, Eval reward: -34.7279979343038, TD loss   : 30.393000173568726, Episode   :    173\n",
      "Iteration :  25100, Train reward: -36.38593067448678, Eval reward: -34.7279979343038, TD loss   : 50.43247171521187, Episode   :    174\n",
      "Iteration :  25200, Train reward: -36.38593067448678, Eval reward: -34.7279979343038, TD loss   : 20.12344589114189, Episode   :    174\n",
      "Iteration :  25300, Train reward: -34.19806435283187, Eval reward: -34.7279979343038, TD loss   : 26.717943816185, Episode   :    175\n",
      "Iteration :  25400, Train reward: -34.19806435283187, Eval reward: -34.7279979343038, TD loss   : 24.072207578420638, Episode   :    175\n",
      "Iteration :  25500, Train reward: -34.19806435283187, Eval reward: 2.0419709403642115, TD loss   : 31.22708674788475, Episode   :    175\n",
      "Iteration :  25600, Train reward: -35.24465008512834, Eval reward: 2.0419709403642115, TD loss   : 28.161023482084275, Episode   :    176\n",
      "Iteration :  25700, Train reward: -35.24465008512834, Eval reward: 2.0419709403642115, TD loss   : 23.722895786762237, Episode   :    176\n",
      "Iteration :  25800, Train reward: -35.24465008512834, Eval reward: 2.0419709403642115, TD loss   : 31.259919662475586, Episode   :    176\n",
      "Iteration :  25900, Train reward: -34.0425160463369, Eval reward: 2.0419709403642115, TD loss   : 29.60543253183365, Episode   :    177\n",
      "Iteration :  26000, Train reward: -34.0425160463369, Eval reward: -183.55243514774628, TD loss   : 27.74035374522209, Episode   :    177\n",
      "Iteration :  26100, Train reward: -33.330002641923436, Eval reward: -183.55243514774628, TD loss   : 26.937168419361115, Episode   :    178\n",
      "Iteration :  26200, Train reward: -34.4227733571381, Eval reward: -183.55243514774628, TD loss   : 20.142735694646834, Episode   :    179\n",
      "Iteration :  26300, Train reward: -34.4227733571381, Eval reward: -183.55243514774628, TD loss   : 35.526029928922654, Episode   :    179\n",
      "Iteration :  26400, Train reward: -34.4227733571381, Eval reward: -183.55243514774628, TD loss   : 31.5310658288002, Episode   :    179\n",
      "Iteration :  26500, Train reward: -29.754920797984493, Eval reward: 0.28277982732584234, TD loss   : 43.257411575317384, Episode   :    180\n",
      "Iteration :  26600, Train reward: -25.55999262189691, Eval reward: 0.28277982732584234, TD loss   : 22.431334029436112, Episode   :    181\n",
      "Iteration :  26700, Train reward: -25.55999262189691, Eval reward: 0.28277982732584234, TD loss   : 22.040783640146255, Episode   :    181\n",
      "Iteration :  26800, Train reward: -25.55999262189691, Eval reward: 0.28277982732584234, TD loss   : 24.948342387676238, Episode   :    181\n",
      "Iteration :  26900, Train reward: -22.995154147827172, Eval reward: 0.28277982732584234, TD loss   : 35.19701279759407, Episode   :    182\n",
      "Iteration :  27000, Train reward: -22.995154147827172, Eval reward: -10.065906219645747, TD loss   : 46.199807003736495, Episode   :    182\n",
      "Iteration :  27100, Train reward: -16.566918605249356, Eval reward: -10.065906219645747, TD loss   : 21.4241863155365, Episode   :    183\n",
      "Iteration :  27200, Train reward: -16.566918605249356, Eval reward: -10.065906219645747, TD loss   : 29.992905871868132, Episode   :    183\n",
      "Iteration :  27300, Train reward: -16.566918605249356, Eval reward: -10.065906219645747, TD loss   : 30.556922974586488, Episode   :    183\n",
      "Iteration :  27400, Train reward: -18.737385757923334, Eval reward: -10.065906219645747, TD loss   : 28.2347590303421, Episode   :    184\n",
      "Iteration :  27500, Train reward: -18.737385757923334, Eval reward: 7.413819089174053, TD loss   : 19.220074837207793, Episode   :    184\n",
      "Iteration :  27600, Train reward: -12.675817793911767, Eval reward: 7.413819089174053, TD loss   : 32.13544216990471, Episode   :    185\n",
      "Iteration :  27700, Train reward: -12.675817793911767, Eval reward: 7.413819089174053, TD loss   : 25.512817877531052, Episode   :    185\n",
      "Iteration :  27800, Train reward: -17.631495753784826, Eval reward: 7.413819089174053, TD loss   : 23.192315769195556, Episode   :    186\n",
      "Iteration :  27900, Train reward: -19.920264540613704, Eval reward: 7.413819089174053, TD loss   : 20.59111604690552, Episode   :    187\n",
      "Iteration :  28000, Train reward: -19.920264540613704, Eval reward: -24.590896178254205, TD loss   : 17.206988860368728, Episode   :    187\n",
      "Iteration :  28100, Train reward: -13.776779304968883, Eval reward: -24.590896178254205, TD loss   : 18.138708149194716, Episode   :    188\n",
      "Iteration :  28200, Train reward: -13.776779304968883, Eval reward: -24.590896178254205, TD loss   : 30.757881432771683, Episode   :    188\n",
      "Iteration :  28300, Train reward: -13.776779304968883, Eval reward: -24.590896178254205, TD loss   : 19.789487990140916, Episode   :    188\n",
      "Iteration :  28400, Train reward: -16.167905449662793, Eval reward: -24.590896178254205, TD loss   : 42.8262985932827, Episode   :    189\n",
      "Iteration :  28500, Train reward: -16.167905449662793, Eval reward: 26.52264115741641, TD loss   : 15.65554671049118, Episode   :    189\n",
      "Iteration :  28600, Train reward: -14.918555115737608, Eval reward: 26.52264115741641, TD loss   : 19.98769494712353, Episode   :    190\n",
      "Iteration :  28700, Train reward: -14.918555115737608, Eval reward: 26.52264115741641, TD loss   : 23.61389015197754, Episode   :    190\n",
      "Iteration :  28800, Train reward: -14.918555115737608, Eval reward: 26.52264115741641, TD loss   : 19.249059519767762, Episode   :    190\n",
      "Iteration :  28900, Train reward: -7.592693312954599, Eval reward: 26.52264115741641, TD loss   : 20.506845655441285, Episode   :    191\n",
      "Iteration :  29000, Train reward: -7.592693312954599, Eval reward: -11.272916851062693, TD loss   : 17.042638384103775, Episode   :    191\n",
      "Iteration :  29100, Train reward: -8.202813533675377, Eval reward: -11.272916851062693, TD loss   : 33.13985198378563, Episode   :    192\n",
      "Iteration :  29200, Train reward: -8.202813533675377, Eval reward: -11.272916851062693, TD loss   : 27.40199479818344, Episode   :    192\n",
      "Iteration :  29300, Train reward: -8.202813533675377, Eval reward: -11.272916851062693, TD loss   : 35.431970722675324, Episode   :    192\n",
      "Iteration :  29400, Train reward: -4.023856653418295, Eval reward: -11.272916851062693, TD loss   : 33.28791658997536, Episode   :    193\n",
      "Iteration :  29500, Train reward: -6.612050809667321, Eval reward: -127.11009404424631, TD loss   : 32.215525777339934, Episode   :    194\n",
      "Iteration :  29600, Train reward: 0.5932149931502042, Eval reward: -127.11009404424631, TD loss   : 29.76983915567398, Episode   :    195\n",
      "Iteration :  29700, Train reward: -3.305494097484585, Eval reward: -127.11009404424631, TD loss   : 37.10348673224449, Episode   :    196\n",
      "Iteration :  29800, Train reward: -3.305494097484585, Eval reward: -127.11009404424631, TD loss   : 17.936146409511565, Episode   :    196\n",
      "Iteration :  29900, Train reward: -3.305494097484585, Eval reward: -127.11009404424631, TD loss   : 36.5175068962574, Episode   :    196\n",
      "Iteration :  30000, Train reward: -2.6977385971534207, Eval reward: -27.394153817913082, TD loss   : 16.763726981878282, Episode   :    197\n",
      "Iteration :  30100, Train reward: -3.2245647106070443, Eval reward: -27.394153817913082, TD loss   : 28.821940395832062, Episode   :    198\n",
      "Iteration :  30200, Train reward: -3.2245647106070443, Eval reward: -27.394153817913082, TD loss   : 19.769868638515472, Episode   :    198\n",
      "Iteration :  30300, Train reward: -18.90347780705872, Eval reward: -27.394153817913082, TD loss   : 24.208068364858626, Episode   :    199\n",
      "Iteration :  30400, Train reward: -18.90347780705872, Eval reward: -27.394153817913082, TD loss   : 45.33604606866837, Episode   :    199\n",
      "Iteration :  30500, Train reward: -24.712888570269747, Eval reward: -43.537247141943986, TD loss   : 24.582301127910615, Episode   :    200\n",
      "Iteration :  30600, Train reward: -26.791234193631915, Eval reward: -43.537247141943986, TD loss   : 15.266742230653763, Episode   :    201\n",
      "Iteration :  30700, Train reward: -26.791234193631915, Eval reward: -43.537247141943986, TD loss   : 28.108153690099716, Episode   :    201\n",
      "Iteration :  30800, Train reward: -26.791234193631915, Eval reward: -43.537247141943986, TD loss   : 15.48308061361313, Episode   :    201\n",
      "Iteration :  30900, Train reward: -27.57191035313473, Eval reward: -43.537247141943986, TD loss   : 38.816532814502715, Episode   :    202\n",
      "Iteration :  31000, Train reward: -27.57191035313473, Eval reward: -66.07988450899349, TD loss   : 30.94978340268135, Episode   :    202\n",
      "Iteration :  31100, Train reward: -27.40769059656194, Eval reward: -66.07988450899349, TD loss   : 25.66502783536911, Episode   :    203\n",
      "Iteration :  31200, Train reward: -27.40769059656194, Eval reward: -66.07988450899349, TD loss   : 36.03472561597824, Episode   :    203\n",
      "Iteration :  31300, Train reward: -27.40769059656194, Eval reward: -66.07988450899349, TD loss   : 23.37699847102165, Episode   :    203\n",
      "Iteration :  31400, Train reward: -32.922557876965364, Eval reward: -66.07988450899349, TD loss   : 22.973819762468338, Episode   :    204\n",
      "Iteration :  31500, Train reward: -32.922557876965364, Eval reward: 18.644952379169187, TD loss   : 28.7628494143486, Episode   :    204\n",
      "Iteration :  31600, Train reward: -40.151349246017745, Eval reward: 18.644952379169187, TD loss   : 22.651845613718034, Episode   :    205\n",
      "Iteration :  31700, Train reward: -40.151349246017745, Eval reward: 18.644952379169187, TD loss   : 33.824528115987775, Episode   :    205\n",
      "Iteration :  31800, Train reward: -38.53899877257139, Eval reward: 18.644952379169187, TD loss   : 28.12482843875885, Episode   :    206\n",
      "Iteration :  31900, Train reward: -38.53899877257139, Eval reward: 18.644952379169187, TD loss   : 33.19599425077438, Episode   :    206\n",
      "Iteration :  32000, Train reward: -38.53899877257139, Eval reward: -79.15500909860076, TD loss   : 43.73496130347252, Episode   :    206\n",
      "Iteration :  32100, Train reward: -44.14475630794826, Eval reward: -79.15500909860076, TD loss   : 25.862312980890273, Episode   :    207\n",
      "Iteration :  32200, Train reward: -48.944327275604905, Eval reward: -79.15500909860076, TD loss   : 28.450909669399262, Episode   :    208\n",
      "Iteration :  32300, Train reward: -48.944327275604905, Eval reward: -79.15500909860076, TD loss   : 24.51334296822548, Episode   :    208\n",
      "Iteration :  32400, Train reward: -48.944327275604905, Eval reward: -79.15500909860076, TD loss   : 29.830580990314484, Episode   :    208\n",
      "Iteration :  32500, Train reward: -47.24362775855473, Eval reward: -53.41494622345082, TD loss   : 21.92183643102646, Episode   :    209\n",
      "Iteration :  32600, Train reward: -53.05783125770565, Eval reward: -53.41494622345082, TD loss   : 25.058054939508438, Episode   :    210\n",
      "Iteration :  32700, Train reward: -53.05783125770565, Eval reward: -53.41494622345082, TD loss   : 24.639807759523393, Episode   :    210\n",
      "Iteration :  32800, Train reward: -65.88951534781384, Eval reward: -53.41494622345082, TD loss   : 30.524604942798614, Episode   :    211\n",
      "Iteration :  32900, Train reward: -65.88951534781384, Eval reward: -53.41494622345082, TD loss   : 31.965475223064423, Episode   :    211\n",
      "Iteration :  33000, Train reward: -65.88951534781384, Eval reward: 24.293294436898243, TD loss   : 32.954020637273786, Episode   :    211\n",
      "Iteration :  33100, Train reward: -65.82848155156651, Eval reward: 24.293294436898243, TD loss   : 25.22150095820427, Episode   :    212\n",
      "Iteration :  33200, Train reward: -72.28835640751085, Eval reward: 24.293294436898243, TD loss   : 30.206093866825103, Episode   :    213\n",
      "Iteration :  33300, Train reward: -72.28835640751085, Eval reward: 24.293294436898243, TD loss   : 28.4511732840538, Episode   :    213\n",
      "Iteration :  33400, Train reward: -72.28835640751085, Eval reward: 24.293294436898243, TD loss   : 22.714381294250487, Episode   :    213\n",
      "Iteration :  33500, Train reward: -71.95411246469112, Eval reward: -144.09092056823866, TD loss   : 20.87014933347702, Episode   :    214\n",
      "Iteration :  33600, Train reward: -79.25616721267728, Eval reward: -144.09092056823866, TD loss   : 31.371918983459473, Episode   :    215\n",
      "Iteration :  33700, Train reward: -79.25616721267728, Eval reward: -144.09092056823866, TD loss   : 25.11551137447357, Episode   :    215\n",
      "Iteration :  33800, Train reward: -79.25616721267728, Eval reward: -144.09092056823866, TD loss   : 35.28395197153091, Episode   :    215\n",
      "Iteration :  33900, Train reward: -76.41419139036961, Eval reward: -144.09092056823866, TD loss   : 22.277670545578005, Episode   :    216\n",
      "Iteration :  34000, Train reward: -76.41419139036961, Eval reward: -22.355903074423548, TD loss   : 31.28812900543213, Episode   :    216\n",
      "Iteration :  34100, Train reward: -74.29218545042488, Eval reward: -22.355903074423548, TD loss   : 22.533636260032655, Episode   :    217\n",
      "Iteration :  34200, Train reward: -74.29218545042488, Eval reward: -22.355903074423548, TD loss   : 33.65917737007141, Episode   :    217\n",
      "Iteration :  34300, Train reward: -74.29218545042488, Eval reward: -22.355903074423548, TD loss   : 19.292145659923552, Episode   :    217\n",
      "Iteration :  34400, Train reward: -75.77558980001162, Eval reward: -22.355903074423548, TD loss   : 33.557559340000154, Episode   :    218\n",
      "Iteration :  34500, Train reward: -75.77558980001162, Eval reward: -22.720632502153464, TD loss   : 27.374795637130738, Episode   :    218\n",
      "Iteration :  34600, Train reward: -59.354626220725564, Eval reward: -22.720632502153464, TD loss   : 21.46427137851715, Episode   :    219\n",
      "Iteration :  34700, Train reward: -59.354626220725564, Eval reward: -22.720632502153464, TD loss   : 16.656286627054214, Episode   :    219\n",
      "Iteration :  34800, Train reward: -59.354626220725564, Eval reward: -22.720632502153464, TD loss   : 14.82232670545578, Episode   :    219\n",
      "Iteration :  34900, Train reward: -57.49843526588048, Eval reward: -22.720632502153464, TD loss   : 21.88772623062134, Episode   :    220\n",
      "Iteration :  35000, Train reward: -57.49843526588048, Eval reward: -144.80397181440156, TD loss   : 24.096841946840286, Episode   :    220\n",
      "Iteration :  35100, Train reward: -62.677547158416225, Eval reward: -144.80397181440156, TD loss   : 18.376603255271913, Episode   :    221\n",
      "Iteration :  35200, Train reward: -62.677547158416225, Eval reward: -144.80397181440156, TD loss   : 32.94645921945572, Episode   :    221\n",
      "Iteration :  35300, Train reward: -66.33207172638313, Eval reward: -144.80397181440156, TD loss   : 24.97178880572319, Episode   :    222\n",
      "Iteration :  35400, Train reward: -66.33207172638313, Eval reward: -144.80397181440156, TD loss   : 23.980112154483795, Episode   :    222\n",
      "Iteration :  35500, Train reward: -71.21766682358692, Eval reward: -183.81934162948747, TD loss   : 30.778891965150834, Episode   :    223\n",
      "Iteration :  35600, Train reward: -63.97948133038075, Eval reward: -183.81934162948747, TD loss   : 26.572448867559434, Episode   :    224\n",
      "Iteration :  35700, Train reward: -63.97948133038075, Eval reward: -183.81934162948747, TD loss   : 35.98876190662384, Episode   :    224\n",
      "Iteration :  35800, Train reward: -64.89973211070031, Eval reward: -183.81934162948747, TD loss   : 15.803296848535538, Episode   :    225\n",
      "Iteration :  35900, Train reward: -64.89973211070031, Eval reward: -183.81934162948747, TD loss   : 23.880958091020585, Episode   :    225\n",
      "Iteration :  36000, Train reward: -64.89973211070031, Eval reward: -112.30246011388604, TD loss   : 28.246500663757324, Episode   :    225\n",
      "Iteration :  36100, Train reward: -68.35821277323329, Eval reward: -112.30246011388604, TD loss   : 18.04629412531853, Episode   :    226\n",
      "Iteration :  36200, Train reward: -68.35821277323329, Eval reward: -112.30246011388604, TD loss   : 22.703104988336563, Episode   :    226\n",
      "Iteration :  36300, Train reward: -65.21039452393646, Eval reward: -112.30246011388604, TD loss   : 21.085707623958587, Episode   :    227\n",
      "Iteration :  36400, Train reward: -65.80287536365893, Eval reward: -112.30246011388604, TD loss   : 30.58322296500206, Episode   :    228\n",
      "Iteration :  36500, Train reward: -65.80287536365893, Eval reward: -77.31716961253704, TD loss   : 20.621072947978973, Episode   :    228\n",
      "Iteration :  36600, Train reward: -66.51993264489718, Eval reward: -77.31716961253704, TD loss   : 22.77861234664917, Episode   :    229\n",
      "Iteration :  36700, Train reward: -66.51993264489718, Eval reward: -77.31716961253704, TD loss   : 21.584694603681566, Episode   :    229\n",
      "Iteration :  36800, Train reward: -69.66237501879135, Eval reward: -77.31716961253704, TD loss   : 26.861018676757812, Episode   :    230\n",
      "Iteration :  36900, Train reward: -69.66237501879135, Eval reward: -77.31716961253704, TD loss   : 20.072565376758575, Episode   :    230\n",
      "Iteration :  37000, Train reward: -69.66237501879135, Eval reward: -163.05990084764136, TD loss   : 34.41532217860222, Episode   :    230\n",
      "Iteration :  37100, Train reward: -70.65745997891483, Eval reward: -163.05990084764136, TD loss   : 27.149562133550646, Episode   :    231\n",
      "Iteration :  37200, Train reward: -69.85627305078461, Eval reward: -163.05990084764136, TD loss   : 28.365750769376756, Episode   :    232\n",
      "Iteration :  37300, Train reward: -69.85627305078461, Eval reward: -163.05990084764136, TD loss   : 23.507341668605804, Episode   :    232\n",
      "Iteration :  37400, Train reward: -73.45922412319047, Eval reward: -163.05990084764136, TD loss   : 24.02390875816345, Episode   :    233\n",
      "Iteration :  37500, Train reward: -73.45922412319047, Eval reward: -40.55653335217491, TD loss   : 30.224622876644133, Episode   :    233\n",
      "Iteration :  37600, Train reward: -68.54466362051592, Eval reward: -40.55653335217491, TD loss   : 26.347580074071885, Episode   :    234\n",
      "Iteration :  37700, Train reward: -68.54466362051592, Eval reward: -40.55653335217491, TD loss   : 25.05785876750946, Episode   :    234\n",
      "Iteration :  37800, Train reward: -68.54466362051592, Eval reward: -40.55653335217491, TD loss   : 28.851555787324905, Episode   :    234\n",
      "Iteration :  37900, Train reward: -66.2225532453673, Eval reward: -40.55653335217491, TD loss   : 16.027999168634416, Episode   :    235\n",
      "Iteration :  38000, Train reward: -66.2225532453673, Eval reward: -16.837630611256074, TD loss   : 28.61467917919159, Episode   :    235\n",
      "Iteration :  38100, Train reward: -62.163155395236366, Eval reward: -16.837630611256074, TD loss   : 28.103087413311005, Episode   :    236\n",
      "Iteration :  38200, Train reward: -62.163155395236366, Eval reward: -16.837630611256074, TD loss   : 27.40510288953781, Episode   :    236\n",
      "Iteration :  38300, Train reward: -72.85546477735821, Eval reward: -16.837630611256074, TD loss   : 33.8031199836731, Episode   :    237\n",
      "Iteration :  38400, Train reward: -72.85546477735821, Eval reward: -16.837630611256074, TD loss   : 25.26209455251694, Episode   :    237\n",
      "Iteration :  38500, Train reward: -72.85546477735821, Eval reward: -71.81112022172087, TD loss   : 23.334664433002473, Episode   :    237\n",
      "Iteration :  38600, Train reward: -75.54898352247434, Eval reward: -71.81112022172087, TD loss   : 35.598255565166475, Episode   :    238\n",
      "Iteration :  38700, Train reward: -80.19344061399879, Eval reward: -71.81112022172087, TD loss   : 18.120232861042023, Episode   :    239\n",
      "Iteration :  38800, Train reward: -80.19344061399879, Eval reward: -71.81112022172087, TD loss   : 26.0224944961071, Episode   :    239\n",
      "Iteration :  38900, Train reward: -80.19344061399879, Eval reward: -71.81112022172087, TD loss   : 30.665932463407515, Episode   :    239\n",
      "Iteration :  39000, Train reward: -82.44370582670105, Eval reward: -256.5052511853302, TD loss   : 32.99561516642571, Episode   :    240\n",
      "Iteration :  39100, Train reward: -81.31902313883754, Eval reward: -256.5052511853302, TD loss   : 35.62607610702515, Episode   :    241\n",
      "Iteration :  39200, Train reward: -81.31902313883754, Eval reward: -256.5052511853302, TD loss   : 30.062056339979172, Episode   :    241\n",
      "Iteration :  39300, Train reward: -83.74077719585011, Eval reward: -256.5052511853302, TD loss   : 32.96085317373276, Episode   :    242\n",
      "Iteration :  39400, Train reward: -83.74077719585011, Eval reward: -256.5052511853302, TD loss   : 32.38617773771286, Episode   :    242\n",
      "Iteration :  39500, Train reward: -83.74077719585011, Eval reward: -37.04457914248411, TD loss   : 24.28678772211075, Episode   :    242\n",
      "Iteration :  39600, Train reward: -81.59602917170686, Eval reward: -37.04457914248411, TD loss   : 26.232365238666535, Episode   :    243\n",
      "Iteration :  39700, Train reward: -81.59602917170686, Eval reward: -37.04457914248411, TD loss   : 34.05570387125015, Episode   :    243\n",
      "Iteration :  39800, Train reward: -80.30911068472895, Eval reward: -37.04457914248411, TD loss   : 10.981572026014328, Episode   :    244\n",
      "Iteration :  39900, Train reward: -80.30911068472895, Eval reward: -37.04457914248411, TD loss   : 22.047701938152315, Episode   :    244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HasanErdin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\HasanErdin\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    !python dqn/dqn/box2d.py --log_dir logs/vanilla-dqn-exp3 --target-update-period 1000 --buffer-capacity 100000 --epsilon-decay 25e-6 --render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"logs\", \"vanilla-dqn-exp3\")\n",
    "exp_3_dataframes = collect_training_logs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c387faaaa874d9e9fe2695499a63ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='X axis', options=('Episode', 'Iteration'), value=None), Dropdown(descriptâ€¦"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Plotter({\"primitive_dqn\": exp_1_dataframes, \"stable_dqn\": exp_2_dataframes, \"exp_decay_dqn\": exp_3_dataframes})()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"margin-top: 0px;\n",
    "  margin-bottom: 10px;\n",
    "  font-family: sans-serif;\n",
    "  font-size: 8rem;\">\n",
    "<span style=\"color:#FF0000\">R</span><span style=\"color:#FFDB00\">a</span><span style=\"color:#49FF00\">i</span><span style=\"color:#00FF92\">n</span><span style=\"color:#0092FF\">b</span><span style=\"color:#4900FF\">o</span><span style=\"color:#FF00DB\">w</span>\n",
    "</h1>\n",
    "\n",
    "We use DQN as a base class for our implementation. Rainbow introduces a few extensions over vanilla DQN. Each of these extensions can be disabled in our implementation. We will test the Rainbow agent in both Lunar Lander and Pong.\n",
    "\n",
    "> **Read** the related paper or the book section before moving to implementation.\n",
    "\n",
    "### Implementation\n",
    "\n",
    "Before implementing extensions we need to have a bare minimum DQN so that you can test your extension independently. We feed ```extensions``` dictionary to Rainbow agent. The dictionary contains information related to extensions that we want to use in RAINBOW agent. You can see the definition of ```extensions``` dictionary in ```dqn/rainbow/box2d.py```.\n",
    "\n",
    "Luckly, we already have a \"vanilla\" DQN to start with. We only need to complete a few parts to run vanilla DQN (one that has no extension) in rainbow agent. \n",
    "\n",
    "> Complete ```ValueNet``` in ```dqn/rainbow/box2d.py```. Ignore the ```extensions``` dictionary for now.\n",
    "\n",
    "Most of the methods use inherited functions from DQN section. However, as you implement the extensions you will need to replace them with their extension based versions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python dqn/rainbow/box2d.py --n-iterations 80000 --no-double --no-dueling --no-noisy --no-prioritized --n-steps 1 --no-dist --render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Prioritized Buffer\n",
    "Let's start with Prioritized Replay Buffer. To start implementing this buffer we need weighted sampling. NumPy has ```np.random.choice``` function that we can use for prioritized sampling. \n",
    "\n",
    "\n",
    "> Complete ``` PriorityBuffer ``` in ``` dqn/replaybuffer/prioritized.py ```.\n",
    "> - ```push```\n",
    "> - ```sample```\n",
    "> - ```update_priority```\n",
    "\n",
    "**Prioritized Buffer** causes a few changes in the code.\n",
    "- ```update``` function in the ```Trainer``` class located at ```dqn/rainbow/train.py```\n",
    "- ``` loss ``` functions (two of them) in the ```Rainbow``` class. Loss tensor must not be averaged over the batch axis! In the ```update``` function we will be using the weighted average loss where the weights are Importance sampling weights obtained from  Prioritized Buffer sample (see the paper for further details). Also, update the td errors of the samples. \n",
    "\n",
    "> Modify ```update``` method in  ```dqn/rainbow/train.py```.\n",
    "\n",
    "> Modify ```vanilla_loss``` in ```dqn/rainbow/model.py```.\n",
    "\n",
    "> Modify ```_next_action_network``` in ```dqn/rainbow/model.py```. (We will comeback to this one in Double & Noisy extensions)\n",
    "\n",
    "Use ```_next_action_network``` to obtain target actions so that the loss functions become compatible with double Q-learning.\n",
    "\n",
    "Remember this while implementing ```update``` function!\n",
    "\n",
    "You can run Prioritized Buffer experiments bash script under the experiments section to test your implementation.\n",
    "\n",
    "- - -\n",
    "\n",
    "#### Distributional RL\n",
    "\n",
    "This extension changes Q value and hence loss function and policy need modifications. Greedy policy need the expected value of Q distribution, therefore we need to implement additional method that we can use in greedy policy. Moreover, we need to have a Q network with more outputs ```(act_size * n_atoms)``` instaed of ```act_size```\n",
    "\n",
    "> Complete ```distributional_loss ``` in ```dqn/rainbow/model.py```.\n",
    "\n",
    "> Complete ```expected_value ``` in ```dqn/rainbow/model.py```.\n",
    "\n",
    "> Modify ```HeadLayer ``` in ```dqn/rainbow/layers.py```.\n",
    "- - -\n",
    "\n",
    "#### N-step Learning\n",
    "\n",
    "There are many ways of using n-step learning, so we will pick the simplest one. Ignore Importance sampling ratios. Yield a transition with a reward that equals to the sum of $n$ consecutive rewards (discounted by gamma) and the nth next state as the next_state. You can find this way of using n-step learning in Chapter 7 of the textbook (without Importance Sampling or Tree Backup, similar to n-step Sarsa). You can use ```deque```s to delay yielding transitions.\n",
    "\n",
    "$(s_t, a_t, \\sum_{j=t}^{t+n}(\\gamma^{j-t} r_t), \\text{done}, s_{t+n})$\n",
    "\n",
    "> Complete ``` __iter__``` in ``` dqn/rainbow/train.py ```\n",
    "\n",
    "We set n to 1 to deactivate this extension.\n",
    "\n",
    "- - -\n",
    "#### Double Q-learning\n",
    "\n",
    "In double Q learning, the target value is calculated using the actions selected from the online network(```valuenet```). Since we already use ```_next_action_network``` function to find the action that yields maximum value at the next state, we only need to implement ```_next_action_network``` method in ```dqn/rainbow/model.py```.\n",
    "\n",
    "> Modify ```_next_action_network``` in ```dqn/rainbow/model.py```.\n",
    "\n",
    "- - -\n",
    "#### Noisy Net\n",
    "\n",
    "In this part, we need to complete ```NoisyLayer``` at ```dqn/rainbow/layers.py```. Moreover, when we use \"noisy-network\" we can act greedily since the stochasticity is built within the network. In ```__iter__``` method at ``` dqn/rainbow/train.py``` use ```greedy_policy``` if noisy-net is active.\n",
    "\n",
    "> Complete ```NoisyLinear``` in ```dqn/rainbow/layers.py```.\n",
    "> - __init__\n",
    "> - reset_noise\n",
    "> - forward\n",
    "\n",
    "> Modify ```update``` in  ```dqn/rainbow/train.py``` to reset noise if noisy network is active. Reset both the target and the online networks separately.\n",
    "\n",
    "> Modify ```__iter__``` in  ```dqn/rainbow/train.py``` to use greedy (but noisy) policy for exploration.\n",
    "\n",
    "> Modify ```ValueNet``` in ```dqn/rainbow/box2d.py```.\n",
    "\n",
    "> Modify ```ValueNet``` in ```dqn/rainbow/pong.py``` when you start working with Pong.\n",
    "\n",
    "> Modify ```HeadLayer``` in ```dqn/rainbow/layers.py```.\n",
    "\n",
    "In eval mode, use parameter means. Do not forget to use eval mode for target value calculations.\n",
    "\n",
    "\n",
    "- - - \n",
    "#### Dueling Architecutre\n",
    "\n",
    "You can implement Dueling architecture by filling the ```HeadLayer``` class at ```dqn/rainbow/layers.py```. Remember, the structure of this class depends on Dueling, Distributional, and Noisy Nets.\n",
    "\n",
    "> Modify ```HeadLayer``` in ```dqn/rainbow/layers.py```.\n",
    "\n",
    "- - - \n",
    "#### Rainbow\n",
    "\n",
    "Once you completed all the extensions you can combine them. Complete the implementation by filling:\n",
    "\n",
    "- In box2D, initialize a fully connected network.\n",
    "> Complete ```ValueNet``` in ```dqn/rainbow/box2d.py``` use ```HeadLayer``` and ```NoisyLinear``` layers if noisy is activated\n",
    "- In pong, initialize a convolutional network that reduces the spatial size into 5 by 5 (or any other value that you prefer). \n",
    "> Complete ```ValueNet``` in ```dqn/rainbow/pong.py``` use ```HeadLayer``` and ```NoisyLinear``` layers if noisy is activated\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments\n",
    "\n",
    "We will test each extension on its own. Run ```box2d.py``` by enabling one extension at a time and store the results (5 runs per experiment). An example run is given below for prioritized-only experiment.\n",
    "\n",
    "> Remember ```n-iterations``` and ```write-period``` must be fixed within each experiment for plotting purposes!\n",
    "In total, there must be 30 runs (5 for each)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DQN with Prioritized Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    !python dqn/rainbow/box2d.py --log_dir logs/prioritized --no-dist --no-dueling --n-step 1 --no-double --no-noisy --n-iterations 80000 --render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DQN with Distributional Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    !python dqn/rainbow/box2d.py --log_dir logs/distributional --no-prioritized --no-dueling --n-step 1 --no-double --no-noisy --n-iterations 80000 --render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DQN with N-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    !python dqn/rainbow/box2d.py --log_dir logs/nsteps --no-prioritized --no-dist --no-dueling --n-step 3 --no-double --no-noisy --n-iterations 80000 --render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DQN with Double Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    !python dqn/rainbow/box2d.py --log_dir logs/double --no-prioritized --no-dist --no-dueling --n-step 1 --no-noisy --n-iterations 80000 --render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DQN with Dueling Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    !python dqn/rainbow/box2d.py --log_dir logs/dueling --no-prioritized --no-dist --n-step 1 --no-double --no-noisy --n-iterations 80000 --render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DQN with Noisy Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    !python dqn/rainbow/box2d.py --log_dir logs/noisy --no-prioritized --no-dist --no-dueling --n-step 1 --no-double --n-iterations 80000 --render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gather dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_vanilla = collect_training_logs(os.path.join(\"logs\", \"vanilla-dqn-exp2\"))\n",
    "dataframes_prioritized = collect_training_logs(os.path.join(\"logs\", \"prioritized\"))\n",
    "dataframes_distributional = collect_training_logs(os.path.join(\"logs\", \"distributional\"))\n",
    "dataframes_nsteps = collect_training_logs(os.path.join(\"logs\", \"nsteps\"))\n",
    "dataframes_double = collect_training_logs(os.path.join(\"logs\", \"double\"))\n",
    "dataframes_dueling = collect_training_logs(os.path.join(\"logs\", \"dueling\"))\n",
    "dataframes_noisy = collect_training_logs(os.path.join(\"logs\", \"noisy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results using the provided Plotter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plotter(\n",
    "    {\"dqn\": dataframes_vanilla,\n",
    "     \"dqn+prioritized_buffer\": dataframes_prioritized,\n",
    "     \"dqn+distributional\": dataframes_distributional,\n",
    "     \"dqn+n_step\": dataframes_nsteps,\n",
    "     \"dqn+double_q\": dataframes_double,\n",
    "     \"dqn+dueling\": dataframes_dueling,\n",
    "     \"dqn+noisy_nets\": dataframes_noisy,\n",
    "    }\n",
    ")()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You can remove the ones that you did not implement from the plots.\n",
    "\n",
    "> Feel free to experiment with hyperparameters. You can plot their scores and compare them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATARI**\n",
    "\n",
    "The next step is to train **Pong** with the Rainbow agent. This time, please enable model saving ```--save-model``` and upload the model parameters that returns the highest evaluation score to google drive. Put the link at the end of the notebook. You can use any combination of extensions.\n",
    "\n",
    "> **Note**: No need to run Pong for more than 1 run!\n",
    "\n",
    "> **Note**: You need GPU for this experiment! You can use [Colab](https://colab.research.google.com/) if you do not have access to a GPU machine.\n",
    "\n",
    "Before starting a long training make sure that pong.py terminates successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python dqn/rainbow/pong.py --log_dir logs/pong --no-double --no-noisy --no-prioritized --n-steps 1 --no-dist --render --device cuda --save-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training\n",
    "Plotter({\"dqn\": collect_training_logs(os.path.join(\"logs\", \"pong\"))})()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put Google drive [link](?) for the model paramterers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://drive.google.com/file/d/1bHl2iDlWs6zfJT_21u4cDnczvDRv1HVB/view?usp=sharing"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
